{"timestamp":"2025-05-28T12:57:33.626868","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-05-28T12:57:33.627407","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/ETL_dags.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-05-28T12:57:34.427862","level":"info","event":"Secrets backends loaded for worker","count":1,"backend_classes":["EnvironmentVariablesBackend"],"logger":"supervisor"}
{"timestamp":"2025-05-28T12:57:35.142884","level":"warning","event":"Skipping masking for a secret as it's too short (<5 chars)","logger":"airflow.sdk.execution_time.secrets_masker"}
{"timestamp":"2025-05-28T12:57:35.144070","level":"info","event":"Connection Retrieved 'spark_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-05-28T12:57:35.145806","level":"info","event":"Spark-Submit cmd: spark-submit --master local[*] --conf spark.master=local[*] --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 --conf spark.hadoop.fs.s3a.access.key=minioLocalAccessKey --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.hadoop.fs.s3a.attempts.maximum=3 --conf spark.hadoop.fs.s3a.connection.establish.timeout=5000 --conf spark.hadoop.fs.s3a.connection.timeout=200000 --conf spark.hadoop.fs.s3a.buffer.dir=/tmp --conf spark.hadoop.fs.s3a.fast.upload=true --conf spark.hadoop.fs.s3a.fast.upload.buffer=disk --conf spark.hadoop.fs.s3a.multipart.size=104857600 --conf spark.hadoop.fs.s3a.multipart.threshold=2147483647 --driver-memory 2g --name split-customer-local --verbose --deploy-mode client /opt/airflow/dags/spark_jobs/split_customer.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.795559","level":"info","event":"Using properties file: /opt/spark/conf/spark-defaults.conf","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.946854","level":"info","event":"Adding default property: spark.executor.extraClassPath=/opt/spark-jars/*","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.947162","level":"info","event":"Adding default property: spark.sql.adaptive.coalescePartitions.enabled=true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.947308","level":"info","event":"Adding default property: spark.sql.adaptive.enabled=true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.947485","level":"info","event":"Adding default property: spark.driver.extraClassPath=/opt/spark-jars/*","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.987351","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.987612","level":"info","event":"master                  local[*]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.987737","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.987851","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.987955","level":"info","event":"executorMemory          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.988068","level":"info","event":"executorCores           null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.988220","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.988336","level":"info","event":"propertiesFile          /opt/spark/conf/spark-defaults.conf","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.988464","level":"info","event":"driverMemory            2g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.988576","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.988685","level":"info","event":"driverExtraClassPath    /opt/spark-jars/*","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.988796","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.988907","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.989014","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.989155","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.989279","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.989391","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.989496","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.989611","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.989714","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.989823","level":"info","event":"primaryResource         file:/opt/airflow/dags/spark_jobs/split_customer.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.990056","level":"info","event":"name                    split-customer-local","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.990305","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.990437","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.990629","level":"info","event":"packages                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.990790","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.990982","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.991126","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.991248","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.991367","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.991497","level":"info","event":"--conf and those from the properties file /opt/spark/conf/spark-defaults.conf:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.991617","level":"info","event":"(spark.driver.extraClassPath,/opt/spark-jars/*)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.991838","level":"info","event":"(spark.driver.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.991971","level":"info","event":"(spark.executor.extraClassPath,/opt/spark-jars/*)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.992113","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.992250","level":"info","event":"(spark.hadoop.fs.s3a.attempts.maximum,3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.992376","level":"info","event":"(spark.hadoop.fs.s3a.aws.credentials.provider,org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.992498","level":"info","event":"(spark.hadoop.fs.s3a.buffer.dir,/tmp)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.992623","level":"info","event":"(spark.hadoop.fs.s3a.connection.establish.timeout,5000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.992823","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.992951","level":"info","event":"(spark.hadoop.fs.s3a.connection.timeout,200000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.993084","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://minio:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.993234","level":"info","event":"(spark.hadoop.fs.s3a.fast.upload,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.993352","level":"info","event":"(spark.hadoop.fs.s3a.fast.upload.buffer,disk)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.993471","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.993597","level":"info","event":"(spark.hadoop.fs.s3a.multipart.size,104857600)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.993716","level":"info","event":"(spark.hadoop.fs.s3a.multipart.threshold,2147483647)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.993836","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.993949","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.994067","level":"info","event":"(spark.master,local[*])","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.994313","level":"info","event":"(spark.sql.adaptive.coalescePartitions.enabled,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.994460","level":"info","event":"(spark.sql.adaptive.enabled,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.994590","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:37.994709","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.425922","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.426205","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.426388","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.426552","level":"info","event":"file:/opt/airflow/dags/spark_jobs/split_customer.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.426702","level":"info","event":"null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.434313","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.434515","level":"info","event":"(spark.app.name,split-customer-local)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.434604","level":"info","event":"(spark.app.submitTime,1748437058400)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.434678","level":"info","event":"(spark.driver.extraClassPath,/opt/spark-jars/*)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.434744","level":"info","event":"(spark.driver.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.434822","level":"info","event":"(spark.executor.extraClassPath,/opt/spark-jars/*)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.434961","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.435068","level":"info","event":"(spark.hadoop.fs.s3a.attempts.maximum,3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.435160","level":"info","event":"(spark.hadoop.fs.s3a.aws.credentials.provider,org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.435232","level":"info","event":"(spark.hadoop.fs.s3a.buffer.dir,/tmp)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.435303","level":"info","event":"(spark.hadoop.fs.s3a.connection.establish.timeout,5000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.435430","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.435563","level":"info","event":"(spark.hadoop.fs.s3a.connection.timeout,200000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.435672","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://minio:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.435759","level":"info","event":"(spark.hadoop.fs.s3a.fast.upload,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.435843","level":"info","event":"(spark.hadoop.fs.s3a.fast.upload.buffer,disk)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.435926","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.436008","level":"info","event":"(spark.hadoop.fs.s3a.multipart.size,104857600)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.436093","level":"info","event":"(spark.hadoop.fs.s3a.multipart.threshold,2147483647)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.436175","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.436258","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.436340","level":"info","event":"(spark.master,local[*])","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.436422","level":"info","event":"(spark.sql.adaptive.coalescePartitions.enabled,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.436504","level":"info","event":"(spark.sql.adaptive.enabled,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.436586","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.436670","level":"info","event":"(spark.submit.pyFiles,)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.436773","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.436859","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.436946","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:38.437030","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:40.628237","level":"info","event":"25/05/28 12:57:40 INFO SparkContext: Running Spark version 3.5.1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:40.632423","level":"info","event":"25/05/28 12:57:40 INFO SparkContext: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:40.633124","level":"info","event":"25/05/28 12:57:40 INFO SparkContext: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:40.752168","level":"info","event":"25/05/28 12:57:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:40.922484","level":"info","event":"25/05/28 12:57:40 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:40.923328","level":"info","event":"25/05/28 12:57:40 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:40.924364","level":"info","event":"25/05/28 12:57:40 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:40.925517","level":"info","event":"25/05/28 12:57:40 INFO SparkContext: Submitted application: split_customer","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:40.960288","level":"info","event":"25/05/28 12:57:40 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:40.975506","level":"info","event":"25/05/28 12:57:40 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:40.976994","level":"info","event":"25/05/28 12:57:40 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:41.056314","level":"info","event":"25/05/28 12:57:41 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:41.057246","level":"info","event":"25/05/28 12:57:41 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:41.058495","level":"info","event":"25/05/28 12:57:41 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:41.060080","level":"info","event":"25/05/28 12:57:41 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:41.061075","level":"info","event":"25/05/28 12:57:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:41.453198","level":"info","event":"25/05/28 12:57:41 INFO Utils: Successfully started service 'sparkDriver' on port 33791.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:41.518751","level":"info","event":"25/05/28 12:57:41 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:41.577666","level":"info","event":"25/05/28 12:57:41 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:41.622881","level":"info","event":"25/05/28 12:57:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:41.625330","level":"info","event":"25/05/28 12:57:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:41.633192","level":"info","event":"25/05/28 12:57:41 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:41.688915","level":"info","event":"25/05/28 12:57:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f2017906-8f0c-4e5b-a3f0-64e51ba66373","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:41.787856","level":"info","event":"25/05/28 12:57:41 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:41.837956","level":"info","event":"25/05/28 12:57:41 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:42.163028","level":"info","event":"25/05/28 12:57:42 INFO JettyUtils: Start Jetty 127.0.0.1:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:42.337666","level":"info","event":"25/05/28 12:57:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:42.339544","level":"info","event":"25/05/28 12:57:42 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:42.361098","level":"info","event":"25/05/28 12:57:42 INFO Utils: Successfully started service 'SparkUI' on port 4042.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:42.600493","level":"info","event":"25/05/28 12:57:42 INFO Executor: Starting executor ID driver on host localhost","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:42.600903","level":"info","event":"25/05/28 12:57:42 INFO Executor: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:42.601825","level":"info","event":"25/05/28 12:57:42 INFO Executor: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:42.614915","level":"info","event":"25/05/28 12:57:42 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark-jars/*,file:/opt/airflow/*'","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:42.616237","level":"info","event":"25/05/28 12:57:42 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@12be5b32 for default.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:42.657155","level":"info","event":"25/05/28 12:57:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42069.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:42.657440","level":"info","event":"25/05/28 12:57:42 INFO NettyBlockTransferService: Server created on localhost:42069","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:42.661955","level":"info","event":"25/05/28 12:57:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:42.671505","level":"info","event":"25/05/28 12:57:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:42.677567","level":"info","event":"25/05/28 12:57:42 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42069 with 1048.8 MiB RAM, BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:42.682341","level":"info","event":"25/05/28 12:57:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:42.684674","level":"info","event":"25/05/28 12:57:42 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:43.481452","level":"info","event":"Reading data from S3...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:43.618245","level":"info","event":"25/05/28 12:57:43 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:43.631857","level":"info","event":"25/05/28 12:57:43 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:45.996314","level":"info","event":"25/05/28 12:57:45 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:46.028938","level":"info","event":"25/05/28 12:57:46 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:46.029364","level":"info","event":"25/05/28 12:57:46 INFO MetricsSystemImpl: s3a-file-system metrics system started","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:48.460077","level":"info","event":"25/05/28 12:57:48 INFO InMemoryFileIndex: It took 154 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:48.596385","level":"info","event":"25/05/28 12:57:48 INFO InMemoryFileIndex: It took 23 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:52.255901","level":"info","event":"25/05/28 12:57:52 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:52.260254","level":"info","event":"25/05/28 12:57:52 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:52.953697","level":"info","event":"25/05/28 12:57:52 INFO CodeGenerator: Code generated in 286.559085 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.025115","level":"info","event":"25/05/28 12:57:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 211.5 KiB, free 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.357345","level":"info","event":"25/05/28 12:57:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.377222","level":"info","event":"25/05/28 12:57:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42069 (size: 35.3 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.384136","level":"info","event":"25/05/28 12:57:53 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.402281","level":"info","event":"25/05/28 12:57:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7426254 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.605744","level":"info","event":"25/05/28 12:57:53 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.638560","level":"info","event":"25/05/28 12:57:53 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.639324","level":"info","event":"25/05/28 12:57:53 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.640105","level":"info","event":"25/05/28 12:57:53 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.642967","level":"info","event":"25/05/28 12:57:53 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.649653","level":"info","event":"25/05/28 12:57:53 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.759841","level":"info","event":"25/05/28 12:57:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.777356","level":"info","event":"25/05/28 12:57:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.778532","level":"info","event":"25/05/28 12:57:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42069 (size: 6.4 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.779730","level":"info","event":"25/05/28 12:57:53 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.803945","level":"info","event":"25/05/28 12:57:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.806137","level":"info","event":"25/05/28 12:57:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.866453","level":"info","event":"25/05/28 12:57:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (localhost, executor driver, partition 0, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:53.886966","level":"info","event":"25/05/28 12:57:53 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.081728","level":"info","event":"25/05/28 12:57:54 INFO CodeGenerator: Code generated in 19.012493 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.087891","level":"info","event":"25/05/28 12:57:54 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 0-7426254, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.115893","level":"info","event":"25/05/28 12:57:54 INFO CodeGenerator: Code generated in 17.599104 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.287445","level":"info","event":"25/05/28 12:57:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1756 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.346303","level":"info","event":"25/05/28 12:57:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 494 ms on localhost (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.350150","level":"info","event":"25/05/28 12:57:54 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.360932","level":"info","event":"25/05/28 12:57:54 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 0.690 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.367293","level":"info","event":"25/05/28 12:57:54 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.368220","level":"info","event":"25/05/28 12:57:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.373853","level":"info","event":"25/05/28 12:57:54 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 0.767019 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.428859","level":"info","event":"25/05/28 12:57:54 INFO CodeGenerator: Code generated in 25.916927 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.543541","level":"info","event":"25/05/28 12:57:54 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.544656","level":"info","event":"25/05/28 12:57:54 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.558044","level":"info","event":"25/05/28 12:57:54 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 211.5 KiB, free 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.586768","level":"info","event":"25/05/28 12:57:54 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.589057","level":"info","event":"25/05/28 12:57:54 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42069 (size: 35.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.591979","level":"info","event":"25/05/28 12:57:54 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.595903","level":"info","event":"25/05/28 12:57:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7426254 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.793593","level":"info","event":"25/05/28 12:57:54 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.795548","level":"info","event":"25/05/28 12:57:54 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 12 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.795841","level":"info","event":"25/05/28 12:57:54 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.795982","level":"info","event":"25/05/28 12:57:54 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.796382","level":"info","event":"25/05/28 12:57:54 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.797845","level":"info","event":"25/05/28 12:57:54 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.852990","level":"info","event":"25/05/28 12:57:54 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 29.0 KiB, free 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.859853","level":"info","event":"25/05/28 12:57:54 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.862729","level":"info","event":"25/05/28 12:57:54 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:42069 (size: 13.4 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.865715","level":"info","event":"25/05/28 12:57:54 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.871894","level":"info","event":"25/05/28 12:57:54 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.873409","level":"info","event":"25/05/28 12:57:54 INFO TaskSchedulerImpl: Adding task set 1.0 with 12 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.878377","level":"info","event":"25/05/28 12:57:54 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (localhost, executor driver, partition 0, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.882403","level":"info","event":"25/05/28 12:57:54 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (localhost, executor driver, partition 1, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.883782","level":"info","event":"25/05/28 12:57:54 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (localhost, executor driver, partition 2, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.893922","level":"info","event":"25/05/28 12:57:54 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (localhost, executor driver, partition 3, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.897705","level":"info","event":"25/05/28 12:57:54 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (localhost, executor driver, partition 4, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.903576","level":"info","event":"25/05/28 12:57:54 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (localhost, executor driver, partition 5, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.908123","level":"info","event":"25/05/28 12:57:54 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (localhost, executor driver, partition 6, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.915609","level":"info","event":"25/05/28 12:57:54 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (localhost, executor driver, partition 7, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.917907","level":"info","event":"25/05/28 12:57:54 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 9) (localhost, executor driver, partition 8, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.922945","level":"info","event":"25/05/28 12:57:54 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 10) (localhost, executor driver, partition 9, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.925746","level":"info","event":"25/05/28 12:57:54 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 11) (localhost, executor driver, partition 10, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.928323","level":"info","event":"25/05/28 12:57:54 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 12) (localhost, executor driver, partition 11, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.938319","level":"info","event":"25/05/28 12:57:54 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.946740","level":"info","event":"25/05/28 12:57:54 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.948654","level":"info","event":"25/05/28 12:57:54 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.974466","level":"info","event":"25/05/28 12:57:54 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:54.998255","level":"info","event":"25/05/28 12:57:54 INFO Executor: Running task 5.0 in stage 1.0 (TID 6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.000235","level":"info","event":"25/05/28 12:57:54 INFO Executor: Running task 6.0 in stage 1.0 (TID 7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.014859","level":"info","event":"25/05/28 12:57:55 INFO Executor: Running task 4.0 in stage 1.0 (TID 5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.029334","level":"info","event":"25/05/28 12:57:55 INFO Executor: Running task 8.0 in stage 1.0 (TID 9)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.049551","level":"info","event":"25/05/28 12:57:55 INFO Executor: Running task 7.0 in stage 1.0 (TID 8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.060581","level":"info","event":"25/05/28 12:57:55 INFO Executor: Running task 9.0 in stage 1.0 (TID 10)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.070971","level":"info","event":"25/05/28 12:57:55 INFO Executor: Running task 10.0 in stage 1.0 (TID 11)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.107607","level":"info","event":"25/05/28 12:57:55 INFO Executor: Running task 11.0 in stage 1.0 (TID 12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.140107","level":"info","event":"25/05/28 12:57:55 INFO CodeGenerator: Code generated in 39.762734 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.147388","level":"info","event":"25/05/28 12:57:55 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 22278762-29705016, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.147778","level":"info","event":"25/05/28 12:57:55 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 0-7426254, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.154173","level":"info","event":"25/05/28 12:57:55 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 7426254-14852508, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.154456","level":"info","event":"25/05/28 12:57:55 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 14852508-22278762, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.154594","level":"info","event":"25/05/28 12:57:55 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 66836286-74262540, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.154714","level":"info","event":"25/05/28 12:57:55 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 44557524-51983778, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.156712","level":"info","event":"25/05/28 12:57:55 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 51983778-59410032, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.160707","level":"info","event":"25/05/28 12:57:55 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 81688794-84920745, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.160896","level":"info","event":"25/05/28 12:57:55 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 37131270-44557524, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.164571","level":"info","event":"25/05/28 12:57:55 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 59410032-66836286, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.167406","level":"info","event":"25/05/28 12:57:55 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 29705016-37131270, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.167718","level":"info","event":"25/05/28 12:57:55 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 74262540-81688794, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:55.985711","level":"info","event":"25/05/28 12:57:55 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:42069 in memory (size: 6.4 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:57:56.111085","level":"info","event":"25/05/28 12:57:56 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:42069 in memory (size: 35.3 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:00.676129","level":"info","event":"25/05/28 12:58:00 INFO Executor: Finished task 11.0 in stage 1.0 (TID 12). 1653 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:00.694919","level":"info","event":"25/05/28 12:58:00 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 12) in 5767 ms on localhost (executor driver) (1/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:02.394287","level":"info","event":"25/05/28 12:58:02 INFO Executor: Finished task 6.0 in stage 1.0 (TID 7). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:02.432381","level":"info","event":"25/05/28 12:58:02 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 7525 ms on localhost (executor driver) (2/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.050040","level":"info","event":"25/05/28 12:58:03 INFO Executor: Finished task 7.0 in stage 1.0 (TID 8). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.074377","level":"info","event":"25/05/28 12:58:03 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 8160 ms on localhost (executor driver) (3/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.081161","level":"info","event":"25/05/28 12:58:03 INFO Executor: Finished task 4.0 in stage 1.0 (TID 5). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.086018","level":"info","event":"25/05/28 12:58:03 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 8187 ms on localhost (executor driver) (4/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.117428","level":"info","event":"25/05/28 12:58:03 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.122364","level":"info","event":"25/05/28 12:58:03 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 8230 ms on localhost (executor driver) (5/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.141699","level":"info","event":"25/05/28 12:58:03 INFO Executor: Finished task 10.0 in stage 1.0 (TID 11). 1653 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.146412","level":"info","event":"25/05/28 12:58:03 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 11) in 8219 ms on localhost (executor driver) (6/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.160060","level":"info","event":"25/05/28 12:58:03 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.165463","level":"info","event":"25/05/28 12:58:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 8288 ms on localhost (executor driver) (7/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.220574","level":"info","event":"25/05/28 12:58:03 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1653 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.236804","level":"info","event":"25/05/28 12:58:03 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 8357 ms on localhost (executor driver) (8/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.237537","level":"info","event":"25/05/28 12:58:03 INFO Executor: Finished task 5.0 in stage 1.0 (TID 6). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.238028","level":"info","event":"25/05/28 12:58:03 INFO Executor: Finished task 9.0 in stage 1.0 (TID 10). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.241287","level":"info","event":"25/05/28 12:58:03 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 10) in 8319 ms on localhost (executor driver) (9/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.244017","level":"info","event":"25/05/28 12:58:03 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 8343 ms on localhost (executor driver) (10/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.246384","level":"info","event":"25/05/28 12:58:03 INFO Executor: Finished task 8.0 in stage 1.0 (TID 9). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.248741","level":"info","event":"25/05/28 12:58:03 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 9) in 8332 ms on localhost (executor driver) (11/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.248975","level":"info","event":"25/05/28 12:58:03 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.254376","level":"info","event":"25/05/28 12:58:03 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 8372 ms on localhost (executor driver) (12/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.254622","level":"info","event":"25/05/28 12:58:03 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.256861","level":"info","event":"25/05/28 12:58:03 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 8.455 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.259286","level":"info","event":"25/05/28 12:58:03 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.259842","level":"info","event":"25/05/28 12:58:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:03.263922","level":"info","event":"25/05/28 12:58:03 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 8.493903 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.020201","level":"info","event":"25/05/28 12:58:04 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.020890","level":"info","event":"25/05/28 12:58:04 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.377400","level":"info","event":"25/05/28 12:58:04 INFO CodeGenerator: Code generated in 17.139464 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.384308","level":"info","event":"25/05/28 12:58:04 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 211.4 KiB, free 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.400886","level":"info","event":"25/05/28 12:58:04 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.402698","level":"info","event":"25/05/28 12:58:04 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:42069 (size: 35.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.404127","level":"info","event":"25/05/28 12:58:04 INFO SparkContext: Created broadcast 4 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.413764","level":"info","event":"25/05/28 12:58:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7426254 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.456140","level":"info","event":"25/05/28 12:58:04 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.461597","level":"info","event":"25/05/28 12:58:04 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 12 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.461922","level":"info","event":"25/05/28 12:58:04 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.462425","level":"info","event":"25/05/28 12:58:04 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.463556","level":"info","event":"25/05/28 12:58:04 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.465579","level":"info","event":"25/05/28 12:58:04 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.485530","level":"info","event":"25/05/28 12:58:04 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 18.9 KiB, free 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.491362","level":"info","event":"25/05/28 12:58:04 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 1048.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.493854","level":"info","event":"25/05/28 12:58:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:42069 (size: 9.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.495069","level":"info","event":"25/05/28 12:58:04 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.497968","level":"info","event":"25/05/28 12:58:04 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.498341","level":"info","event":"25/05/28 12:58:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 12 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.502382","level":"info","event":"25/05/28 12:58:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 13) (localhost, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.503895","level":"info","event":"25/05/28 12:58:04 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 14) (localhost, executor driver, partition 1, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.504222","level":"info","event":"25/05/28 12:58:04 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 15) (localhost, executor driver, partition 2, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.505391","level":"info","event":"25/05/28 12:58:04 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 16) (localhost, executor driver, partition 3, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.505955","level":"info","event":"25/05/28 12:58:04 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 17) (localhost, executor driver, partition 4, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.509220","level":"info","event":"25/05/28 12:58:04 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 18) (localhost, executor driver, partition 5, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.509904","level":"info","event":"25/05/28 12:58:04 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 19) (localhost, executor driver, partition 6, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.510249","level":"info","event":"25/05/28 12:58:04 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 20) (localhost, executor driver, partition 7, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.511946","level":"info","event":"25/05/28 12:58:04 INFO TaskSetManager: Starting task 8.0 in stage 2.0 (TID 21) (localhost, executor driver, partition 8, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.512914","level":"info","event":"25/05/28 12:58:04 INFO TaskSetManager: Starting task 9.0 in stage 2.0 (TID 22) (localhost, executor driver, partition 9, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.516488","level":"info","event":"25/05/28 12:58:04 INFO TaskSetManager: Starting task 10.0 in stage 2.0 (TID 23) (localhost, executor driver, partition 10, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.517363","level":"info","event":"25/05/28 12:58:04 INFO TaskSetManager: Starting task 11.0 in stage 2.0 (TID 24) (localhost, executor driver, partition 11, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.525567","level":"info","event":"25/05/28 12:58:04 INFO Executor: Running task 1.0 in stage 2.0 (TID 14)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.525823","level":"info","event":"25/05/28 12:58:04 INFO Executor: Running task 2.0 in stage 2.0 (TID 15)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.526394","level":"info","event":"25/05/28 12:58:04 INFO Executor: Running task 4.0 in stage 2.0 (TID 17)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.526787","level":"info","event":"25/05/28 12:58:04 INFO Executor: Running task 3.0 in stage 2.0 (TID 16)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.527179","level":"info","event":"25/05/28 12:58:04 INFO Executor: Running task 5.0 in stage 2.0 (TID 18)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.527543","level":"info","event":"25/05/28 12:58:04 INFO Executor: Running task 10.0 in stage 2.0 (TID 23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.527774","level":"info","event":"25/05/28 12:58:04 INFO Executor: Running task 11.0 in stage 2.0 (TID 24)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.528013","level":"info","event":"25/05/28 12:58:04 INFO Executor: Running task 6.0 in stage 2.0 (TID 19)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.528833","level":"info","event":"25/05/28 12:58:04 INFO Executor: Running task 7.0 in stage 2.0 (TID 20)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.529041","level":"info","event":"25/05/28 12:58:04 INFO Executor: Running task 0.0 in stage 2.0 (TID 13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.529428","level":"info","event":"25/05/28 12:58:04 INFO Executor: Running task 8.0 in stage 2.0 (TID 21)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.529579","level":"info","event":"25/05/28 12:58:04 INFO Executor: Running task 9.0 in stage 2.0 (TID 22)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.574389","level":"info","event":"25/05/28 12:58:04 INFO CodeGenerator: Code generated in 17.911402 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.598499","level":"info","event":"25/05/28 12:58:04 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 22278762-29705016, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.598839","level":"info","event":"25/05/28 12:58:04 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 37131270-44557524, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.601735","level":"info","event":"25/05/28 12:58:04 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 29705016-37131270, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.602408","level":"info","event":"25/05/28 12:58:04 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 14852508-22278762, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.603769","level":"info","event":"25/05/28 12:58:04 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 44557524-51983778, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.604064","level":"info","event":"25/05/28 12:58:04 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 66836286-74262540, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.604234","level":"info","event":"25/05/28 12:58:04 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 74262540-81688794, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.604378","level":"info","event":"25/05/28 12:58:04 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 81688794-84920745, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.606877","level":"info","event":"25/05/28 12:58:04 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 59410032-66836286, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.609620","level":"info","event":"25/05/28 12:58:04 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 51983778-59410032, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.609897","level":"info","event":"25/05/28 12:58:04 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 7426254-14852508, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.612014","level":"info","event":"25/05/28 12:58:04 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 0-7426254, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:04.613618","level":"info","event":"25/05/28 12:58:04 INFO CodeGenerator: Code generated in 12.550083 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.825676","level":"info","event":"25/05/28 12:58:05 INFO Executor: Finished task 4.0 in stage 2.0 (TID 17). 1857 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.825941","level":"info","event":"25/05/28 12:58:05 INFO Executor: Finished task 6.0 in stage 2.0 (TID 19). 1857 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.826064","level":"info","event":"25/05/28 12:58:05 INFO Executor: Finished task 3.0 in stage 2.0 (TID 16). 1857 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.872143","level":"info","event":"25/05/28 12:58:05 INFO Executor: Finished task 1.0 in stage 2.0 (TID 14). 1943 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.893165","level":"info","event":"25/05/28 12:58:05 INFO Executor: Finished task 2.0 in stage 2.0 (TID 15). 1943 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.897477","level":"info","event":"25/05/28 12:58:05 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 17) in 1389 ms on localhost (executor driver) (1/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.908400","level":"info","event":"25/05/28 12:58:05 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 15) in 1404 ms on localhost (executor driver) (2/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.911053","level":"info","event":"25/05/28 12:58:05 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 16) in 1406 ms on localhost (executor driver) (3/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.929546","level":"info","event":"25/05/28 12:58:05 INFO Executor: Finished task 8.0 in stage 2.0 (TID 21). 1900 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.929786","level":"info","event":"25/05/28 12:58:05 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 19) in 1410 ms on localhost (executor driver) (4/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.930088","level":"info","event":"25/05/28 12:58:05 INFO Executor: Finished task 11.0 in stage 2.0 (TID 24). 1900 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.930251","level":"info","event":"25/05/28 12:58:05 INFO TaskSetManager: Finished task 8.0 in stage 2.0 (TID 21) in 1415 ms on localhost (executor driver) (5/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.930378","level":"info","event":"25/05/28 12:58:05 INFO TaskSetManager: Finished task 11.0 in stage 2.0 (TID 24) in 1410 ms on localhost (executor driver) (6/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.930639","level":"info","event":"25/05/28 12:58:05 INFO Executor: Finished task 9.0 in stage 2.0 (TID 22). 1900 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.935682","level":"info","event":"25/05/28 12:58:05 INFO TaskSetManager: Finished task 9.0 in stage 2.0 (TID 22) in 1422 ms on localhost (executor driver) (7/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.942817","level":"info","event":"25/05/28 12:58:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 13). 1900 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.948742","level":"info","event":"25/05/28 12:58:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 13) in 1448 ms on localhost (executor driver) (8/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.956546","level":"info","event":"25/05/28 12:58:05 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 14) in 1453 ms on localhost (executor driver) (9/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.962862","level":"info","event":"25/05/28 12:58:05 INFO Executor: Finished task 10.0 in stage 2.0 (TID 23). 1900 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.963070","level":"info","event":"25/05/28 12:58:05 INFO Executor: Finished task 7.0 in stage 2.0 (TID 20). 1900 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.965684","level":"info","event":"25/05/28 12:58:05 INFO TaskSetManager: Finished task 10.0 in stage 2.0 (TID 23) in 1449 ms on localhost (executor driver) (10/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.969798","level":"info","event":"25/05/28 12:58:05 INFO TaskSetManager: Finished task 7.0 in stage 2.0 (TID 20) in 1459 ms on localhost (executor driver) (11/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.972215","level":"info","event":"25/05/28 12:58:05 INFO Executor: Finished task 5.0 in stage 2.0 (TID 18). 1900 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.977061","level":"info","event":"25/05/28 12:58:05 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 18) in 1467 ms on localhost (executor driver) (12/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.977284","level":"info","event":"25/05/28 12:58:05 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.979635","level":"info","event":"25/05/28 12:58:05 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 1.510 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.982338","level":"info","event":"25/05/28 12:58:05 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.984866","level":"info","event":"25/05/28 12:58:05 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.985458","level":"info","event":"25/05/28 12:58:05 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:05.988355","level":"info","event":"25/05/28 12:58:05 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.098025","level":"info","event":"25/05/28 12:58:06 INFO CodeGenerator: Code generated in 56.77329 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.343656","level":"info","event":"25/05/28 12:58:06 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.408079","level":"info","event":"25/05/28 12:58:06 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.408298","level":"info","event":"25/05/28 12:58:06 INFO DAGScheduler: Final stage: ResultStage 4 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.408454","level":"info","event":"25/05/28 12:58:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.408574","level":"info","event":"25/05/28 12:58:06 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.408672","level":"info","event":"25/05/28 12:58:06 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.408791","level":"info","event":"25/05/28 12:58:06 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 12.5 KiB, free 1048.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.455394","level":"info","event":"25/05/28 12:58:06 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 1048.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.455688","level":"info","event":"25/05/28 12:58:06 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:42069 (size: 5.9 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.455961","level":"info","event":"25/05/28 12:58:06 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.456073","level":"info","event":"25/05/28 12:58:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.456174","level":"info","event":"25/05/28 12:58:06 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.487393","level":"info","event":"25/05/28 12:58:06 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 25) (localhost, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.487594","level":"info","event":"25/05/28 12:58:06 INFO Executor: Running task 0.0 in stage 4.0 (TID 25)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.633326","level":"info","event":"25/05/28 12:58:06 INFO ShuffleBlockFetcherIterator: Getting 12 (720.0 B) non-empty blocks including 12 (720.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.637659","level":"info","event":"25/05/28 12:58:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 48 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.785747","level":"info","event":"25/05/28 12:58:06 INFO CodeGenerator: Code generated in 105.436268 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.858036","level":"info","event":"25/05/28 12:58:06 INFO Executor: Finished task 0.0 in stage 4.0 (TID 25). 3808 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.862753","level":"info","event":"25/05/28 12:58:06 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 25) in 401 ms on localhost (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.863005","level":"info","event":"25/05/28 12:58:06 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.873517","level":"info","event":"25/05/28 12:58:06 INFO DAGScheduler: ResultStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.488 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.875035","level":"info","event":"25/05/28 12:58:06 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.875446","level":"info","event":"25/05/28 12:58:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.886541","level":"info","event":"25/05/28 12:58:06 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.533909 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:06.904281","level":"info","event":"Total records: 302010","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.180253","level":"info","event":"25/05/28 12:58:08 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.180555","level":"info","event":"25/05/28 12:58:08 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.449050","level":"info","event":"25/05/28 12:58:08 INFO CodeGenerator: Code generated in 148.262745 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.463786","level":"info","event":"25/05/28 12:58:08 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 211.4 KiB, free 1048.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.494373","level":"info","event":"25/05/28 12:58:08 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1048.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.496312","level":"info","event":"25/05/28 12:58:08 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:42069 (size: 35.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.501208","level":"info","event":"25/05/28 12:58:08 INFO SparkContext: Created broadcast 7 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.504874","level":"info","event":"25/05/28 12:58:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7426254 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.560724","level":"info","event":"25/05/28 12:58:08 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.561100","level":"info","event":"25/05/28 12:58:08 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 12 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.561273","level":"info","event":"25/05/28 12:58:08 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.561414","level":"info","event":"25/05/28 12:58:08 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.561551","level":"info","event":"25/05/28 12:58:08 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.562129","level":"info","event":"25/05/28 12:58:08 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.572736","level":"info","event":"25/05/28 12:58:08 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 39.4 KiB, free 1048.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.616079","level":"info","event":"25/05/28 12:58:08 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 18.5 KiB, free 1047.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.622746","level":"info","event":"25/05/28 12:58:08 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:42069 (size: 18.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.622984","level":"info","event":"25/05/28 12:58:08 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:42069 in memory (size: 9.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.623188","level":"info","event":"25/05/28 12:58:08 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.625158","level":"info","event":"25/05/28 12:58:08 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.639581","level":"info","event":"25/05/28 12:58:08 INFO TaskSchedulerImpl: Adding task set 5.0 with 12 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.639857","level":"info","event":"25/05/28 12:58:08 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 26) (localhost, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.640012","level":"info","event":"25/05/28 12:58:08 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 27) (localhost, executor driver, partition 1, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.640140","level":"info","event":"25/05/28 12:58:08 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 28) (localhost, executor driver, partition 2, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.640258","level":"info","event":"25/05/28 12:58:08 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 29) (localhost, executor driver, partition 3, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.640374","level":"info","event":"25/05/28 12:58:08 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 30) (localhost, executor driver, partition 4, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.640480","level":"info","event":"25/05/28 12:58:08 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 31) (localhost, executor driver, partition 5, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.640584","level":"info","event":"25/05/28 12:58:08 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 32) (localhost, executor driver, partition 6, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.640685","level":"info","event":"25/05/28 12:58:08 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 33) (localhost, executor driver, partition 7, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.640828","level":"info","event":"25/05/28 12:58:08 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 34) (localhost, executor driver, partition 8, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.640944","level":"info","event":"25/05/28 12:58:08 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 35) (localhost, executor driver, partition 9, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.641047","level":"info","event":"25/05/28 12:58:08 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 36) (localhost, executor driver, partition 10, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.641148","level":"info","event":"25/05/28 12:58:08 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 37) (localhost, executor driver, partition 11, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.641271","level":"info","event":"25/05/28 12:58:08 INFO Executor: Running task 1.0 in stage 5.0 (TID 27)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.641364","level":"info","event":"25/05/28 12:58:08 INFO Executor: Running task 0.0 in stage 5.0 (TID 26)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.649915","level":"info","event":"25/05/28 12:58:08 INFO Executor: Running task 3.0 in stage 5.0 (TID 29)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.650901","level":"info","event":"25/05/28 12:58:08 INFO Executor: Running task 6.0 in stage 5.0 (TID 32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.651176","level":"info","event":"25/05/28 12:58:08 INFO Executor: Running task 2.0 in stage 5.0 (TID 28)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.651469","level":"info","event":"25/05/28 12:58:08 INFO Executor: Running task 4.0 in stage 5.0 (TID 30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.651621","level":"info","event":"25/05/28 12:58:08 INFO Executor: Running task 5.0 in stage 5.0 (TID 31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.652467","level":"info","event":"25/05/28 12:58:08 INFO Executor: Running task 7.0 in stage 5.0 (TID 33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.652707","level":"info","event":"25/05/28 12:58:08 INFO Executor: Running task 8.0 in stage 5.0 (TID 34)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.666986","level":"info","event":"25/05/28 12:58:08 INFO Executor: Running task 9.0 in stage 5.0 (TID 35)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.668542","level":"info","event":"25/05/28 12:58:08 INFO Executor: Running task 10.0 in stage 5.0 (TID 36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.680324","level":"info","event":"25/05/28 12:58:08 INFO Executor: Running task 11.0 in stage 5.0 (TID 37)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.691448","level":"info","event":"25/05/28 12:58:08 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:42069 in memory (size: 35.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.729829","level":"info","event":"25/05/28 12:58:08 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:42069 in memory (size: 5.9 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.752303","level":"info","event":"25/05/28 12:58:08 INFO CodeGenerator: Code generated in 92.858616 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.871361","level":"info","event":"25/05/28 12:58:08 INFO CodeGenerator: Code generated in 107.740864 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.985827","level":"info","event":"25/05/28 12:58:08 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 81688794-84920745, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:08.986148","level":"info","event":"25/05/28 12:58:08 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 44557524-51983778, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:09.029636","level":"info","event":"25/05/28 12:58:09 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 59410032-66836286, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:09.032583","level":"info","event":"25/05/28 12:58:09 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 7426254-14852508, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:09.033253","level":"info","event":"25/05/28 12:58:09 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 74262540-81688794, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:09.041630","level":"info","event":"25/05/28 12:58:08 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 22278762-29705016, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:09.046472","level":"info","event":"25/05/28 12:58:08 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 29705016-37131270, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:09.046662","level":"info","event":"25/05/28 12:58:08 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 37131270-44557524, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:09.046799","level":"info","event":"25/05/28 12:58:09 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 51983778-59410032, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:09.063911","level":"info","event":"25/05/28 12:58:09 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 66836286-74262540, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:09.069240","level":"info","event":"25/05/28 12:58:09 INFO CodeGenerator: Code generated in 47.346117 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:09.083859","level":"info","event":"25/05/28 12:58:09 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 0-7426254, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:09.084176","level":"info","event":"25/05/28 12:58:09 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 14852508-22278762, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:09.141094","level":"info","event":"25/05/28 12:58:09 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:42069 in memory (size: 13.4 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:09.221941","level":"info","event":"25/05/28 12:58:09 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:42069 in memory (size: 35.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:16.860039","level":"info","event":"25/05/28 12:58:16 INFO Executor: Finished task 7.0 in stage 5.0 (TID 33). 2735 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:16.860497","level":"info","event":"25/05/28 12:58:16 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 33) in 8219 ms on localhost (executor driver) (1/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:16.863069","level":"info","event":"25/05/28 12:58:16 INFO Executor: Finished task 10.0 in stage 5.0 (TID 36). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:16.865771","level":"info","event":"25/05/28 12:58:16 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 36) in 8227 ms on localhost (executor driver) (2/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.033208","level":"info","event":"25/05/28 12:58:17 INFO Executor: Finished task 8.0 in stage 5.0 (TID 34). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.039393","level":"info","event":"25/05/28 12:58:17 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 34) in 8397 ms on localhost (executor driver) (3/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.039640","level":"info","event":"25/05/28 12:58:17 INFO Executor: Finished task 3.0 in stage 5.0 (TID 29). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.041292","level":"info","event":"25/05/28 12:58:17 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 29) in 8406 ms on localhost (executor driver) (4/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.092094","level":"info","event":"25/05/28 12:58:17 INFO Executor: Finished task 4.0 in stage 5.0 (TID 30). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.094127","level":"info","event":"25/05/28 12:58:17 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 30) in 8458 ms on localhost (executor driver) (5/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.128808","level":"info","event":"25/05/28 12:58:17 INFO Executor: Finished task 6.0 in stage 5.0 (TID 32). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.132259","level":"info","event":"25/05/28 12:58:17 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 32) in 8495 ms on localhost (executor driver) (6/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.152333","level":"info","event":"25/05/28 12:58:17 INFO Executor: Finished task 9.0 in stage 5.0 (TID 35). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.153919","level":"info","event":"25/05/28 12:58:17 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 35) in 8516 ms on localhost (executor driver) (7/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.179787","level":"info","event":"25/05/28 12:58:17 INFO Executor: Finished task 11.0 in stage 5.0 (TID 37). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.181610","level":"info","event":"25/05/28 12:58:17 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 37) in 8542 ms on localhost (executor driver) (8/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.196390","level":"info","event":"25/05/28 12:58:17 INFO Executor: Finished task 0.0 in stage 5.0 (TID 26). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.198104","level":"info","event":"25/05/28 12:58:17 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 26) in 8570 ms on localhost (executor driver) (9/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.206767","level":"info","event":"25/05/28 12:58:17 INFO Executor: Finished task 1.0 in stage 5.0 (TID 27). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.207003","level":"info","event":"25/05/28 12:58:17 INFO Executor: Finished task 2.0 in stage 5.0 (TID 28). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.207306","level":"info","event":"25/05/28 12:58:17 INFO Executor: Finished task 5.0 in stage 5.0 (TID 31). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.207953","level":"info","event":"25/05/28 12:58:17 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 27) in 8577 ms on localhost (executor driver) (10/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.209545","level":"info","event":"25/05/28 12:58:17 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 31) in 8573 ms on localhost (executor driver) (11/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.209746","level":"info","event":"25/05/28 12:58:17 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 28) in 8576 ms on localhost (executor driver) (12/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.210153","level":"info","event":"25/05/28 12:58:17 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.210489","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 8.645 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.210695","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.210842","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.210976","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.211124","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.243044","level":"info","event":"25/05/28 12:58:17 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.354683","level":"info","event":"25/05/28 12:58:17 INFO CodeGenerator: Code generated in 58.077578 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.402139","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: Registering RDD 23 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.402553","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.402714","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.402894","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.403106","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.403976","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.433821","level":"info","event":"25/05/28 12:58:17 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 49.2 KiB, free 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.436924","level":"info","event":"25/05/28 12:58:17 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 22.7 KiB, free 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.438188","level":"info","event":"25/05/28 12:58:17 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:42069 (size: 22.7 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.444762","level":"info","event":"25/05/28 12:58:17 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.452070","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.452890","level":"info","event":"25/05/28 12:58:17 INFO TaskSchedulerImpl: Adding task set 7.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.454213","level":"info","event":"25/05/28 12:58:17 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 38) (localhost, executor driver, partition 0, NODE_LOCAL, 7604 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.454940","level":"info","event":"25/05/28 12:58:17 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 39) (localhost, executor driver, partition 1, NODE_LOCAL, 7604 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.456412","level":"info","event":"25/05/28 12:58:17 INFO Executor: Running task 1.0 in stage 7.0 (TID 39)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.456653","level":"info","event":"25/05/28 12:58:17 INFO Executor: Running task 0.0 in stage 7.0 (TID 38)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.481713","level":"info","event":"25/05/28 12:58:17 INFO ShuffleBlockFetcherIterator: Getting 12 (1034.6 KiB) non-empty blocks including 12 (1034.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.482117","level":"info","event":"25/05/28 12:58:17 INFO ShuffleBlockFetcherIterator: Getting 12 (1143.1 KiB) non-empty blocks including 12 (1143.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:58:17.482401","level":"info","event":"25/05/28 12:58:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.522792","level":"info","event":"25/05/28 12:58:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.523910","level":"info","event":"25/05/28 12:58:17 INFO CodeGenerator: Code generated in 41.845193 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.524177","level":"info","event":"25/05/28 12:58:17 INFO Executor: Finished task 0.0 in stage 7.0 (TID 38). 5524 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.524340","level":"info","event":"25/05/28 12:58:17 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 38) in 416 ms on localhost (executor driver) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.524480","level":"info","event":"25/05/28 12:58:17 INFO Executor: Finished task 1.0 in stage 7.0 (TID 39). 5524 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.524611","level":"info","event":"25/05/28 12:58:17 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 39) in 418 ms on localhost (executor driver) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.524764","level":"info","event":"25/05/28 12:58:17 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.524893","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.446 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.525006","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.525149","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.525267","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.525387","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.525505","level":"info","event":"25/05/28 12:58:17 INFO CodeGenerator: Code generated in 13.9303 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.525619","level":"info","event":"25/05/28 12:58:17 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.525740","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: Got job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.525851","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: Final stage: ResultStage 10 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.525959","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.526094","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.526210","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.526323","level":"info","event":"25/05/28 12:58:17 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 12.5 KiB, free 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.526435","level":"info","event":"25/05/28 12:58:17 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.526546","level":"info","event":"25/05/28 12:58:17 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:42069 (size: 5.9 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.526668","level":"info","event":"25/05/28 12:58:17 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.526795","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.526917","level":"info","event":"25/05/28 12:58:17 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.527064","level":"info","event":"25/05/28 12:58:17 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 40) (localhost, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.527191","level":"info","event":"25/05/28 12:58:17 INFO Executor: Running task 0.0 in stage 10.0 (TID 40)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.527304","level":"info","event":"25/05/28 12:58:17 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.527415","level":"info","event":"25/05/28 12:58:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.527527","level":"info","event":"25/05/28 12:58:17 INFO CodeGenerator: Code generated in 12.288353 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.527648","level":"info","event":"25/05/28 12:58:17 INFO Executor: Finished task 0.0 in stage 10.0 (TID 40). 3808 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.527770","level":"info","event":"25/05/28 12:58:17 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 40) in 28 ms on localhost (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.527890","level":"info","event":"25/05/28 12:58:17 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.528028","level":"info","event":"25/05/28 12:58:17 INFO DAGScheduler: ResultStage 10 (count at NativeMethodAccessorImpl.java:0) finished in 0.044 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.528162","level":"info","event":"25/05/28 12:58:18 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.528286","level":"info","event":"25/05/28 12:58:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.528398","level":"info","event":"25/05/28 12:58:18 INFO DAGScheduler: Job 6 finished: count at NativeMethodAccessorImpl.java:0, took 0.049614 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.528514","level":"info","event":"Unique customers: 86767","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.528635","level":"info","event":"Writing customer data to S3...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.528755","level":"info","event":"25/05/28 12:58:18 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.528876","level":"info","event":"25/05/28 12:58:18 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.528997","level":"info","event":"25/05/28 12:58:18 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.529149","level":"info","event":"25/05/28 12:58:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(cast(Customer_ID#458 as string))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.529264","level":"info","event":"25/05/28 12:58:18 INFO CodeGenerator: Code generated in 40.323235 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.529404","level":"info","event":"25/05/28 12:58:18 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 211.4 KiB, free 1048.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.529523","level":"info","event":"25/05/28 12:58:18 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1048.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.529641","level":"info","event":"25/05/28 12:58:18 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:42069 (size: 35.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.529762","level":"info","event":"25/05/28 12:58:18 INFO SparkContext: Created broadcast 11 from parquet at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.529881","level":"info","event":"25/05/28 12:58:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7426254 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.530023","level":"info","event":"25/05/28 12:58:19 INFO DAGScheduler: Registering RDD 31 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.530154","level":"info","event":"25/05/28 12:58:19 INFO DAGScheduler: Got map stage job 7 (parquet at NativeMethodAccessorImpl.java:0) with 12 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.530275","level":"info","event":"25/05/28 12:58:19 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (parquet at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.530395","level":"info","event":"25/05/28 12:58:19 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.530515","level":"info","event":"25/05/28 12:58:19 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.530638","level":"info","event":"25/05/28 12:58:19 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[31] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.530761","level":"info","event":"25/05/28 12:58:19 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 45.4 KiB, free 1048.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.530899","level":"info","event":"25/05/28 12:58:19 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 1048.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.531068","level":"info","event":"25/05/28 12:58:19 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:42069 (size: 19.4 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.531209","level":"info","event":"25/05/28 12:58:19 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.531365","level":"info","event":"25/05/28 12:58:19 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[31] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.531632","level":"info","event":"25/05/28 12:58:19 INFO TaskSchedulerImpl: Adding task set 11.0 with 12 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.531770","level":"info","event":"25/05/28 12:58:19 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 41) (localhost, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.531992","level":"info","event":"25/05/28 12:58:19 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 42) (localhost, executor driver, partition 1, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.532265","level":"info","event":"25/05/28 12:58:19 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 43) (localhost, executor driver, partition 2, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.532383","level":"info","event":"25/05/28 12:58:19 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 44) (localhost, executor driver, partition 3, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.532492","level":"info","event":"25/05/28 12:58:19 INFO TaskSetManager: Starting task 4.0 in stage 11.0 (TID 45) (localhost, executor driver, partition 4, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.532597","level":"info","event":"25/05/28 12:58:19 INFO TaskSetManager: Starting task 5.0 in stage 11.0 (TID 46) (localhost, executor driver, partition 5, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.532818","level":"info","event":"25/05/28 12:58:19 INFO TaskSetManager: Starting task 6.0 in stage 11.0 (TID 47) (localhost, executor driver, partition 6, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.533067","level":"info","event":"25/05/28 12:58:19 INFO TaskSetManager: Starting task 7.0 in stage 11.0 (TID 48) (localhost, executor driver, partition 7, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.533211","level":"info","event":"25/05/28 12:58:19 INFO TaskSetManager: Starting task 8.0 in stage 11.0 (TID 49) (localhost, executor driver, partition 8, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.533323","level":"info","event":"25/05/28 12:58:19 INFO TaskSetManager: Starting task 9.0 in stage 11.0 (TID 50) (localhost, executor driver, partition 9, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.533425","level":"info","event":"25/05/28 12:58:19 INFO TaskSetManager: Starting task 10.0 in stage 11.0 (TID 51) (localhost, executor driver, partition 10, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.533669","level":"info","event":"25/05/28 12:58:19 INFO TaskSetManager: Starting task 11.0 in stage 11.0 (TID 52) (localhost, executor driver, partition 11, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.533867","level":"info","event":"25/05/28 12:58:19 INFO Executor: Running task 2.0 in stage 11.0 (TID 43)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.534065","level":"info","event":"25/05/28 12:58:19 INFO Executor: Running task 0.0 in stage 11.0 (TID 41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.534162","level":"info","event":"25/05/28 12:58:19 INFO Executor: Running task 6.0 in stage 11.0 (TID 47)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.534236","level":"info","event":"25/05/28 12:58:19 INFO Executor: Running task 8.0 in stage 11.0 (TID 49)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.534310","level":"info","event":"25/05/28 12:58:19 INFO Executor: Running task 5.0 in stage 11.0 (TID 46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.534513","level":"info","event":"25/05/28 12:58:19 INFO Executor: Running task 4.0 in stage 11.0 (TID 45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.534820","level":"info","event":"25/05/28 12:58:19 INFO Executor: Running task 9.0 in stage 11.0 (TID 50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.535239","level":"info","event":"25/05/28 12:58:19 INFO Executor: Running task 11.0 in stage 11.0 (TID 52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.535443","level":"info","event":"25/05/28 12:58:19 INFO Executor: Running task 10.0 in stage 11.0 (TID 51)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.535568","level":"info","event":"25/05/28 12:58:19 INFO Executor: Running task 3.0 in stage 11.0 (TID 44)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.535706","level":"info","event":"25/05/28 12:58:19 INFO Executor: Running task 1.0 in stage 11.0 (TID 42)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.535896","level":"info","event":"25/05/28 12:58:19 INFO Executor: Running task 7.0 in stage 11.0 (TID 48)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.536050","level":"info","event":"25/05/28 12:58:19 INFO CodeGenerator: Code generated in 66.103029 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.536183","level":"info","event":"25/05/28 12:58:19 INFO CodeGenerator: Code generated in 22.445804 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.536319","level":"info","event":"25/05/28 12:58:19 INFO CodeGenerator: Code generated in 128.00905 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.536455","level":"info","event":"25/05/28 12:58:19 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 211.4 KiB, free 1047.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.536572","level":"info","event":"25/05/28 12:58:19 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1047.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.536684","level":"info","event":"25/05/28 12:58:19 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:42069 (size: 35.3 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.536784","level":"info","event":"25/05/28 12:58:19 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.537102","level":"info","event":"25/05/28 12:58:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7426254 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.537233","level":"info","event":"25/05/28 12:58:19 INFO CodeGenerator: Code generated in 23.253129 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.537341","level":"info","event":"25/05/28 12:58:19 INFO DAGScheduler: Registering RDD 35 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.537439","level":"info","event":"25/05/28 12:58:19 INFO DAGScheduler: Got map stage job 8 (parquet at NativeMethodAccessorImpl.java:0) with 12 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.537528","level":"info","event":"25/05/28 12:58:19 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (parquet at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.537759","level":"info","event":"25/05/28 12:58:19 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.537843","level":"info","event":"25/05/28 12:58:19 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.537928","level":"info","event":"25/05/28 12:58:19 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[35] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.538042","level":"info","event":"25/05/28 12:58:19 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 51.3 KiB, free 1047.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.538279","level":"info","event":"25/05/28 12:58:19 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.7 KiB, free 1047.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.538434","level":"info","event":"25/05/28 12:58:19 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:42069 (size: 22.7 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.538551","level":"info","event":"25/05/28 12:58:19 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.538653","level":"info","event":"25/05/28 12:58:19 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[35] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.538917","level":"info","event":"25/05/28 12:58:19 INFO TaskSchedulerImpl: Adding task set 12.0 with 12 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.539118","level":"info","event":"25/05/28 12:58:19 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 51983778-59410032, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.539252","level":"info","event":"25/05/28 12:58:19 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 59410032-66836286, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.539531","level":"info","event":"25/05/28 12:58:19 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 29705016-37131270, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.539669","level":"info","event":"25/05/28 12:58:19 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 22278762-29705016, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.539843","level":"info","event":"25/05/28 12:58:19 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 0-7426254, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.540020","level":"info","event":"25/05/28 12:58:19 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 66836286-74262540, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.540532","level":"info","event":"25/05/28 12:58:19 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 74262540-81688794, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.540832","level":"info","event":"25/05/28 12:58:19 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 14852508-22278762, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.541108","level":"info","event":"25/05/28 12:58:19 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 7426254-14852508, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.541239","level":"info","event":"25/05/28 12:58:19 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 81688794-84920745, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.541344","level":"info","event":"25/05/28 12:58:19 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 37131270-44557524, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.541458","level":"info","event":"25/05/28 12:58:19 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 44557524-51983778, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.541669","level":"info","event":"25/05/28 12:58:19 INFO CodeGenerator: Code generated in 32.411174 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.541801","level":"info","event":"25/05/28 12:58:23 INFO CodeGenerator: Code generated in 25.105156 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.541896","level":"info","event":"25/05/28 12:58:23 INFO CodeGenerator: Code generated in 39.858767 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.541990","level":"info","event":"25/05/28 12:58:23 INFO CodeGenerator: Code generated in 28.921563 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.542122","level":"info","event":"25/05/28 12:58:24 INFO Executor: Finished task 8.0 in stage 11.0 (TID 49). 2499 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.542312","level":"info","event":"25/05/28 12:58:24 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 53) (localhost, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.542505","level":"info","event":"25/05/28 12:58:24 INFO TaskSetManager: Finished task 8.0 in stage 11.0 (TID 49) in 5786 ms on localhost (executor driver) (1/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.542619","level":"info","event":"25/05/28 12:58:24 INFO Executor: Running task 0.0 in stage 12.0 (TID 53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.542742","level":"info","event":"25/05/28 12:58:50 INFO CodeGenerator: Code generated in 22257.1282 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.542860","level":"info","event":"25/05/28 12:58:50 INFO CodeGenerator: Code generated in 6.875712 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.543027","level":"info","event":"25/05/28 12:58:50 INFO CodeGenerator: Code generated in 9.425328 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.543150","level":"info","event":"25/05/28 12:58:50 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 0-7426254, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:08.543253","level":"info","event":"25/05/28 12:58:50 INFO CodeGenerator: Code generated in 12.79918 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:11.020922","level":"info","event":"25/05/28 12:59:11 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:42069 in memory (size: 22.7 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:11.049049","level":"info","event":"25/05/28 12:59:11 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:42069 in memory (size: 5.9 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:12.411571","level":"info","event":"25/05/28 12:59:12 INFO Executor: Finished task 11.0 in stage 11.0 (TID 52). 2542 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:12.497373","level":"info","event":"25/05/28 12:59:12 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 54) (localhost, executor driver, partition 1, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:12.498246","level":"info","event":"25/05/28 12:59:12 INFO Executor: Running task 1.0 in stage 12.0 (TID 54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:12.503125","level":"info","event":"25/05/28 12:59:12 INFO TaskSetManager: Finished task 11.0 in stage 11.0 (TID 52) in 53423 ms on localhost (executor driver) (2/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:12.558763","level":"info","event":"25/05/28 12:59:12 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 7426254-14852508, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:12.883626","level":"info","event":"25/05/28 12:59:12 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:42069 in memory (size: 35.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:12.905084","level":"info","event":"25/05/28 12:59:12 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:42069 in memory (size: 18.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:13.075155","level":"info","event":"25/05/28 12:59:13 INFO Executor: Finished task 3.0 in stage 11.0 (TID 44). 2542 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:13.076761","level":"info","event":"25/05/28 12:59:13 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 55) (localhost, executor driver, partition 2, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:13.077629","level":"info","event":"25/05/28 12:59:13 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 44) in 54006 ms on localhost (executor driver) (3/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:13.077859","level":"info","event":"25/05/28 12:59:13 INFO Executor: Running task 2.0 in stage 12.0 (TID 55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:13.194672","level":"info","event":"25/05/28 12:59:13 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 14852508-22278762, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:13.598718","level":"info","event":"25/05/28 12:59:13 INFO Executor: Finished task 1.0 in stage 11.0 (TID 42). 2499 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:13.606414","level":"info","event":"25/05/28 12:59:13 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 56) (localhost, executor driver, partition 3, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:13.608323","level":"info","event":"25/05/28 12:59:13 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 42) in 54536 ms on localhost (executor driver) (4/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:13.610261","level":"info","event":"25/05/28 12:59:13 INFO Executor: Running task 3.0 in stage 12.0 (TID 56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:13.660275","level":"info","event":"25/05/28 12:59:13 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 22278762-29705016, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.339966","level":"info","event":"25/05/28 12:59:14 INFO Executor: Finished task 1.0 in stage 12.0 (TID 54). 2791 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.342098","level":"info","event":"25/05/28 12:59:14 INFO TaskSetManager: Starting task 4.0 in stage 12.0 (TID 57) (localhost, executor driver, partition 4, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.342818","level":"info","event":"25/05/28 12:59:14 INFO Executor: Running task 4.0 in stage 12.0 (TID 57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.343137","level":"info","event":"25/05/28 12:59:14 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 54) in 1858 ms on localhost (executor driver) (1/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.368053","level":"info","event":"25/05/28 12:59:14 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 29705016-37131270, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.441494","level":"info","event":"25/05/28 12:59:14 INFO Executor: Finished task 6.0 in stage 11.0 (TID 47). 2499 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.445094","level":"info","event":"25/05/28 12:59:14 INFO TaskSetManager: Starting task 5.0 in stage 12.0 (TID 58) (localhost, executor driver, partition 5, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.445342","level":"info","event":"25/05/28 12:59:14 INFO TaskSetManager: Finished task 6.0 in stage 11.0 (TID 47) in 55371 ms on localhost (executor driver) (5/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.450663","level":"info","event":"25/05/28 12:59:14 INFO Executor: Running task 5.0 in stage 12.0 (TID 58)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.495744","level":"info","event":"25/05/28 12:59:14 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 37131270-44557524, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.566085","level":"info","event":"25/05/28 12:59:14 INFO Executor: Finished task 3.0 in stage 12.0 (TID 56). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.568134","level":"info","event":"25/05/28 12:59:14 INFO TaskSetManager: Starting task 6.0 in stage 12.0 (TID 59) (localhost, executor driver, partition 6, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.570310","level":"info","event":"25/05/28 12:59:14 INFO Executor: Running task 6.0 in stage 12.0 (TID 59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.570566","level":"info","event":"25/05/28 12:59:14 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 56) in 968 ms on localhost (executor driver) (2/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.598575","level":"info","event":"25/05/28 12:59:14 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 44557524-51983778, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.598886","level":"info","event":"25/05/28 12:59:14 INFO Executor: Finished task 2.0 in stage 12.0 (TID 55). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.603531","level":"info","event":"25/05/28 12:59:14 INFO TaskSetManager: Starting task 7.0 in stage 12.0 (TID 60) (localhost, executor driver, partition 7, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.603892","level":"info","event":"25/05/28 12:59:14 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 55) in 1525 ms on localhost (executor driver) (3/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.604040","level":"info","event":"25/05/28 12:59:14 INFO Executor: Running task 7.0 in stage 12.0 (TID 60)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.631432","level":"info","event":"25/05/28 12:59:14 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 51983778-59410032, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.861547","level":"info","event":"25/05/28 12:59:14 INFO Executor: Finished task 4.0 in stage 12.0 (TID 57). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.869864","level":"info","event":"25/05/28 12:59:14 INFO TaskSetManager: Starting task 8.0 in stage 12.0 (TID 61) (localhost, executor driver, partition 8, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.870186","level":"info","event":"25/05/28 12:59:14 INFO Executor: Running task 8.0 in stage 12.0 (TID 61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.870342","level":"info","event":"25/05/28 12:59:14 INFO TaskSetManager: Finished task 4.0 in stage 12.0 (TID 57) in 524 ms on localhost (executor driver) (4/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.873773","level":"info","event":"25/05/28 12:59:14 INFO Executor: Finished task 5.0 in stage 11.0 (TID 46). 2542 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.892541","level":"info","event":"25/05/28 12:59:14 INFO TaskSetManager: Starting task 9.0 in stage 12.0 (TID 62) (localhost, executor driver, partition 9, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.892792","level":"info","event":"25/05/28 12:59:14 INFO TaskSetManager: Finished task 5.0 in stage 11.0 (TID 46) in 55819 ms on localhost (executor driver) (6/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.893525","level":"info","event":"25/05/28 12:59:14 INFO Executor: Running task 9.0 in stage 12.0 (TID 62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.931559","level":"info","event":"25/05/28 12:59:14 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 59410032-66836286, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:14.935083","level":"info","event":"25/05/28 12:59:14 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 66836286-74262540, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.113646","level":"info","event":"25/05/28 12:59:15 INFO Executor: Finished task 6.0 in stage 12.0 (TID 59). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.117041","level":"info","event":"25/05/28 12:59:15 INFO TaskSetManager: Starting task 10.0 in stage 12.0 (TID 63) (localhost, executor driver, partition 10, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.117348","level":"info","event":"25/05/28 12:59:15 INFO TaskSetManager: Finished task 6.0 in stage 12.0 (TID 59) in 549 ms on localhost (executor driver) (5/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.118867","level":"info","event":"25/05/28 12:59:15 INFO Executor: Running task 10.0 in stage 12.0 (TID 63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.140101","level":"info","event":"25/05/28 12:59:15 INFO Executor: Finished task 5.0 in stage 12.0 (TID 58). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.144480","level":"info","event":"25/05/28 12:59:15 INFO TaskSetManager: Starting task 11.0 in stage 12.0 (TID 64) (localhost, executor driver, partition 11, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.144748","level":"info","event":"25/05/28 12:59:15 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 74262540-81688794, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.145074","level":"info","event":"25/05/28 12:59:15 INFO Executor: Running task 11.0 in stage 12.0 (TID 64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.145219","level":"info","event":"25/05/28 12:59:15 INFO TaskSetManager: Finished task 5.0 in stage 12.0 (TID 58) in 702 ms on localhost (executor driver) (6/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.174685","level":"info","event":"25/05/28 12:59:15 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 81688794-84920745, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.182509","level":"info","event":"25/05/28 12:59:15 INFO Executor: Finished task 7.0 in stage 12.0 (TID 60). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.191762","level":"info","event":"25/05/28 12:59:15 INFO TaskSetManager: Finished task 7.0 in stage 12.0 (TID 60) in 592 ms on localhost (executor driver) (7/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.234718","level":"info","event":"25/05/28 12:59:15 INFO Executor: Finished task 0.0 in stage 12.0 (TID 53). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.238382","level":"info","event":"25/05/28 12:59:15 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 53) in 50395 ms on localhost (executor driver) (8/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.409486","level":"info","event":"25/05/28 12:59:15 INFO Executor: Finished task 9.0 in stage 12.0 (TID 62). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.411042","level":"info","event":"25/05/28 12:59:15 INFO TaskSetManager: Finished task 9.0 in stage 12.0 (TID 62) in 521 ms on localhost (executor driver) (9/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.419934","level":"info","event":"25/05/28 12:59:15 INFO Executor: Finished task 8.0 in stage 12.0 (TID 61). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.421476","level":"info","event":"25/05/28 12:59:15 INFO TaskSetManager: Finished task 8.0 in stage 12.0 (TID 61) in 558 ms on localhost (executor driver) (10/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.452319","level":"info","event":"25/05/28 12:59:15 INFO Executor: Finished task 11.0 in stage 12.0 (TID 64). 2791 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.454816","level":"info","event":"25/05/28 12:59:15 INFO TaskSetManager: Finished task 11.0 in stage 12.0 (TID 64) in 310 ms on localhost (executor driver) (11/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.524492","level":"info","event":"25/05/28 12:59:15 INFO Executor: Finished task 10.0 in stage 12.0 (TID 63). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.525683","level":"info","event":"25/05/28 12:59:15 INFO TaskSetManager: Finished task 10.0 in stage 12.0 (TID 63) in 411 ms on localhost (executor driver) (12/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.525874","level":"info","event":"25/05/28 12:59:15 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.526710","level":"info","event":"25/05/28 12:59:15 INFO DAGScheduler: ShuffleMapStage 12 (parquet at NativeMethodAccessorImpl.java:0) finished in 56.212 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.526880","level":"info","event":"25/05/28 12:59:15 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.526991","level":"info","event":"25/05/28 12:59:15 INFO DAGScheduler: running: Set(ShuffleMapStage 11)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.527108","level":"info","event":"25/05/28 12:59:15 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.527208","level":"info","event":"25/05/28 12:59:15 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.882102","level":"info","event":"25/05/28 12:59:15 INFO Executor: Finished task 10.0 in stage 11.0 (TID 51). 2499 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:15.883089","level":"info","event":"25/05/28 12:59:15 INFO TaskSetManager: Finished task 10.0 in stage 11.0 (TID 51) in 56805 ms on localhost (executor driver) (7/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:18.185509","level":"info","event":"25/05/28 12:59:18 INFO Executor: Finished task 0.0 in stage 11.0 (TID 41). 2499 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:18.186909","level":"info","event":"25/05/28 12:59:18 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 41) in 59117 ms on localhost (executor driver) (8/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:18.217241","level":"info","event":"25/05/28 12:59:18 INFO Executor: Finished task 9.0 in stage 11.0 (TID 50). 2499 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:18.218809","level":"info","event":"25/05/28 12:59:18 INFO TaskSetManager: Finished task 9.0 in stage 11.0 (TID 50) in 59142 ms on localhost (executor driver) (9/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:18.707441","level":"info","event":"25/05/28 12:59:18 INFO Executor: Finished task 7.0 in stage 11.0 (TID 48). 2542 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:18.709491","level":"info","event":"25/05/28 12:59:18 INFO TaskSetManager: Finished task 7.0 in stage 11.0 (TID 48) in 59634 ms on localhost (executor driver) (10/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:18.782275","level":"info","event":"25/05/28 12:59:18 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:42069 in memory (size: 22.7 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:20.368771","level":"info","event":"25/05/28 12:59:20 INFO Executor: Finished task 4.0 in stage 11.0 (TID 45). 2499 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:20.370346","level":"info","event":"25/05/28 12:59:20 INFO TaskSetManager: Finished task 4.0 in stage 11.0 (TID 45) in 61297 ms on localhost (executor driver) (11/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:20.634579","level":"info","event":"25/05/28 12:59:20 INFO Executor: Finished task 2.0 in stage 11.0 (TID 43). 2499 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:20.635753","level":"info","event":"25/05/28 12:59:20 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 43) in 61565 ms on localhost (executor driver) (12/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:20.636030","level":"info","event":"25/05/28 12:59:20 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:20.639158","level":"info","event":"25/05/28 12:59:20 INFO DAGScheduler: ShuffleMapStage 11 (parquet at NativeMethodAccessorImpl.java:0) finished in 61.589 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:20.639442","level":"info","event":"25/05/28 12:59:20 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:20.639595","level":"info","event":"25/05/28 12:59:20 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:20.639728","level":"info","event":"25/05/28 12:59:20 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:20.639864","level":"info","event":"25/05/28 12:59:20 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:20.669078","level":"info","event":"25/05/28 12:59:20 INFO ShufflePartitionsUtil: For shuffle(3, 4), advisory target size: 67108864, actual target size 3773179, minimum partition size: 1048576","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:21.149013","level":"info","event":"25/05/28 12:59:21 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:21.393394","level":"info","event":"25/05/28 12:59:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:21.393663","level":"info","event":"25/05/28 12:59:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:21.396049","level":"info","event":"25/05/28 12:59:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:21.396605","level":"info","event":"25/05/28 12:59:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:21.396939","level":"info","event":"25/05/28 12:59:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T12:59:21.397112","level":"info","event":"25/05/28 12:59:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.324956","level":"info","event":"25/05/28 13:00:24 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.TimeoutException: Cannot receive any reply from localhost:33791 in 10000 milliseconds","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.337120","level":"info","event":"25/05/28 13:00:24 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@7e2ef84)) by listener AppStatusListener took 3.903073733s.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.337326","level":"info","event":"25/05/28 13:00:24 WARN Executor: Issue communicating with driver in heartbeater","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.337455","level":"info","event":"org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.337565","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.337664","level":"info","event":"at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.337757","level":"info","event":"at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.337852","level":"info","event":"at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.337951","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.338045","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.338138","level":"info","event":"at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1219)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.338238","level":"info","event":"at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.338379","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.338503","level":"info","event":"at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.338635","level":"info","event":"at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.338754","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.338868","level":"info","event":"at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.340703","level":"info","event":"at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.341470","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.341682","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.342830","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.343039","level":"info","event":"Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.343217","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.343386","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.343527","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.343656","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.343774","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.343908","level":"info","event":"... 12 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.377556","level":"info","event":"25/05/28 13:00:24 INFO CodeGenerator: Code generated in 59982.609777 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.520255","level":"info","event":"25/05/28 13:00:24 INFO CodeGenerator: Code generated in 104.721767 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.582204","level":"info","event":"25/05/28 13:00:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.686137","level":"info","event":"25/05/28 13:00:24 INFO CodeGenerator: Code generated in 86.379438 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.891248","level":"info","event":"25/05/28 13:00:24 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.896166","level":"info","event":"25/05/28 13:00:24 INFO DAGScheduler: Got job 9 (parquet at NativeMethodAccessorImpl.java:0) with 13 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.896404","level":"info","event":"25/05/28 13:00:24 INFO DAGScheduler: Final stage: ResultStage 15 (parquet at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.896546","level":"info","event":"25/05/28 13:00:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13, ShuffleMapStage 14)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.896759","level":"info","event":"25/05/28 13:00:24 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:24.898058","level":"info","event":"25/05/28 13:00:24 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[43] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.221637","level":"info","event":"25/05/28 13:00:25 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 306.5 KiB, free 1048.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.328114","level":"info","event":"25/05/28 13:00:25 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 112.9 KiB, free 1047.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.343724","level":"info","event":"25/05/28 13:00:25 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:42069 (size: 112.9 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.361038","level":"info","event":"25/05/28 13:00:25 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.361440","level":"info","event":"25/05/28 13:00:25 INFO DAGScheduler: Submitting 13 missing tasks from ResultStage 15 (MapPartitionsRDD[43] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.361659","level":"info","event":"25/05/28 13:00:25 INFO TaskSchedulerImpl: Adding task set 15.0 with 13 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.361868","level":"info","event":"25/05/28 13:00:25 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 65) (localhost, executor driver, partition 0, NODE_LOCAL, 7897 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.363650","level":"info","event":"25/05/28 13:00:25 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 66) (localhost, executor driver, partition 1, NODE_LOCAL, 7897 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.363851","level":"info","event":"25/05/28 13:00:25 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 67) (localhost, executor driver, partition 2, NODE_LOCAL, 7897 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.363965","level":"info","event":"25/05/28 13:00:25 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 68) (localhost, executor driver, partition 3, NODE_LOCAL, 7897 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.364069","level":"info","event":"25/05/28 13:00:25 INFO TaskSetManager: Starting task 4.0 in stage 15.0 (TID 69) (localhost, executor driver, partition 4, NODE_LOCAL, 7897 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.364166","level":"info","event":"25/05/28 13:00:25 INFO TaskSetManager: Starting task 5.0 in stage 15.0 (TID 70) (localhost, executor driver, partition 5, NODE_LOCAL, 7897 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.364262","level":"info","event":"25/05/28 13:00:25 INFO TaskSetManager: Starting task 6.0 in stage 15.0 (TID 71) (localhost, executor driver, partition 6, NODE_LOCAL, 7897 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.364354","level":"info","event":"25/05/28 13:00:25 INFO TaskSetManager: Starting task 7.0 in stage 15.0 (TID 72) (localhost, executor driver, partition 7, NODE_LOCAL, 7897 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.364481","level":"info","event":"25/05/28 13:00:25 INFO TaskSetManager: Starting task 8.0 in stage 15.0 (TID 73) (localhost, executor driver, partition 8, NODE_LOCAL, 7897 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.364583","level":"info","event":"25/05/28 13:00:25 INFO TaskSetManager: Starting task 9.0 in stage 15.0 (TID 74) (localhost, executor driver, partition 9, NODE_LOCAL, 7897 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.364677","level":"info","event":"25/05/28 13:00:25 INFO TaskSetManager: Starting task 10.0 in stage 15.0 (TID 75) (localhost, executor driver, partition 10, NODE_LOCAL, 7897 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.364769","level":"info","event":"25/05/28 13:00:25 INFO TaskSetManager: Starting task 11.0 in stage 15.0 (TID 76) (localhost, executor driver, partition 11, NODE_LOCAL, 7897 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.405283","level":"info","event":"25/05/28 13:00:25 INFO Executor: Running task 0.0 in stage 15.0 (TID 65)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.408371","level":"info","event":"25/05/28 13:00:25 INFO Executor: Running task 2.0 in stage 15.0 (TID 67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.412070","level":"info","event":"25/05/28 13:00:25 INFO Executor: Running task 3.0 in stage 15.0 (TID 68)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.509973","level":"info","event":"25/05/28 13:00:25 INFO Executor: Running task 6.0 in stage 15.0 (TID 71)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.510226","level":"info","event":"25/05/28 13:00:25 INFO Executor: Running task 8.0 in stage 15.0 (TID 73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.520348","level":"info","event":"25/05/28 13:00:25 INFO Executor: Running task 5.0 in stage 15.0 (TID 70)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.520876","level":"info","event":"25/05/28 13:00:25 INFO Executor: Running task 1.0 in stage 15.0 (TID 66)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.527249","level":"info","event":"25/05/28 13:00:25 INFO Executor: Running task 7.0 in stage 15.0 (TID 72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.527450","level":"info","event":"25/05/28 13:00:25 INFO Executor: Running task 4.0 in stage 15.0 (TID 69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.560165","level":"info","event":"25/05/28 13:00:25 INFO Executor: Running task 11.0 in stage 15.0 (TID 76)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.613182","level":"info","event":"25/05/28 13:00:25 INFO Executor: Running task 10.0 in stage 15.0 (TID 75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:25.631653","level":"info","event":"25/05/28 13:00:25 INFO Executor: Running task 9.0 in stage 15.0 (TID 74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.080152","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Getting 12 (3.0 MiB) non-empty blocks including 12 (3.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.103554","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 22 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.106759","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Getting 12 (3.0 MiB) non-empty blocks including 12 (3.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.107493","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 23 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.108227","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Getting 12 (3.0 MiB) non-empty blocks including 12 (3.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.108756","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 37 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.109197","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Getting 12 (3.0 MiB) non-empty blocks including 12 (3.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.118582","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Getting 12 (3.0 MiB) non-empty blocks including 12 (3.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.118932","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.119391","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Getting 12 (3.0 MiB) non-empty blocks including 12 (3.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.119621","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.119819","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Getting 12 (3.0 MiB) non-empty blocks including 12 (3.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.119941","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.122128","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Getting 12 (3.0 MiB) non-empty blocks including 12 (3.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.123183","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Getting 12 (3.1 MiB) non-empty blocks including 12 (3.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.123790","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.123996","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.124170","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 44 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.125213","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Getting 12 (3.1 MiB) non-empty blocks including 12 (3.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.125447","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.127991","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Getting 12 (3.0 MiB) non-empty blocks including 12 (3.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.128191","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.128312","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Getting 12 (3.1 MiB) non-empty blocks including 12 (3.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.128444","level":"info","event":"25/05/28 13:00:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.308777","level":"info","event":"25/05/28 13:00:26 INFO CodeGenerator: Code generated in 22.932836 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:26.826687","level":"info","event":"25/05/28 13:00:26 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:42069 in memory (size: 19.4 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.033968","level":"info","event":"25/05/28 13:00:27 INFO CodeGenerator: Code generated in 162.589168 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.119534","level":"info","event":"25/05/28 13:00:27 INFO CodeGenerator: Code generated in 31.555218 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.136984","level":"info","event":"25/05/28 13:00:27 INFO CodeGenerator: Code generated in 12.013793 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.150116","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Getting 12 (449.9 KiB) non-empty blocks including 12 (449.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.151703","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.155554","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Getting 12 (451.3 KiB) non-empty blocks including 12 (451.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.156365","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.157485","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Getting 12 (441.6 KiB) non-empty blocks including 12 (441.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.157685","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Getting 12 (449.8 KiB) non-empty blocks including 12 (449.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.157807","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.157920","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.158032","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Getting 12 (452.4 KiB) non-empty blocks including 12 (452.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.158144","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.158269","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Getting 12 (457.3 KiB) non-empty blocks including 12 (457.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.158414","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.161110","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Getting 12 (444.9 KiB) non-empty blocks including 12 (444.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.161326","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.162022","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Getting 12 (450.2 KiB) non-empty blocks including 12 (450.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.162182","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.169444","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Getting 12 (443.1 KiB) non-empty blocks including 12 (443.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.177940","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.197049","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Getting 12 (453.9 KiB) non-empty blocks including 12 (453.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.197372","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 28 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.197508","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Getting 12 (442.4 KiB) non-empty blocks including 12 (442.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.197636","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.197768","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Getting 12 (441.0 KiB) non-empty blocks including 12 (441.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.197922","level":"info","event":"25/05/28 13:00:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 31 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.279641","level":"info","event":"25/05/28 13:00:27 INFO CodeGenerator: Code generated in 62.813578 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.334033","level":"info","event":"25/05/28 13:00:27 INFO CodeGenerator: Code generated in 47.635869 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.352577","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.352892","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.353163","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.354033","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.354207","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.354344","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.354552","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.355234","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.356278","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.356735","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.356937","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.357065","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.357195","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.357306","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.357426","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.357571","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.357691","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.357892","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.358037","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.358153","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.358280","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.358383","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.358532","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.358699","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.358874","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.359000","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.359142","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.359250","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.359429","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.359571","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.359691","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.359798","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.363288","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.363662","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.363836","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.363965","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.364164","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.365024","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.365249","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.365478","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.365616","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.365735","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.365857","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.365973","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:00:27.366111","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.631462","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.631842","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.632007","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.632159","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.632274","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.632392","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.632521","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.632642","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.632770","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.632934","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.633063","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.633189","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.633344","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.633610","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.634140","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.634273","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.634387","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.634542","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.634686","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.634802","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.634908","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.635017","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.635129","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.635240","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.635355","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.635473","level":"info","event":"25/05/28 13:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.635599","level":"info","event":"25/05/28 13:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.635755","level":"info","event":"25/05/28 13:00:27 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.635872","level":"info","event":"25/05/28 13:00:27 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.636027","level":"info","event":"25/05/28 13:00:27 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.636188","level":"info","event":"25/05/28 13:00:27 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.636311","level":"info","event":"25/05/28 13:02:37 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 131909 ms exceeds timeout 120000 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.636428","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.636758","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.636951","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.637091","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.637220","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.637346","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.637477","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.637597","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.637724","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.637824","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.637932","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.638025","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.638108","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.638206","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.638318","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.638432","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.638550","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.638691","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.638817","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.638936","level":"info","event":"25/05/28 13:02:37 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.639053","level":"info","event":"25/05/28 13:02:37 INFO Executor: Told to re-register on heartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.639171","level":"info","event":"25/05/28 13:02:37 INFO BlockManager: BlockManager BlockManagerId(driver, localhost, 42069, None) re-registering with master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.639289","level":"info","event":"25/05/28 13:02:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.639407","level":"info","event":"25/05/28 13:02:37 WARN SparkContext: Killing executors is not supported by current scheduler.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.639924","level":"info","event":"25/05/28 13:02:37 WARN Executor: Issue communicating with driver in heartbeater","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.640080","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.640217","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.640536","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.641193","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.649787","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.650066","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.650207","level":"info","event":"at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.650338","level":"info","event":"at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.650467","level":"info","event":"at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.650581","level":"info","event":"at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.650710","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.650828","level":"info","event":"at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.650933","level":"info","event":"at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.651044","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.651161","level":"info","event":"at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.651267","level":"info","event":"at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.651381","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.651491","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.651601","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.651730","level":"info","event":"Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.651837","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.651960","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.652084","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.652206","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.652311","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.652422","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.652534","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.652644","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.652785","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.652885","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.653002","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.653098","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.653191","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.653283","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.653450","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.653559","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.653655","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.653780","level":"info","event":"... 3 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.653875","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.653987","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.654086","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.654205","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.654318","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.654426","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.654534","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.654646","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.654799","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.654927","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.655039","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.655153","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.655256","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.657537","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.657801","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.657957","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.658540","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.658720","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.658854","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.659000","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.659117","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.659211","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.659297","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.659383","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.669147","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.669575","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.669728","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.669852","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.669968","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.670076","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.670193","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.670348","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.670477","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.670588","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.670699","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.670808","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.670923","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.671037","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.671147","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.671257","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.671460","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.671581","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.671698","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.671808","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.671918","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.672025","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.672131","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.672240","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:41.672419","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.047646","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.047845","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.047979","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.048100","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.048227","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.048433","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.048568","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.048697","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.048819","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.048970","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.049088","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.049193","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.049333","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.049455","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.049575","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.049714","level":"info","event":"25/05/28 13:02:37 ERROR Inbox: Ignoring error","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.049870","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.049984","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.050088","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.050185","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.050282","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.050434","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.050537","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.050645","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.050751","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.050897","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.051029","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.051139","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.051238","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.051337","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.051509","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.051624","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.051721","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.051841","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.052006","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.052121","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.052243","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.052354","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.052501","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.052613","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.052720","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.052822","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.052965","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.053073","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.053167","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.053260","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.053502","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.053651","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.053776","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.053910","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.054097","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.054221","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.054331","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.054434","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.054589","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.054742","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.054860","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.054972","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.055076","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.055170","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.055265","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.055360","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.055455","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.055664","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.055803","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.056004","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.056144","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.056270","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.064252","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.064646","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.065181","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.065708","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.065888","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.066014","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.066120","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.066235","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.066365","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.066492","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.066657","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.066791","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.066916","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.067041","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.067169","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.067291","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.067406","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.067518","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.067676","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.067798","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.067926","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.068049","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.068168","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.068285","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.068411","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.068573","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.068708","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.068841","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.068974","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.069102","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.069235","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.069357","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.069470","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.069615","level":"info","event":"25/05/28 13:02:37 INFO Executor: Told to re-register on heartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.069743","level":"info","event":"25/05/28 13:02:37 INFO BlockManager: BlockManager BlockManagerId(driver, localhost, 42069, None) re-registering with master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.069875","level":"info","event":"25/05/28 13:02:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.069994","level":"info","event":"25/05/28 13:02:37 WARN Executor: Issue communicating with driver in heartbeater","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.070114","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.070231","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.070345","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.070462","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.070618","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.070752","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.070885","level":"info","event":"at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.071016","level":"info","event":"at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.071149","level":"info","event":"at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.071312","level":"info","event":"at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.071455","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.071603","level":"info","event":"at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.071763","level":"info","event":"at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.071912","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.072035","level":"info","event":"at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.072156","level":"info","event":"at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.072278","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.072391","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.072498","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.072636","level":"info","event":"Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.072754","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.072876","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.072998","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.073114","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.073225","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.073357","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.073481","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.073639","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.073761","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.073875","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.073981","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.074105","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.074226","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.074336","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.074454","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.074598","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.275437","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.275668","level":"info","event":"... 3 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.276021","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.276187","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.276323","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.276485","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.276619","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.276750","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.276881","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.277041","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.277173","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.277307","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.277433","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.277555","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.277684","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.277829","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.277986","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.278127","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.278260","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.278392","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.278525","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.278658","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.278786","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.278937","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.279163","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.279310","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.279443","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.279573","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.279701","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.279842","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.279996","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.280131","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.280256","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.283761","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.284048","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.284238","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.284403","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.284559","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.284710","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.284858","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.285038","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.285194","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.285345","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.285492","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.285636","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.285780","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.285965","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.286116","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.286255","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.286400","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.286548","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.286688","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.286830","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.286997","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.287166","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.287316","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.287463","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.287607","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.287749","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.287900","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.288068","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.288202","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.288336","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.288470","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.288601","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.289544","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.289743","level":"info","event":"25/05/28 13:02:37 INFO Executor: Told to re-register on heartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.290104","level":"info","event":"25/05/28 13:02:37 INFO BlockManager: BlockManager BlockManagerId(driver, localhost, 42069, None) re-registering with master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.290278","level":"info","event":"25/05/28 13:02:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.291131","level":"info","event":"25/05/28 13:02:37 ERROR Inbox: Ignoring error","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.291281","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.291404","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.291520","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.291627","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.291727","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.291827","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.291966","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.292090","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.292208","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.292322","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.292414","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.292500","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.292584","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.292666","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.292749","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.292833","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.292940","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.293047","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.293136","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.293220","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.293360","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.293476","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.293566","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.293654","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.293752","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.293848","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.293986","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.294081","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.294166","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.294251","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.294332","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.294418","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.294499","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.294581","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.294661","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.294748","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.294833","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.294948","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.295056","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.295146","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.295238","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.295353","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.295465","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.295583","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.295682","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.295777","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.295864","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.295984","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.296087","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.296183","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.296275","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.296366","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.296458","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.296598","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.296796","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.296929","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.297066","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.297168","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.297259","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.297345","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.297430","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.297550","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.297657","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.297748","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.493510","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.493752","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.493915","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.494037","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.494187","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.494312","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.494431","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.494546","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.494712","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.494836","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.494950","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.495063","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.495213","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.495337","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.495452","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.495563","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.495673","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.495781","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.495910","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.496025","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.496138","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.496292","level":"info","event":"25/05/28 13:02:37 WARN Executor: Issue communicating with driver in heartbeater","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.496411","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.496525","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.496639","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.496752","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.496866","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.496979","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.497110","level":"info","event":"at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.497273","level":"info","event":"at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.497398","level":"info","event":"at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.497514","level":"info","event":"at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.497633","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.497751","level":"info","event":"at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.497867","level":"info","event":"at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.497981","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.498094","level":"info","event":"at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.498239","level":"info","event":"at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.498365","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.498483","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.498600","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.498710","level":"info","event":"Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.498870","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.498985","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.499098","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.499240","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.499361","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.499471","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.499579","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.499693","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.499824","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.499938","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.500055","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.500201","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.500330","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.500448","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.500597","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.500733","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.500852","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.500968","level":"info","event":"... 3 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.501084","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.501234","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.501362","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.501482","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.501602","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.501716","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.501847","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.501957","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.502066","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.502208","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.502331","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.502445","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.502559","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.502669","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.502780","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.502892","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.503004","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.503117","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.503266","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.503409","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.503526","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.503638","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.503751","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.512638","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.513421","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.513670","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.515447","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.515611","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.515718","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.515812","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.515905","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.516086","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.516222","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.516328","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.516435","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.516535","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.516628","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.516729","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.516827","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.516926","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.517024","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.517120","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.517259","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.517363","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.517460","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.517557","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.517652","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.517747","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.517843","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.517938","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.518038","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.518134","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.518274","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.518389","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.518498","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.518608","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.518714","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.518822","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.518931","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.519039","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.519169","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.519325","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.519447","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.519559","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.519669","level":"info","event":"25/05/28 13:02:37 ERROR Inbox: Ignoring error","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.519778","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.519905","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.520018","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.520127","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.520273","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.520388","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.520499","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.520663","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.520781","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.520897","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.521053","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.521201","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.521424","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.521551","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.521663","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.521840","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.521967","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.522088","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.522266","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.522404","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.522547","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.522687","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.522823","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.522987","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.798410","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.798689","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.798856","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.798984","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.799106","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.799229","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.799354","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.799496","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.799623","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.799739","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.799874","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.799986","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.800100","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.800216","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.800329","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.800439","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.800594","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.800709","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.800818","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.803263","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.803451","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.803590","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.803693","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.803788","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.806240","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.806444","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.806594","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.806698","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.806796","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.806893","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.807076","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.807185","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.807290","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.807398","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.807546","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.807667","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.807779","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.807886","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.808029","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.808155","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.808265","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.808361","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.808459","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.828347","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.828579","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.829171","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.829319","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.829552","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.829702","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.829830","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.829944","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.830104","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.830214","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.830314","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.830425","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.830543","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.830650","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.830746","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.830841","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.830947","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.831102","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.831225","level":"info","event":"25/05/28 13:02:37 INFO Executor: Told to re-register on heartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.831346","level":"info","event":"25/05/28 13:02:37 INFO BlockManager: BlockManager BlockManagerId(driver, localhost, 42069, None) re-registering with master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.831466","level":"info","event":"25/05/28 13:02:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.831579","level":"info","event":"25/05/28 13:02:37 ERROR Inbox: Ignoring error","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.831693","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.831810","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.831929","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.832075","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.832200","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.832316","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.832424","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.832536","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.832645","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.832814","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.832950","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.833098","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.833209","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.833380","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.833516","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.833635","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.833765","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.833876","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.834022","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.834166","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.834293","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.834416","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.834526","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.834636","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.834751","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.834859","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.834963","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.835113","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.835232","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.835344","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.844636","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.844898","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.845062","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.845191","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.845305","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.845416","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.845528","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.845637","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.845747","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.845851","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.845953","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.846093","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.846197","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.846305","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.846407","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.846506","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.846602","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.846698","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.846809","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.846905","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.847036","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.847151","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.847261","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.847368","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.847467","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.847566","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.847668","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.847766","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.847862","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.847956","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.848094","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.848208","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.848316","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.848417","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.848520","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.848617","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.848718","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.848816","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:42.848916","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.016583","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.016804","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.016948","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.017117","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.017306","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.017444","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.017571","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.017694","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.017832","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.018027","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.018224","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.018355","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.018482","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.018607","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.018749","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.018876","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.018994","level":"info","event":"25/05/28 13:02:37 WARN Executor: Issue communicating with driver in heartbeater","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.019116","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.019261","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.019386","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.019506","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.019624","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.019742","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.019858","level":"info","event":"at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.019977","level":"info","event":"at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.020095","level":"info","event":"at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.020255","level":"info","event":"at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.020388","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.020511","level":"info","event":"at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.020633","level":"info","event":"at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.020752","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.020868","level":"info","event":"at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.020984","level":"info","event":"at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.021107","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.021525","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.021720","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.021869","level":"info","event":"Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.021984","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.022091","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.022196","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.022339","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.022429","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.022518","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.022604","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.022690","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.022778","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.022863","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.022950","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.023034","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.023118","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.023219","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.023349","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.023440","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.023525","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.023609","level":"info","event":"... 3 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.023693","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.023842","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.023935","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.029434","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.029641","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.029751","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.029851","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.029974","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.030083","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.030180","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.030299","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.030401","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.030493","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.030584","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.030673","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.030785","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.030881","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.030975","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.031070","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.031165","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.031519","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.031751","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.032124","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.032394","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.032654","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.032997","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.033205","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.033533","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.033793","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.034078","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.034364","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.034528","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.034660","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.034786","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.034910","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.035124","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.035357","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.035481","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.035583","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.035679","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.035793","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.035914","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.036037","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.036158","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.036296","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.036425","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.036545","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.036647","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.036769","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.036887","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.036985","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.037077","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.037165","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.037289","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.037469","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.037587","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.037722","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.037840","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.037974","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.038104","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.038227","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.038383","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.038512","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.038632","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.038777","level":"info","event":"25/05/28 13:02:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.038904","level":"info","event":"25/05/28 13:02:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.039019","level":"info","event":"25/05/28 13:02:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.039138","level":"info","event":"25/05/28 13:02:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.039274","level":"info","event":"25/05/28 13:02:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.039403","level":"info","event":"25/05/28 13:02:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.039526","level":"info","event":"25/05/28 13:02:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.039648","level":"info","event":"25/05/28 13:02:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.039762","level":"info","event":"25/05/28 13:02:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.039878","level":"info","event":"25/05/28 13:02:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.039997","level":"info","event":"25/05/28 13:02:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.040112","level":"info","event":"25/05/28 13:02:38 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.040226","level":"info","event":"25/05/28 13:02:41 INFO Executor: Told to re-register on heartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.040371","level":"info","event":"25/05/28 13:02:41 INFO BlockManager: BlockManager BlockManagerId(driver, localhost, 42069, None) re-registering with master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.040499","level":"info","event":"25/05/28 13:02:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.040626","level":"info","event":"25/05/28 13:02:41 ERROR Inbox: Ignoring error","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.040784","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.040904","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.041018","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.041137","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.041284","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.041408","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.041529","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.041655","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.041794","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.041941","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.042063","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.042178","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.042317","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.042433","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.042549","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.081829","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.082026","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.082157","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.082338","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.082464","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.082580","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.082699","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.082814","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.082928","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.083039","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.083149","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.083294","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.083565","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.083703","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.083827","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.083944","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.084057","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.084167","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.084310","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.084426","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.084536","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.084652","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.084756","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.084832","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.084941","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.085029","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.085111","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.085220","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.085359","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.085473","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.085615","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.085730","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.085867","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.085983","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.086096","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.086209","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.086357","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.086471","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.086580","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.086693","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.086825","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.086941","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.087064","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.087189","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.087345","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.087501","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.087641","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.087786","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.087905","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.088027","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.088263","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.088408","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.088539","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.088674","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.088799","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.088923","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.089047","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.089166","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.089317","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.089450","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.089584","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.089689","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.089796","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.089909","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.090023","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.090134","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.090273","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.090404","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.090520","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.090632","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.090746","level":"info","event":"25/05/28 13:02:41 WARN Executor: Issue communicating with driver in heartbeater","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.090861","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.090976","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.091087","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.091202","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.091353","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.091475","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.091593","level":"info","event":"at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.091708","level":"info","event":"at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.091876","level":"info","event":"at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.092004","level":"info","event":"at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.092122","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.092270","level":"info","event":"at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.092397","level":"info","event":"at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.092506","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.092620","level":"info","event":"at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.092734","level":"info","event":"at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.092848","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.092963","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.093076","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.093190","level":"info","event":"Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.093371","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.093513","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.093668","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.093792","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.093912","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.094029","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.094145","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.094396","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.094553","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.094686","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.094816","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.094937","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.095057","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.095174","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.095327","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.095463","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.095598","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.095725","level":"info","event":"... 3 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.095847","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.095970","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.096123","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.096290","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.096425","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.096548","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.096667","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.096793","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.096892","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.096969","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.097043","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.097113","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.097182","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.097306","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.097391","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.097479","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.097588","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.097671","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.097741","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.097839","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.097930","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.098000","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.098079","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.098177","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.098280","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.098393","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.098500","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.098575","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.098645","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.098740","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.098820","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.098889","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.098991","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.099097","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.099176","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.099283","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.099406","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.099487","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.099556","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.099624","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.099732","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.099887","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.099982","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.100092","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.100201","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.100333","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.100431","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.100557","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.100740","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.100857","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.100962","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.101060","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.101157","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.101280","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.101393","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.101491","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.101585","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.101677","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.101781","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.101904","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.102011","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.102104","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.102461","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.102918","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.103438","level":"info","event":"25/05/28 13:02:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.103563","level":"info","event":"{","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.103684","level":"info","event":"\"type\" : \"struct\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.103782","level":"info","event":"\"fields\" : [ {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.103874","level":"info","event":"\"name\" : \"Customer_ID\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.103991","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.104093","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.104182","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.104313","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.104437","level":"info","event":"\"name\" : \"Name\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.104548","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.104656","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.104781","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.104894","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.105006","level":"info","event":"\"name\" : \"Email\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.105118","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.105225","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.105374","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.105483","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.105589","level":"info","event":"\"name\" : \"Phone\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.105721","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.105838","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.105953","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.106061","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.106172","level":"info","event":"\"name\" : \"Address\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.106317","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.106441","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.106557","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.106678","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.106795","level":"info","event":"\"name\" : \"City\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.106913","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.107020","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.107121","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.107257","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.107363","level":"info","event":"\"name\" : \"State\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.107455","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.107544","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.107633","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.158769","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.158944","level":"info","event":"\"name\" : \"Zipcode\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.159055","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.159154","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.159277","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.159391","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.159486","level":"info","event":"\"name\" : \"Country\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.159575","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.159701","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.159797","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.159889","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.159981","level":"info","event":"\"name\" : \"Age\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.160071","level":"info","event":"\"type\" : \"integer\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.160162","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.160278","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.160383","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.160477","level":"info","event":"\"name\" : \"Gender\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.160566","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.160655","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.160743","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.160829","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.160918","level":"info","event":"\"name\" : \"Income\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.161004","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.161114","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.161225","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.161352","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.161447","level":"info","event":"\"name\" : \"Customer_Segment\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.161538","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.161627","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.161734","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.161825","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.161918","level":"info","event":"\"name\" : \"total_orders\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.162007","level":"info","event":"\"type\" : \"long\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.162078","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.162152","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.162223","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.162341","level":"info","event":"\"name\" : \"total_spent\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.162432","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.162504","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.162572","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.162646","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.162735","level":"info","event":"\"name\" : \"avg_rating\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.162800","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.162865","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.162930","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.163016","level":"info","event":"} ]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.163090","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.163159","level":"info","event":"and corresponding Parquet message type:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.163256","level":"info","event":"message spark_schema {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.163408","level":"info","event":"optional binary Customer_ID (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.163517","level":"info","event":"optional binary Name (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.163608","level":"info","event":"optional binary Email (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.163697","level":"info","event":"optional binary Phone (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.163789","level":"info","event":"optional binary Address (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.163877","level":"info","event":"optional binary City (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.163967","level":"info","event":"optional binary State (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.164059","level":"info","event":"optional binary Zipcode (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.164148","level":"info","event":"optional binary Country (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.164260","level":"info","event":"optional int32 Age;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.164366","level":"info","event":"optional binary Gender (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.164458","level":"info","event":"optional binary Income (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.164549","level":"info","event":"optional binary Customer_Segment (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.164639","level":"info","event":"optional int64 total_orders;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.164730","level":"info","event":"optional double total_spent;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.164820","level":"info","event":"optional double avg_rating;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.164912","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.165006","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.165095","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.165186","level":"info","event":"25/05/28 13:02:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.165305","level":"info","event":"{","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.165404","level":"info","event":"\"type\" : \"struct\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.165498","level":"info","event":"\"fields\" : [ {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.165589","level":"info","event":"\"name\" : \"Customer_ID\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.165696","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.165795","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.165888","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.165983","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.166076","level":"info","event":"\"name\" : \"Name\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.166169","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.166289","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.166395","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.166492","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.166584","level":"info","event":"\"name\" : \"Email\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.166677","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.166769","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.166880","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.166995","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.167087","level":"info","event":"\"name\" : \"Phone\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.167181","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.167673","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.167846","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.167989","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.168097","level":"info","event":"\"name\" : \"Address\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.168304","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.168466","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.168750","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.168895","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.169074","level":"info","event":"\"name\" : \"City\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.169185","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.169306","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.169406","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.169496","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.169587","level":"info","event":"\"name\" : \"State\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.169675","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.169780","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.169893","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.169999","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.170094","level":"info","event":"\"name\" : \"Zipcode\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.170186","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.170306","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.170407","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.170499","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.170589","level":"info","event":"\"name\" : \"Country\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.170679","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.170768","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.170857","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.170948","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.171038","level":"info","event":"\"name\" : \"Age\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.171129","level":"info","event":"\"type\" : \"integer\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.171219","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.171418","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.171534","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.171633","level":"info","event":"\"name\" : \"Gender\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.171740","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.171822","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.171904","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.171985","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.172079","level":"info","event":"\"name\" : \"Income\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.172206","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.172347","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.172440","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.172521","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.172604","level":"info","event":"\"name\" : \"Customer_Segment\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.172707","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.172797","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.172885","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.172973","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.173090","level":"info","event":"\"name\" : \"total_orders\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.173196","level":"info","event":"\"type\" : \"long\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.173555","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.173763","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.173917","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.174075","level":"info","event":"\"name\" : \"total_spent\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.174258","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.174392","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.174513","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.174627","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.174759","level":"info","event":"\"name\" : \"avg_rating\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.174873","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.174984","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.175094","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.175205","level":"info","event":"} ]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.175353","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.175471","level":"info","event":"and corresponding Parquet message type:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.175586","level":"info","event":"message spark_schema {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.175704","level":"info","event":"optional binary Customer_ID (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.175820","level":"info","event":"optional binary Name (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.175932","level":"info","event":"optional binary Email (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.176045","level":"info","event":"optional binary Phone (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.176158","level":"info","event":"optional binary Address (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.176298","level":"info","event":"optional binary City (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.176415","level":"info","event":"optional binary State (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.176527","level":"info","event":"optional binary Zipcode (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.176637","level":"info","event":"optional binary Country (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.176764","level":"info","event":"optional int32 Age;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.176878","level":"info","event":"optional binary Gender (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.177048","level":"info","event":"optional binary Income (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.177171","level":"info","event":"optional binary Customer_Segment (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.177317","level":"info","event":"optional int64 total_orders;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.177442","level":"info","event":"optional double total_spent;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.177558","level":"info","event":"optional double avg_rating;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.177688","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.177797","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.177908","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.178018","level":"info","event":"25/05/28 13:02:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.178126","level":"info","event":"{","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.178280","level":"info","event":"\"type\" : \"struct\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.178435","level":"info","event":"\"fields\" : [ {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.178550","level":"info","event":"\"name\" : \"Customer_ID\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.178681","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.178793","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.178905","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.179016","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.179131","level":"info","event":"\"name\" : \"Name\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.179268","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.179393","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.179506","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.179618","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.179732","level":"info","event":"\"name\" : \"Email\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.179847","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.179956","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.180065","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.180176","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.180317","level":"info","event":"\"name\" : \"Phone\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.180444","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.180558","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.180667","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.180798","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.180921","level":"info","event":"\"name\" : \"Address\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.181051","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.181174","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.181328","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.181458","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.181611","level":"info","event":"\"name\" : \"City\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.181764","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.181882","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.181996","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.182111","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.182243","level":"info","event":"\"name\" : \"State\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.182381","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.182499","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.182616","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.182730","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.182844","level":"info","event":"\"name\" : \"Zipcode\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.182962","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.183085","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.183202","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.183415","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.183577","level":"info","event":"\"name\" : \"Country\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.183672","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.183750","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.183823","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.183895","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.183964","level":"info","event":"\"name\" : \"Age\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.184034","level":"info","event":"\"type\" : \"integer\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.184145","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.184226","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.184366","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.184445","level":"info","event":"\"name\" : \"Gender\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.184516","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.184587","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.184656","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.184725","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.184795","level":"info","event":"\"name\" : \"Income\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.184864","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.184932","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.185010","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.185084","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.185153","level":"info","event":"\"name\" : \"Customer_Segment\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.185244","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.185339","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.185411","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.185481","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.185555","level":"info","event":"\"name\" : \"total_orders\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.185625","level":"info","event":"\"type\" : \"long\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.185695","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.185779","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.185846","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.185912","level":"info","event":"\"name\" : \"total_spent\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.185980","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.186046","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.186112","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.186178","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.186289","level":"info","event":"\"name\" : \"avg_rating\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.186381","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.186452","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.186520","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.186597","level":"info","event":"} ]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.186689","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.186761","level":"info","event":"and corresponding Parquet message type:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.186838","level":"info","event":"message spark_schema {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.186926","level":"info","event":"optional binary Customer_ID (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.187069","level":"info","event":"optional binary Name (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.187195","level":"info","event":"optional binary Email (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.187342","level":"info","event":"optional binary Phone (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.187471","level":"info","event":"optional binary Address (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.187593","level":"info","event":"optional binary City (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.187711","level":"info","event":"optional binary State (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.187820","level":"info","event":"optional binary Zipcode (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.187898","level":"info","event":"optional binary Country (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.187967","level":"info","event":"optional int32 Age;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.188052","level":"info","event":"optional binary Gender (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.188159","level":"info","event":"optional binary Income (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.188420","level":"info","event":"optional binary Customer_Segment (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.188590","level":"info","event":"optional int64 total_orders;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.188707","level":"info","event":"optional double total_spent;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.188803","level":"info","event":"optional double avg_rating;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.188975","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.189106","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.189251","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.189370","level":"info","event":"25/05/28 13:02:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.189472","level":"info","event":"{","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.189555","level":"info","event":"\"type\" : \"struct\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.189733","level":"info","event":"\"fields\" : [ {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.189882","level":"info","event":"\"name\" : \"Customer_ID\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.190024","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.190145","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.190275","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.190391","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.190495","level":"info","event":"\"name\" : \"Name\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.190607","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.190732","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.190830","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.190928","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.191028","level":"info","event":"\"name\" : \"Email\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.191125","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.191223","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.191356","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.191457","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.191556","level":"info","event":"\"name\" : \"Phone\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.191663","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.191764","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.191857","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.268009","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.268291","level":"info","event":"\"name\" : \"Address\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.268688","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.268948","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.269146","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.269482","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.269646","level":"info","event":"\"name\" : \"City\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.269767","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.269868","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.269971","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.270106","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.270252","level":"info","event":"\"name\" : \"State\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.270395","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.270568","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.270711","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.270835","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.270949","level":"info","event":"\"name\" : \"Zipcode\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.271061","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.271173","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.271281","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.271389","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.271540","level":"info","event":"\"name\" : \"Country\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.271656","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.271777","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.271941","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.272056","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.272162","level":"info","event":"\"name\" : \"Age\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.272266","level":"info","event":"\"type\" : \"integer\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.272372","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.272516","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.272633","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.272763","level":"info","event":"\"name\" : \"Gender\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.272873","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.272982","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.273090","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.273201","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.273344","level":"info","event":"\"name\" : \"Income\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.273506","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.273629","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.273743","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.273861","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.273974","level":"info","event":"\"name\" : \"Customer_Segment\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.274091","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.274200","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.274312","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.274454","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.274578","level":"info","event":"\"name\" : \"total_orders\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.274690","level":"info","event":"\"type\" : \"long\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.274798","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.274907","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.275013","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.275094","level":"info","event":"\"name\" : \"total_spent\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.275178","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.275280","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.275361","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.275515","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.275625","level":"info","event":"\"name\" : \"avg_rating\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.275704","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.275795","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.275909","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.276036","level":"info","event":"} ]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.276173","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.276315","level":"info","event":"and corresponding Parquet message type:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.276453","level":"info","event":"message spark_schema {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.276601","level":"info","event":"optional binary Customer_ID (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.276729","level":"info","event":"optional binary Name (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.276844","level":"info","event":"optional binary Email (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.276977","level":"info","event":"optional binary Phone (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.277081","level":"info","event":"optional binary Address (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.277242","level":"info","event":"optional binary City (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.277386","level":"info","event":"optional binary State (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.277721","level":"info","event":"optional binary Zipcode (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.277898","level":"info","event":"optional binary Country (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.278060","level":"info","event":"optional int32 Age;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.278219","level":"info","event":"optional binary Gender (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.278375","level":"info","event":"optional binary Income (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.278555","level":"info","event":"optional binary Customer_Segment (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.278725","level":"info","event":"optional int64 total_orders;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.278880","level":"info","event":"optional double total_spent;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.279059","level":"info","event":"optional double avg_rating;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.279226","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.279387","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.279568","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.279722","level":"info","event":"25/05/28 13:02:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.279866","level":"info","event":"{","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.280003","level":"info","event":"\"type\" : \"struct\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.280139","level":"info","event":"\"fields\" : [ {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.280283","level":"info","event":"\"name\" : \"Customer_ID\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.280466","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.280624","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.280775","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.280926","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.281075","level":"info","event":"\"name\" : \"Name\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.281217","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.281361","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.281550","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.281730","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.281886","level":"info","event":"\"name\" : \"Email\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.282018","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.282147","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.282291","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.282466","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.282619","level":"info","event":"\"name\" : \"Phone\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.282771","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.282918","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.283099","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.283249","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.283484","level":"info","event":"\"name\" : \"Address\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.283648","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.283815","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.283957","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.284101","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.284242","level":"info","event":"\"name\" : \"City\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.284385","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.284562","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.284707","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.284852","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.285025","level":"info","event":"\"name\" : \"State\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.285166","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.285293","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.285406","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.285568","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.285709","level":"info","event":"\"name\" : \"Zipcode\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.285822","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.285936","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.286056","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.286174","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.286292","level":"info","event":"\"name\" : \"Country\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.286410","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.286576","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.286711","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.286840","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.286976","level":"info","event":"\"name\" : \"Age\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.287142","level":"info","event":"\"type\" : \"integer\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.287288","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.287426","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.287594","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.287735","level":"info","event":"\"name\" : \"Gender\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.287871","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.288006","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.288139","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.288272","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.288404","level":"info","event":"\"name\" : \"Income\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.288577","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.288739","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.288879","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.289018","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.289159","level":"info","event":"\"name\" : \"Customer_Segment\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.289295","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.289425","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.289597","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.289738","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.289877","level":"info","event":"\"name\" : \"total_orders\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.290017","level":"info","event":"\"type\" : \"long\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.290156","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.290293","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.290454","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.290605","level":"info","event":"\"name\" : \"total_spent\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.290743","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.290884","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.291025","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.291168","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.291337","level":"info","event":"\"name\" : \"avg_rating\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.291526","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.291657","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.291811","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.291977","level":"info","event":"} ]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.292123","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.292249","level":"info","event":"and corresponding Parquet message type:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.292342","level":"info","event":"message spark_schema {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.292422","level":"info","event":"optional binary Customer_ID (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.292601","level":"info","event":"optional binary Name (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.292748","level":"info","event":"optional binary Email (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.292858","level":"info","event":"optional binary Phone (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.292963","level":"info","event":"optional binary Address (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.293062","level":"info","event":"optional binary City (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.293164","level":"info","event":"optional binary State (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.293267","level":"info","event":"optional binary Zipcode (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.293409","level":"info","event":"optional binary Country (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.293562","level":"info","event":"optional int32 Age;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.293670","level":"info","event":"optional binary Gender (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.293769","level":"info","event":"optional binary Income (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.293866","level":"info","event":"optional binary Customer_Segment (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.293960","level":"info","event":"optional int64 total_orders;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.294054","level":"info","event":"optional double total_spent;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.294148","level":"info","event":"optional double avg_rating;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.294245","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.294342","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.294457","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.294580","level":"info","event":"25/05/28 13:02:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.294686","level":"info","event":"{","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.294827","level":"info","event":"\"type\" : \"struct\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.294944","level":"info","event":"\"fields\" : [ {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.295089","level":"info","event":"\"name\" : \"Customer_ID\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.295249","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.295399","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.295562","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.295678","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.295785","level":"info","event":"\"name\" : \"Name\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.295889","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.296004","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.296103","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.296238","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.296372","level":"info","event":"\"name\" : \"Email\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.296545","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.296687","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.296805","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.296892","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.296975","level":"info","event":"\"name\" : \"Phone\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.297097","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.297375","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.297577","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.297712","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.297874","level":"info","event":"\"name\" : \"Address\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.298011","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.298261","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.298410","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.298545","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.298720","level":"info","event":"\"name\" : \"City\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.298841","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.299011","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.299267","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.299489","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.299684","level":"info","event":"\"name\" : \"State\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.299964","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.300152","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.300310","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.300497","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.300646","level":"info","event":"\"name\" : \"Zipcode\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.300865","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.301018","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.301143","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.301386","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.301574","level":"info","event":"\"name\" : \"Country\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.301714","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.301825","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.301932","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.302039","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.302146","level":"info","event":"\"name\" : \"Age\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.302253","level":"info","event":"\"type\" : \"integer\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.302357","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.302490","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.302610","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.302735","level":"info","event":"\"name\" : \"Gender\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.302843","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.302951","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.303057","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.303164","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.303270","level":"info","event":"\"name\" : \"Income\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.303575","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.303707","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.303821","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.303933","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.304045","level":"info","event":"\"name\" : \"Customer_Segment\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.304158","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.304270","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.304379","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.304522","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.304644","level":"info","event":"\"name\" : \"total_orders\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.304833","level":"info","event":"\"type\" : \"long\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.305013","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.305197","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.305343","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.305532","level":"info","event":"\"name\" : \"total_spent\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.305690","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.305926","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.306062","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.306174","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.306274","level":"info","event":"\"name\" : \"avg_rating\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.306372","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.306556","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.306791","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.306925","level":"info","event":"} ]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.307027","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.307123","level":"info","event":"and corresponding Parquet message type:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.307217","level":"info","event":"message spark_schema {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.307308","level":"info","event":"optional binary Customer_ID (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.307401","level":"info","event":"optional binary Name (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.307530","level":"info","event":"optional binary Email (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.307656","level":"info","event":"optional binary Phone (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.307762","level":"info","event":"optional binary Address (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.307869","level":"info","event":"optional binary City (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.307998","level":"info","event":"optional binary State (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.308126","level":"info","event":"optional binary Zipcode (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.308258","level":"info","event":"optional binary Country (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.374225","level":"info","event":"optional int32 Age;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.374423","level":"info","event":"optional binary Gender (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.374550","level":"info","event":"optional binary Income (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.374662","level":"info","event":"optional binary Customer_Segment (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.374762","level":"info","event":"optional int64 total_orders;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.374865","level":"info","event":"optional double total_spent;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.375004","level":"info","event":"optional double avg_rating;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.375145","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.375258","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.375362","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.375461","level":"info","event":"25/05/28 13:02:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.375564","level":"info","event":"{","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.375670","level":"info","event":"\"type\" : \"struct\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.375779","level":"info","event":"\"fields\" : [ {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.375866","level":"info","event":"\"name\" : \"Customer_ID\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.375955","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.376039","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.376160","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.376256","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.376346","level":"info","event":"\"name\" : \"Name\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.376434","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.376518","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.376600","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.376684","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.376768","level":"info","event":"\"name\" : \"Email\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.376851","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.376937","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.377023","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.377142","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.377243","level":"info","event":"\"name\" : \"Phone\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.377336","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.377424","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.377512","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.377602","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.377709","level":"info","event":"\"name\" : \"Address\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.377801","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.377892","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.377985","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.378103","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.378210","level":"info","event":"\"name\" : \"City\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.378305","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.378399","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.378563","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.378669","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.378769","level":"info","event":"\"name\" : \"State\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.378860","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.378946","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.379030","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.379236","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.379365","level":"info","event":"\"name\" : \"Zipcode\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.379477","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.379582","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.379682","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.379782","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.379880","level":"info","event":"\"name\" : \"Country\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.379980","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.380104","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.380215","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.380312","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.380412","level":"info","event":"\"name\" : \"Age\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.380513","level":"info","event":"\"type\" : \"integer\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.380610","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.380703","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.380796","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.380888","level":"info","event":"\"name\" : \"Gender\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.381035","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.381239","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.381421","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.381530","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.381629","level":"info","event":"\"name\" : \"Income\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.381750","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.381879","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.381991","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.382136","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.382249","level":"info","event":"\"name\" : \"Customer_Segment\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.382353","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.382452","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.382549","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.382659","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.382753","level":"info","event":"\"name\" : \"total_orders\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.382849","level":"info","event":"\"type\" : \"long\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.382940","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.383030","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.383159","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.383256","level":"info","event":"\"name\" : \"total_spent\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.383374","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.383473","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.383570","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.383682","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.383780","level":"info","event":"\"name\" : \"avg_rating\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.383874","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.383973","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.384093","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.384211","level":"info","event":"} ]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.384341","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.384449","level":"info","event":"and corresponding Parquet message type:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.384548","level":"info","event":"message spark_schema {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.384674","level":"info","event":"optional binary Customer_ID (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.384789","level":"info","event":"optional binary Name (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.384887","level":"info","event":"optional binary Email (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.384986","level":"info","event":"optional binary Phone (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.385114","level":"info","event":"optional binary Address (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.385229","level":"info","event":"optional binary City (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.385330","level":"info","event":"optional binary State (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.385434","level":"info","event":"optional binary Zipcode (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.385531","level":"info","event":"optional binary Country (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.385627","level":"info","event":"optional int32 Age;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.385727","level":"info","event":"optional binary Gender (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.385822","level":"info","event":"optional binary Income (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.385915","level":"info","event":"optional binary Customer_Segment (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.386005","level":"info","event":"optional int64 total_orders;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.386213","level":"info","event":"optional double total_spent;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.386441","level":"info","event":"optional double avg_rating;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.386549","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.386641","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.386734","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.386829","level":"info","event":"25/05/28 13:02:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.386933","level":"info","event":"{","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.387027","level":"info","event":"\"type\" : \"struct\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.387152","level":"info","event":"\"fields\" : [ {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.387256","level":"info","event":"\"name\" : \"Customer_ID\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.387351","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.387446","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.387538","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.387633","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.387731","level":"info","event":"\"name\" : \"Name\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.387829","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.387924","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.388018","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.388148","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.388252","level":"info","event":"\"name\" : \"Email\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.388350","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.388444","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.388536","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.388624","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.388712","level":"info","event":"\"name\" : \"Phone\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.388799","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.388886","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.388972","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.389085","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.389190","level":"info","event":"\"name\" : \"Address\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.389282","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.389371","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.389457","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.389543","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.389697","level":"info","event":"\"name\" : \"City\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.389795","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.389885","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.389973","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.390061","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.390204","level":"info","event":"\"name\" : \"State\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.390311","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.390410","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.390510","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.390637","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.390769","level":"info","event":"\"name\" : \"Zipcode\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.390869","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.390965","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.391062","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.391216","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.391327","level":"info","event":"\"name\" : \"Country\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.391426","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.391523","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.391618","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.391769","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.391880","level":"info","event":"\"name\" : \"Age\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.391980","level":"info","event":"\"type\" : \"integer\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.392077","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.392174","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.392310","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.392419","level":"info","event":"\"name\" : \"Gender\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.392521","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.392617","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.392731","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.392910","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.393033","level":"info","event":"\"name\" : \"Income\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.393139","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.393241","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.393432","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.393559","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.393666","level":"info","event":"\"name\" : \"Customer_Segment\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.393771","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.393868","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.393966","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.394064","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.394162","level":"info","event":"\"name\" : \"total_orders\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.394291","level":"info","event":"\"type\" : \"long\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.394436","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.394545","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.394644","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.394739","level":"info","event":"\"name\" : \"total_spent\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.394841","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.394939","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.395036","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.395134","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.395231","level":"info","event":"\"name\" : \"avg_rating\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.395350","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.395470","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.395607","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.395712","level":"info","event":"} ]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.395815","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.395917","level":"info","event":"and corresponding Parquet message type:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.396016","level":"info","event":"message spark_schema {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.396116","level":"info","event":"optional binary Customer_ID (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.396218","level":"info","event":"optional binary Name (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.396319","level":"info","event":"optional binary Email (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.396463","level":"info","event":"optional binary Phone (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.396565","level":"info","event":"optional binary Address (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.396662","level":"info","event":"optional binary City (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.396756","level":"info","event":"optional binary State (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.396849","level":"info","event":"optional binary Zipcode (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.396941","level":"info","event":"optional binary Country (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.397035","level":"info","event":"optional int32 Age;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.397135","level":"info","event":"optional binary Gender (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.397227","level":"info","event":"optional binary Income (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.397318","level":"info","event":"optional binary Customer_Segment (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.397455","level":"info","event":"optional int64 total_orders;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.397552","level":"info","event":"optional double total_spent;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.397645","level":"info","event":"optional double avg_rating;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.397737","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.397831","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.397925","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.398018","level":"info","event":"25/05/28 13:02:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.398111","level":"info","event":"{","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.398203","level":"info","event":"\"type\" : \"struct\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.398295","level":"info","event":"\"fields\" : [ {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.398421","level":"info","event":"\"name\" : \"Customer_ID\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.398523","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.398618","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.398709","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.398803","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.398895","level":"info","event":"\"name\" : \"Name\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.398985","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.399075","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.399166","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.399259","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.399390","level":"info","event":"\"name\" : \"Email\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.399502","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.399597","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.399689","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.399782","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.399879","level":"info","event":"\"name\" : \"Phone\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.399973","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.400070","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.516847","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.517057","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.517191","level":"info","event":"\"name\" : \"Address\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.517309","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.517427","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.517669","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.517803","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.517923","level":"info","event":"\"name\" : \"City\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.518028","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.518133","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.518236","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.518337","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.518440","level":"info","event":"\"name\" : \"State\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.518542","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.518681","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.518820","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.518930","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.519036","level":"info","event":"\"name\" : \"Zipcode\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.519139","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.519238","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.519337","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.519437","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.519548","level":"info","event":"\"name\" : \"Country\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.519692","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.519803","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.519907","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.520008","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.520108","level":"info","event":"\"name\" : \"Age\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.520209","level":"info","event":"\"type\" : \"integer\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.520310","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.520409","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.520511","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.520652","level":"info","event":"\"name\" : \"Gender\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.520771","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.520875","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.520976","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.521077","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.521183","level":"info","event":"\"name\" : \"Income\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.521296","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.521407","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.521520","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.521686","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.521812","level":"info","event":"\"name\" : \"Customer_Segment\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.521922","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.522026","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.522129","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.522256","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.522379","level":"info","event":"\"name\" : \"total_orders\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.522492","level":"info","event":"\"type\" : \"long\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.522723","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.522852","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.522959","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.523062","level":"info","event":"\"name\" : \"total_spent\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.523165","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.523266","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.523404","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.523509","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.523651","level":"info","event":"\"name\" : \"avg_rating\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.523779","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.523890","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.523994","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.524094","level":"info","event":"} ]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.524229","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.524395","level":"info","event":"and corresponding Parquet message type:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.524507","level":"info","event":"message spark_schema {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.524667","level":"info","event":"optional binary Customer_ID (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.524790","level":"info","event":"optional binary Name (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.525001","level":"info","event":"optional binary Email (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.525154","level":"info","event":"optional binary Phone (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.525263","level":"info","event":"optional binary Address (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.525367","level":"info","event":"optional binary City (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.525471","level":"info","event":"optional binary State (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.525574","level":"info","event":"optional binary Zipcode (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.525750","level":"info","event":"optional binary Country (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.525859","level":"info","event":"optional int32 Age;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.525962","level":"info","event":"optional binary Gender (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.526073","level":"info","event":"optional binary Income (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.526196","level":"info","event":"optional binary Customer_Segment (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.526299","level":"info","event":"optional int64 total_orders;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.526399","level":"info","event":"optional double total_spent;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.526498","level":"info","event":"optional double avg_rating;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.526632","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.526755","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.526858","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.526959","level":"info","event":"25/05/28 13:02:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.527060","level":"info","event":"{","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.527270","level":"info","event":"\"type\" : \"struct\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.527383","level":"info","event":"\"fields\" : [ {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.527485","level":"info","event":"\"name\" : \"Customer_ID\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.528093","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.528242","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.528459","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.528621","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.528845","level":"info","event":"\"name\" : \"Name\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.528971","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.529085","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.529359","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.529518","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.529679","level":"info","event":"\"name\" : \"Email\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.529817","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.529944","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.530069","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.530192","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.530335","level":"info","event":"\"name\" : \"Phone\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.530456","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.530577","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.530739","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.530849","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.530947","level":"info","event":"\"name\" : \"Address\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.531052","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.535798","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.536007","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.536143","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.537271","level":"info","event":"\"name\" : \"City\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.537463","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.537630","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.537784","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.537901","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.538010","level":"info","event":"\"name\" : \"State\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.538119","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.538222","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.538323","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.538425","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.538525","level":"info","event":"\"name\" : \"Zipcode\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.538656","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.538780","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.538933","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.539049","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.539163","level":"info","event":"\"name\" : \"Country\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.539275","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.539386","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.539501","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.539695","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.539830","level":"info","event":"\"name\" : \"Age\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.540126","level":"info","event":"\"type\" : \"integer\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.540343","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.540475","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.540596","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.540751","level":"info","event":"\"name\" : \"Gender\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.543217","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.543504","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.543642","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.543758","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.543911","level":"info","event":"\"name\" : \"Income\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.544033","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.544482","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.544621","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.544736","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.544847","level":"info","event":"\"name\" : \"Customer_Segment\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.545006","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.545129","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.545263","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.545386","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.545570","level":"info","event":"\"name\" : \"total_orders\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.545689","level":"info","event":"\"type\" : \"long\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.546197","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.546342","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.546460","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.546572","level":"info","event":"\"name\" : \"total_spent\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.546719","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.546839","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.546946","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.547049","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.547179","level":"info","event":"\"name\" : \"avg_rating\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.547310","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.547418","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.547524","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.547633","level":"info","event":"} ]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.547796","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.547918","level":"info","event":"and corresponding Parquet message type:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.548031","level":"info","event":"message spark_schema {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.548139","level":"info","event":"optional binary Customer_ID (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.548245","level":"info","event":"optional binary Name (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.548353","level":"info","event":"optional binary Email (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.548545","level":"info","event":"optional binary Phone (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.548713","level":"info","event":"optional binary Address (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.548849","level":"info","event":"optional binary City (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.548963","level":"info","event":"optional binary State (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.549069","level":"info","event":"optional binary Zipcode (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.549174","level":"info","event":"optional binary Country (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.549277","level":"info","event":"optional int32 Age;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.549384","level":"info","event":"optional binary Gender (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.549533","level":"info","event":"optional binary Income (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.549723","level":"info","event":"optional binary Customer_Segment (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.549855","level":"info","event":"optional int64 total_orders;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.549964","level":"info","event":"optional double total_spent;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.550073","level":"info","event":"optional double avg_rating;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.550180","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.550290","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.550398","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.550701","level":"info","event":"25/05/28 13:02:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.550864","level":"info","event":"{","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.551193","level":"info","event":"\"type\" : \"struct\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.694615","level":"info","event":"\"fields\" : [ {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.694837","level":"info","event":"\"name\" : \"Customer_ID\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.695047","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.695215","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.695347","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.695517","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.695650","level":"info","event":"\"name\" : \"Name\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.695770","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.695885","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.696000","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.696173","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.696306","level":"info","event":"\"name\" : \"Email\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.696470","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.696604","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.696722","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.696843","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.696958","level":"info","event":"\"name\" : \"Phone\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.697076","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.697191","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.697308","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.697468","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.697656","level":"info","event":"\"name\" : \"Address\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.697785","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.697903","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.698016","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.698131","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.698246","level":"info","event":"\"name\" : \"City\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.698363","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.698581","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.698706","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.698874","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.699019","level":"info","event":"\"name\" : \"State\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.699145","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.699265","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.699412","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.699566","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.699696","level":"info","event":"\"name\" : \"Zipcode\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.699819","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.699995","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.700145","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.700304","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.700519","level":"info","event":"\"name\" : \"Country\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.700705","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.700975","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.701164","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.701373","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.701543","level":"info","event":"\"name\" : \"Age\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.701771","level":"info","event":"\"type\" : \"integer\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.702017","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.702303","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.702546","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.702735","level":"info","event":"\"name\" : \"Gender\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.703074","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.703223","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.703458","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.703653","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.703883","level":"info","event":"\"name\" : \"Income\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.704017","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.704142","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.704272","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.704453","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.704688","level":"info","event":"\"name\" : \"Customer_Segment\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.704878","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.705026","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.705155","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.705480","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.705703","level":"info","event":"\"name\" : \"total_orders\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.705863","level":"info","event":"\"type\" : \"long\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.706103","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.706308","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.706703","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.706863","level":"info","event":"\"name\" : \"total_spent\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.707103","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.707246","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.707502","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.707736","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.708012","level":"info","event":"\"name\" : \"avg_rating\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.708321","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.708675","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.708972","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.709132","level":"info","event":"} ]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.709315","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.709541","level":"info","event":"and corresponding Parquet message type:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.709797","level":"info","event":"message spark_schema {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.710056","level":"info","event":"optional binary Customer_ID (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.710555","level":"info","event":"optional binary Name (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.711082","level":"info","event":"optional binary Email (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.711534","level":"info","event":"optional binary Phone (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.711708","level":"info","event":"optional binary Address (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.711837","level":"info","event":"optional binary City (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.711963","level":"info","event":"optional binary State (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.712072","level":"info","event":"optional binary Zipcode (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.712187","level":"info","event":"optional binary Country (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.712305","level":"info","event":"optional int32 Age;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.712446","level":"info","event":"optional binary Gender (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.712571","level":"info","event":"optional binary Income (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.712687","level":"info","event":"optional binary Customer_Segment (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.712937","level":"info","event":"optional int64 total_orders;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.713072","level":"info","event":"optional double total_spent;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.713195","level":"info","event":"optional double avg_rating;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.713362","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.713543","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.713655","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.713779","level":"info","event":"25/05/28 13:02:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.713895","level":"info","event":"{","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.714019","level":"info","event":"\"type\" : \"struct\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.714138","level":"info","event":"\"fields\" : [ {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.714254","level":"info","event":"\"name\" : \"Customer_ID\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.714391","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.714518","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.714631","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.714738","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.714852","level":"info","event":"\"name\" : \"Name\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.714971","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.715093","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.715204","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.715308","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.715448","level":"info","event":"\"name\" : \"Email\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.715568","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.715685","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.715793","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.715918","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.716034","level":"info","event":"\"name\" : \"Phone\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.716148","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.716252","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.716365","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.716519","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.716633","level":"info","event":"\"name\" : \"Address\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.716752","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.716866","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.716981","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.717105","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.717217","level":"info","event":"\"name\" : \"City\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.717325","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.717468","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.717581","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.717689","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.717797","level":"info","event":"\"name\" : \"State\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.717915","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.718034","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.718155","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.718275","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.718425","level":"info","event":"\"name\" : \"Zipcode\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.718555","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.718668","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.718780","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.718887","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.719074","level":"info","event":"\"name\" : \"Country\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.720476","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.720790","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.721021","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.721380","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.721530","level":"info","event":"\"name\" : \"Age\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.721668","level":"info","event":"\"type\" : \"integer\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.721782","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.721897","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.722013","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.722125","level":"info","event":"\"name\" : \"Gender\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.722245","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.722391","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.722637","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.722827","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.722997","level":"info","event":"\"name\" : \"Income\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.723130","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.723285","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.723430","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.723550","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.723688","level":"info","event":"\"name\" : \"Customer_Segment\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.723810","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.723956","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.724082","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.724204","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.724324","level":"info","event":"\"name\" : \"total_orders\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.724472","level":"info","event":"\"type\" : \"long\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.724597","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.724714","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.724831","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.724978","level":"info","event":"\"name\" : \"total_spent\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.725103","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.725296","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.725537","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.725669","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.725791","level":"info","event":"\"name\" : \"avg_rating\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.725939","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.726068","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.726212","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.726335","level":"info","event":"} ]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.726458","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.726583","level":"info","event":"and corresponding Parquet message type:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.726705","level":"info","event":"message spark_schema {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.726824","level":"info","event":"optional binary Customer_ID (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.726968","level":"info","event":"optional binary Name (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.727094","level":"info","event":"optional binary Email (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.727215","level":"info","event":"optional binary Phone (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.727334","level":"info","event":"optional binary Address (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.727453","level":"info","event":"optional binary City (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.727569","level":"info","event":"optional binary State (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.727695","level":"info","event":"optional binary Zipcode (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.727805","level":"info","event":"optional binary Country (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.727939","level":"info","event":"optional int32 Age;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.728058","level":"info","event":"optional binary Gender (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.728168","level":"info","event":"optional binary Income (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.728277","level":"info","event":"optional binary Customer_Segment (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.728378","level":"info","event":"optional int64 total_orders;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.728486","level":"info","event":"optional double total_spent;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.728618","level":"info","event":"optional double avg_rating;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.728734","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.728835","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.729228","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.729364","level":"info","event":"25/05/28 13:02:42 INFO Executor: Told to re-register on heartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.729751","level":"info","event":"25/05/28 13:02:43 INFO BlockManager: BlockManager BlockManagerId(driver, localhost, 42069, None) re-registering with master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.730033","level":"info","event":"25/05/28 13:02:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.730165","level":"info","event":"25/05/28 13:02:43 ERROR Inbox: Ignoring error","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.730286","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.730405","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.730521","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.730633","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.730748","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.730864","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.731008","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.731123","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.731238","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.731354","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.731470","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.731587","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.731697","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.731805","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.731939","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.732061","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.732170","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.732277","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.732389","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.732503","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.732617","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.732731","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.732844","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.732983","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.733102","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.733215","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.733371","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.733491","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.733608","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.733865","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.734013","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.734128","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.734244","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.734387","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.734509","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.734638","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.734756","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.898856","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.899074","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.899212","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.899326","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.899434","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.899538","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.899679","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.899797","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.899901","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.900003","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.900121","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.900229","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.900331","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.900434","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.900533","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.900665","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.900778","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.900880","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.900982","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.901097","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.901250","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.901367","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.901465","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.901562","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.901703","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.901819","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.901931","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.902038","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.902149","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.902252","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.902365","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.902470","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.902580","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.902718","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.902818","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.902924","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.903025","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.903183","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.903332","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.903477","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.903581","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.903738","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.903850","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.903954","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.904069","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.904175","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.904340","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.904447","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.904552","level":"info","event":"25/05/28 13:02:43 WARN Executor: Issue communicating with driver in heartbeater","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.904653","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.904808","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.904921","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.905035","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.905144","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.905245","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.905407","level":"info","event":"at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.905513","level":"info","event":"at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.905614","level":"info","event":"at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.905713","level":"info","event":"at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.905860","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.905977","level":"info","event":"at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.906092","level":"info","event":"at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.906193","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.906297","level":"info","event":"at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.906449","level":"info","event":"at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.906554","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.906653","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.906754","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.909934","level":"info","event":"Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.912982","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.917240","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.917431","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.917573","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.917707","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.917841","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.918007","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.918145","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.918279","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.918411","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.918540","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.918661","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.918783","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.918938","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.919073","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.919193","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.919313","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.919430","level":"info","event":"... 3 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.919534","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.919637","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.919736","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.919845","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.919993","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.920106","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.920291","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.920428","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.920540","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.920649","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.920757","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.920928","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.921060","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.921176","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.921284","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.921392","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.921511","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.921638","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.921765","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.921923","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.922061","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.922182","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.922330","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.922458","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.922590","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.922713","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.922898","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.923032","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.923166","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.923383","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.923526","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.923644","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.923755","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.923911","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.924038","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.924151","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.924263","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.924413","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.924543","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.924658","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.924770","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.924880","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.924990","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.925101","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.925209","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.935337","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.935590","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.935726","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.935841","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.935955","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.936063","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.936166","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.936280","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.936418","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.936542","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.936654","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.936762","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.936868","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.936973","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.937127","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.937240","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.937348","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.937497","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.937609","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.937717","level":"info","event":"25/05/28 13:02:43 INFO Executor: Told to re-register on heartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.937824","level":"info","event":"25/05/28 13:02:43 INFO BlockManager: BlockManager BlockManagerId(driver, localhost, 42069, None) re-registering with master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.937930","level":"info","event":"25/05/28 13:02:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.938036","level":"info","event":"25/05/28 13:02:43 WARN Executor: Issue communicating with driver in heartbeater","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.938143","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.938248","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.938405","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.938534","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.938684","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.938808","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.938930","level":"info","event":"at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.939056","level":"info","event":"at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.939188","level":"info","event":"at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.939390","level":"info","event":"at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.939533","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.939650","level":"info","event":"at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.955699","level":"info","event":"at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.956614","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.957283","level":"info","event":"at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.957509","level":"info","event":"at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.957652","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.957780","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.957916","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.958020","level":"info","event":"Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.958120","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.958807","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.958942","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.959070","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.959190","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.959314","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.959464","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.959818","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.960027","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.960139","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.960258","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.960365","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.960611","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.960781","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.961346","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.961523","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.961651","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.961769","level":"info","event":"... 3 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.961882","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.962083","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.962209","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.962322","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.962451","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.962576","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.962686","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.962793","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.962898","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.963018","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.963128","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:43.963236","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.023834","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.024014","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.024170","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.024258","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.024373","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.024489","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.024608","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.024744","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.024825","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.024930","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.025032","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.025108","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.025216","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.025311","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.025392","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.025505","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.025584","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.025648","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.025750","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.025834","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.025918","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.026044","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.026177","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.026337","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.026485","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.026610","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.026780","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.026894","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.027035","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.027155","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.027331","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.027451","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.027582","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.027723","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.027866","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.027998","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.028121","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.028269","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.028387","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.028497","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.028570","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.028632","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.028717","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.028810","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.028921","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.029027","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.029122","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.029203","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.029284","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.029364","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.029443","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.029522","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.029601","level":"info","event":"25/05/28 13:02:43 ERROR Inbox: Ignoring error","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.029703","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.029809","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.029901","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.029997","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.030088","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.030152","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.030218","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.030311","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.030393","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.030458","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.030518","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.030596","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.030718","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.030834","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.030927","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.031010","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.031090","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.031184","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.031279","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.031381","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.031518","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.031633","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.031763","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.031877","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.031987","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.032095","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.032219","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.032322","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.032428","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.032534","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.032638","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.032767","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.032923","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.033039","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.033148","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.033255","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.033548","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.033770","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.033986","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.034108","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.034227","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.034317","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.034409","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.034512","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.034614","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.035021","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.035186","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.035492","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.035701","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.035846","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.035965","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.036077","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.036473","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.036617","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.039399","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.039692","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.039832","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.039997","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.040117","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.040234","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.040349","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.040462","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.040615","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.040922","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.041040","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.041156","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.041309","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.041431","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.041708","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.041976","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.042111","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.042210","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.042301","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.042387","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.042471","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.042626","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.042742","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.042830","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.042911","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.042990","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.043069","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.043148","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.043270","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.043416","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.043508","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.043590","level":"info","event":"25/05/28 13:02:43 INFO Executor: Told to re-register on heartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.043674","level":"info","event":"25/05/28 13:02:43 INFO BlockManager: BlockManager BlockManagerId(driver, localhost, 42069, None) re-registering with master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.043823","level":"info","event":"25/05/28 13:02:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.043919","level":"info","event":"25/05/28 13:02:43 ERROR Inbox: Ignoring error","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.044001","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.044083","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.044164","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.044244","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.044323","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.044401","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.044507","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.044600","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.044685","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.044770","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.044849","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.044927","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.045062","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.045156","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.045239","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.045321","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.045400","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.045477","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.045621","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.045709","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.045791","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.045871","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.045953","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.046072","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.046206","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.046310","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.046406","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.046501","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.046593","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.046726","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.046828","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.046920","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.047012","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.047101","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.047246","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.047351","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.047447","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.047540","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.047631","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.047723","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.047869","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.047965","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.048058","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.048181","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.048314","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.048434","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.048544","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.048725","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.048876","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.048992","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.049092","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.049185","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.049275","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.049382","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.049488","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.049595","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.049706","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.049797","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.049917","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.050007","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.050093","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.050198","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.050284","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.050364","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.050443","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.050519","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.050596","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.050681","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.050787","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.050937","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.051042","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.051325","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.051758","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.052732","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.052972","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.107378","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.107610","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.107735","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.107837","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.108030","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.108212","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.108335","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.108592","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.108704","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.108800","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.108967","level":"info","event":"25/05/28 13:02:43 WARN Executor: Issue communicating with driver in heartbeater","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.109091","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.109256","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.109941","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.110427","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.110626","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.110900","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.111626","level":"info","event":"at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.111849","level":"info","event":"at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.112267","level":"info","event":"at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.112461","level":"info","event":"at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.112786","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.113201","level":"info","event":"at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.113355","level":"info","event":"at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.113548","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.113701","level":"info","event":"at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.113830","level":"info","event":"at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.113972","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.114159","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.114295","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.114414","level":"info","event":"Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.114533","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.114646","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.114753","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.114859","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.115010","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.115183","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.115310","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.115426","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.115541","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.115653","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.115767","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.115878","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.116016","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.116143","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.116260","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.116370","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.116478","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.116591","level":"info","event":"... 3 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.116708","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.116834","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.116951","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.117100","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.117224","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.117341","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.117460","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.117586","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.117700","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.117817","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.117937","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.118083","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.118210","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.118326","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.118441","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.118560","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.118669","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.118782","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.118894","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.119033","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.119174","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.119288","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.119437","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.119552","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.119743","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.119872","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.120019","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.120136","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.120243","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.120360","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.120746","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.120989","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.121359","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.121490","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.121769","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.121913","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.122058","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.122175","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.122315","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.122428","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.122537","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.122643","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.122750","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.122856","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.122978","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.123115","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.123219","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.123411","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.123561","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.123676","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.123787","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.123899","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.124037","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.124305","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.124415","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.124520","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.124619","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.124719","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.124907","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.125065","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.125307","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.125557","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.125765","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.125896","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.126104","level":"info","event":"25/05/28 13:02:43 INFO Executor: Told to re-register on heartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.126254","level":"info","event":"25/05/28 13:02:43 INFO BlockManager: BlockManager BlockManagerId(driver, localhost, 42069, None) re-registering with master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.126536","level":"info","event":"25/05/28 13:02:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.126733","level":"info","event":"25/05/28 13:02:43 WARN Executor: Issue communicating with driver in heartbeater","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.126910","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.127060","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.127228","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.127374","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.127497","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.127756","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.127895","level":"info","event":"at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.128095","level":"info","event":"at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.128239","level":"info","event":"at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.128535","level":"info","event":"at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.128714","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.128871","level":"info","event":"at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.129119","level":"info","event":"at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.129254","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.129572","level":"info","event":"at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.129768","level":"info","event":"at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.130330","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.130588","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.130807","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.130940","level":"info","event":"Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.131106","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.131214","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.131321","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.131427","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.131528","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.131629","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.131802","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.131924","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.132068","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.132179","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.132284","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.132389","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.132495","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.132595","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.132687","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.132778","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.132870","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.133000","level":"info","event":"... 3 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.133119","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.133250","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.133420","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.133528","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.134399","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.134624","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.134758","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.134864","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.134996","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.135122","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.135229","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.135396","level":"info","event":"at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.135508","level":"info","event":"at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.135609","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.135710","level":"info","event":"at scala.concurrent.Future.flatMap(Future.scala:306)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.135810","level":"info","event":"at scala.concurrent.Future.flatMap$(Future.scala:306)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.135906","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.136045","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.136150","level":"info","event":"... 17 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.136582","level":"info","event":"25/05/28 13:02:43 ERROR Inbox: Ignoring error","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.136727","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.136847","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.136993","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.137104","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.137213","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.137489","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.137932","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.138475","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.198193","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.198418","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.198558","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.198665","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.198769","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.198872","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.198987","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.199084","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.199198","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.199315","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.199459","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.199577","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.199712","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.199844","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.199959","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.200088","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.200207","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.200334","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.200481","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.200592","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.200715","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.200827","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.200930","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.201031","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.201137","level":"info","event":"at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.201234","level":"info","event":"at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.201333","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.201474","level":"info","event":"at scala.concurrent.Future.flatMap(Future.scala:306)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.201582","level":"info","event":"at scala.concurrent.Future.flatMap$(Future.scala:306)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.201689","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.201793","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.201898","level":"info","event":"... 17 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.202000","level":"info","event":"25/05/28 13:02:43 INFO Executor: Told to re-register on heartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.202106","level":"info","event":"25/05/28 13:02:43 INFO BlockManager: BlockManager BlockManagerId(driver, localhost, 42069, None) re-registering with master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.202203","level":"info","event":"25/05/28 13:02:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.202381","level":"info","event":"25/05/28 13:02:43 ERROR Inbox: Ignoring error","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.202511","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.202624","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.202728","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.202834","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.203006","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.203139","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.203262","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.203416","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.203544","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.203672","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.203777","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.203874","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.204051","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.204181","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.204314","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.204472","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.204609","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.204738","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.204885","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.205012","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.205124","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.205237","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.205364","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.205482","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.205556","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.205639","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.205736","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.205840","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.205955","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.206069","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.206168","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.206271","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.206398","level":"info","event":"at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.206720","level":"info","event":"at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.206866","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.206998","level":"info","event":"at scala.concurrent.Future.flatMap(Future.scala:306)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.207358","level":"info","event":"at scala.concurrent.Future.flatMap$(Future.scala:306)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.207510","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.207651","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.207727","level":"info","event":"... 17 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.208168","level":"info","event":"25/05/28 13:02:43 WARN Executor: Issue communicating with driver in heartbeater","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.208297","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.208398","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.208581","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.209221","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.209374","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.209508","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.210166","level":"info","event":"at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.210414","level":"info","event":"at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.211215","level":"info","event":"at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.211352","level":"info","event":"at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.211457","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.211735","level":"info","event":"at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.211925","level":"info","event":"at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.212047","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.212139","level":"info","event":"at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.212328","level":"info","event":"at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.212520","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.212709","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.212999","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.213241","level":"info","event":"Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.213437","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.213567","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.213763","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.213963","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.214093","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.214209","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.214321","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.214432","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.214541","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.214650","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.214758","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.214934","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.215098","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.215226","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.215349","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.215466","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.215569","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.215668","level":"info","event":"... 3 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.215797","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.215934","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.216044","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.216185","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.216305","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.216409","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.216556","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.216661","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.216756","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.216877","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.217000","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.217122","level":"info","event":"at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.217238","level":"info","event":"at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.217321","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.217411","level":"info","event":"at scala.concurrent.Future.flatMap(Future.scala:306)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.217487","level":"info","event":"at scala.concurrent.Future.flatMap$(Future.scala:306)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.217563","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.217651","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.217756","level":"info","event":"... 17 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.217895","level":"info","event":"25/05/28 13:02:43 INFO Executor: Told to re-register on heartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.218004","level":"info","event":"25/05/28 13:02:43 INFO BlockManager: BlockManager BlockManagerId(driver, localhost, 42069, None) re-registering with master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.218076","level":"info","event":"25/05/28 13:02:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.218152","level":"info","event":"25/05/28 13:02:43 WARN Executor: Issue communicating with driver in heartbeater","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.218242","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.218361","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.218480","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.218592","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.218665","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.218729","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.218825","level":"info","event":"at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.218979","level":"info","event":"at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.219077","level":"info","event":"at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.219175","level":"info","event":"at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.219303","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.219408","level":"info","event":"at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.219507","level":"info","event":"at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.219607","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.219708","level":"info","event":"at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.219808","level":"info","event":"at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.219926","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.220022","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.220118","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.220212","level":"info","event":"Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.220304","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.220389","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.220492","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.220593","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.220703","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.220817","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.220989","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.221095","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.221200","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.221304","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.221407","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.221519","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.221618","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.221712","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.221803","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.221930","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.222038","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.222105","level":"info","event":"... 3 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.222179","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.222279","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.222620","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.222765","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.223084","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.223233","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.223422","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.223539","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.223701","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.224379","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.224931","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.225344","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.225559","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.226096","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.226290","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.226456","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.226632","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.226769","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.226927","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.227046","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.227255","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.227382","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.227587","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.227707","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.288807","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.289021","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.289170","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.289672","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.290077","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.290455","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.291634","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.291972","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.292187","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.292332","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.292457","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.292566","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.292673","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.292807","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.292923","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.293030","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.293133","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.293234","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.293381","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.293490","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.293593","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.293695","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.293829","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.293940","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.294043","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.294144","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.294249","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.294360","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.294593","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.294768","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.294940","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.295071","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.295386","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.295724","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.296049","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.298706","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.301087","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.301342","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.301563","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.301699","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.301863","level":"info","event":"25/05/28 13:02:43 ERROR Inbox: Ignoring error","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.301975","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.302305","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.302433","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.302539","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.302639","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.302765","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.303471","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.303837","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.304033","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.304245","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.304387","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.304562","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.304698","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.304900","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.305042","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.305171","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.305340","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.305479","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.305607","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.305753","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.305914","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.306041","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.306166","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.306437","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.306596","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.306750","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.306890","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.307018","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.307162","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.307805","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.307984","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.308143","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.308589","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.308806","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.309058","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.309193","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.309321","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.309445","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.309570","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.309693","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.309853","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.309979","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.310100","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.310254","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.310383","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.310505","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.310620","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.312306","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.312980","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.314334","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.314941","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.315479","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.316051","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.316768","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.317981","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.318158","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.318330","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.318826","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.319301","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.319469","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.319603","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.320075","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.320614","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.321509","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.321869","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.322076","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.322213","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.322335","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.322507","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.322635","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.322815","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.322940","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.323137","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.323267","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.323407","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.323525","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.323637","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.323803","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.323923","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.324037","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.324153","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.324277","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.324402","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.324527","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.324645","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.324858","level":"info","event":"25/05/28 13:02:43 INFO Executor: Told to re-register on heartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.324994","level":"info","event":"25/05/28 13:02:43 INFO BlockManager: BlockManager BlockManagerId(driver, localhost, 42069, None) re-registering with master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.325115","level":"info","event":"25/05/28 13:02:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.325240","level":"info","event":"25/05/28 13:02:43 ERROR Inbox: Ignoring error","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.325354","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.325467","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.325601","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.325761","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.325920","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.326031","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.326130","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.326230","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.326336","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.326441","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.326570","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.326712","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.326844","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.326963","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.327081","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.327202","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.327319","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.464113","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.464353","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.464554","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.464750","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.464917","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.467539","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.467804","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.467957","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.468122","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.468269","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.468405","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.468532","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.468660","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.468777","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.468898","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.469017","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.469166","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.469288","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.472472","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.482728","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.483043","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.483264","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.483512","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.483675","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.483838","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.483992","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.484184","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.484341","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.484493","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.484636","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.484763","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.484910","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.485053","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.485237","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.485393","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.485919","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.486154","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.486319","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.486511","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.486682","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.486821","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.486979","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.487152","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.487287","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.487400","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.487533","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.487674","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.487802","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.487920","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.488032","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.488202","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.488340","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.488482","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.488641","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.488791","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.488946","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.489178","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.489572","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.493156","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.493582","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.494098","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.494257","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.494379","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.494662","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.494775","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.494870","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.494965","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.495103","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.495286","level":"info","event":"25/05/28 13:02:43 WARN Executor: Issue communicating with driver in heartbeater","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.495417","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.495515","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.495594","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.495670","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.495766","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.495861","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.495939","level":"info","event":"at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.496015","level":"info","event":"at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.496346","level":"info","event":"at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.496595","level":"info","event":"at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.496804","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.496934","level":"info","event":"at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.497118","level":"info","event":"at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.497231","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.497319","level":"info","event":"at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.498190","level":"info","event":"at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.498322","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.498414","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.498499","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.498691","level":"info","event":"Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.498790","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.498874","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.498997","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.499140","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.499389","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.499478","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.499599","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.499688","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.499813","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.499906","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.500116","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.500297","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.500566","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.500675","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.500760","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.500840","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.500922","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.501004","level":"info","event":"... 3 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.501161","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.501256","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.501346","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.501438","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.501528","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.501615","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.501702","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.501789","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.501877","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.501963","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.502087","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.502189","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.502303","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.502402","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.502493","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.502582","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.502671","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.502759","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.502847","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.502937","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.503025","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.503162","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.503276","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.506835","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.507121","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.507458","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.507618","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.507721","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.507825","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.507923","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.508180","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.508287","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.508395","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.508476","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.508553","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.508629","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.508703","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.508777","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.508851","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.508940","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.509018","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.509135","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.509229","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.509327","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.665738","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.665952","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.666099","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.666234","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.666360","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.666528","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.666661","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.666790","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.666917","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.667043","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.667174","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.667306","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.667467","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.667596","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.667721","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.667849","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.667973","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.668099","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.668223","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.668395","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.668565","level":"info","event":"25/05/28 13:02:44 INFO Executor: Told to re-register on heartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.668705","level":"info","event":"25/05/28 13:02:44 INFO BlockManager: BlockManager BlockManagerId(driver, localhost, 42069, None) re-registering with master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.668836","level":"info","event":"25/05/28 13:02:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.668960","level":"info","event":"25/05/28 13:02:44 ERROR Inbox: Ignoring error","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.669085","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.669214","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.669379","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.669544","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.669688","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.669818","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.669945","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.670073","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.670196","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.670331","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.670523","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.670661","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.670791","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.670922","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.671054","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.671186","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.671304","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.671454","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.671580","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.671691","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.671800","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.671929","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.672062","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.672194","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.672315","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.672487","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.672624","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.672749","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.672878","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.673008","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.673125","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.673243","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.673425","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.673561","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.673670","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.673768","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.673865","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.673961","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.674068","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.674174","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.674274","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.674412","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.674567","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.674679","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.674786","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.674892","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.674995","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.675101","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.675206","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.675311","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.675453","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.675960","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.676206","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.676827","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.677055","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.677295","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.678221","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.679770","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.680078","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.680306","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.680530","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.680700","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.680841","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.680967","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.681111","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.681226","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.681365","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.681503","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.681617","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.681726","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.681834","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.681987","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.682129","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.682271","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.682474","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.682606","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.682718","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.682825","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.682968","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.683079","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.683186","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.683483","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.683627","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.683748","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.683866","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.683980","level":"info","event":"25/05/28 13:02:44 INFO CodecPool: Got brand-new compressor [.snappy]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.684099","level":"info","event":"25/05/28 13:02:44 INFO CodecPool: Got brand-new compressor [.snappy]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.684222","level":"info","event":"25/05/28 13:02:44 INFO CodecPool: Got brand-new compressor [.snappy]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.684417","level":"info","event":"25/05/28 13:02:44 INFO CodecPool: Got brand-new compressor [.snappy]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.684532","level":"info","event":"25/05/28 13:02:44 INFO CodecPool: Got brand-new compressor [.snappy]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.684736","level":"info","event":"25/05/28 13:02:44 INFO CodecPool: Got brand-new compressor [.snappy]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.684870","level":"info","event":"25/05/28 13:02:44 INFO CodecPool: Got brand-new compressor [.snappy]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.684980","level":"info","event":"25/05/28 13:02:44 INFO CodecPool: Got brand-new compressor [.snappy]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.685085","level":"info","event":"25/05/28 13:02:44 INFO CodecPool: Got brand-new compressor [.snappy]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.685183","level":"info","event":"25/05/28 13:02:44 INFO CodecPool: Got brand-new compressor [.snappy]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.685295","level":"info","event":"25/05/28 13:02:44 INFO CodecPool: Got brand-new compressor [.snappy]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.685459","level":"info","event":"25/05/28 13:02:44 INFO CodecPool: Got brand-new compressor [.snappy]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.685578","level":"info","event":"25/05/28 13:02:44 WARN Executor: Issue communicating with driver in heartbeater","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.685687","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.685792","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.685899","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.686013","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.686122","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.686233","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.686425","level":"info","event":"at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.686591","level":"info","event":"at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.686727","level":"info","event":"at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.686852","level":"info","event":"at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.686971","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.687089","level":"info","event":"at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.687204","level":"info","event":"at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.687355","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.687487","level":"info","event":"at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.687637","level":"info","event":"at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.687757","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.687873","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.687985","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.688095","level":"info","event":"Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.688206","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.688317","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.688466","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.688581","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.688696","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.688810","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.688920","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.689033","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.689145","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.689255","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.689395","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.689518","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.689633","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.689745","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.689857","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.689968","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.690079","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.690191","level":"info","event":"... 3 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.690328","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.690489","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.690607","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.690718","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.690870","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.690999","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.691113","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.691224","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.691386","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.691519","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.691636","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.691752","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.691866","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.691979","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.692138","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.692261","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.692407","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.692669","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.692896","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.693093","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.693237","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.693909","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.694153","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.694436","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.926635","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.927531","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.927707","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.927820","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.927940","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.928062","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.928221","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.928324","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.928444","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.928555","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.928653","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.928806","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.928986","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.929079","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.929321","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.929446","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.929544","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.929638","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.929726","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.929811","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.929896","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.929986","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.930072","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.930192","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.930459","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.930588","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.930698","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.930805","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.930909","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.931010","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.931150","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.931353","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.931455","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.931544","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.931627","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.931706","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.931783","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.931859","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.931936","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.932033","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.932155","level":"info","event":"25/05/28 13:02:44 INFO Executor: Told to re-register on heartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.932252","level":"info","event":"25/05/28 13:02:44 INFO BlockManager: BlockManager BlockManagerId(driver, localhost, 42069, None) re-registering with master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.932336","level":"info","event":"25/05/28 13:02:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.932426","level":"info","event":"25/05/28 13:02:44 ERROR Inbox: Ignoring error","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.932516","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.932601","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.932679","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.932768","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.932857","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.932944","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.933033","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.933281","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.933823","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.934194","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.934329","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.934440","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.934542","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.934640","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.934735","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.934831","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.934924","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.935020","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.935171","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.935325","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.935449","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.935567","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.935679","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.935794","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.935899","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.936003","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.936181","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.936311","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.936416","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.936518","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.936645","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.936735","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.936819","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.936899","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.936976","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.937053","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.937160","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.937250","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.937335","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.937418","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.937497","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.937573","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.937649","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.937724","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.937822","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.937911","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.938005","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.938085","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.938199","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.938281","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.938360","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.938439","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.938515","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.938592","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.938670","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.938748","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.938827","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.938904","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.938986","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.939068","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.939192","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.939348","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.939438","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.939521","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.939600","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.939678","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.939759","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.939839","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.939923","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.940022","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.940143","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.940242","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.940327","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.940408","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.940490","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.940571","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.940650","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.940730","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.940813","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.940893","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.940990","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.941073","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.941195","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.941285","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.941371","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.941455","level":"info","event":"25/05/28 13:02:44 WARN Executor: Issue communicating with driver in heartbeater","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.941539","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.941622","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.941705","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:44.941787","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.049863","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.050092","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.050251","level":"info","event":"at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.050417","level":"info","event":"at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.050561","level":"info","event":"at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.050687","level":"info","event":"at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.050809","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.050939","level":"info","event":"at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.051053","level":"info","event":"at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.051165","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.051276","level":"info","event":"at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.051387","level":"info","event":"at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.051538","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.051645","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.051752","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.051869","level":"info","event":"Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.051966","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.052065","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.052163","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.052265","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.052380","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.052530","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.052646","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.052761","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.052897","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.053012","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.053125","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.053267","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.053466","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.053597","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.053717","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.053857","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.053973","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.054084","level":"info","event":"... 3 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.054199","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.054313","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.054454","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.054577","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.054693","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.054807","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.054928","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.055045","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.055161","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.055283","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.055426","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.055545","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.055648","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.055752","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.055875","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.055978","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.056087","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.056196","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.056310","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.056453","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.056590","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.056711","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.056829","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.056949","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.057063","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.057180","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.057299","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.057447","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.057573","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.057691","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.057805","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.057914","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.058026","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.058145","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.058267","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.058422","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.058547","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.058659","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.058821","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.061540","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.062209","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.062493","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.062666","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.062876","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.064858","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.065092","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.065234","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.065358","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.065513","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.065625","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.065733","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.065836","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.070383","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.070622","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.070762","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.070907","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.071028","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.071147","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.071265","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.071413","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.071547","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.071668","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.071801","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:45.071915","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.802596","level":"info","event":"25/05/28 13:02:51 INFO FileOutputCommitter: Saved output of task 'attempt_202505281300242330201223000684774_0015_m_000004_69' to s3a://etl-dag/silver/data/customers/_temporary/0/task_202505281300242330201223000684774_0015_m_000004","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.804070","level":"info","event":"25/05/28 13:02:51 INFO SparkHadoopMapRedUtil: attempt_202505281300242330201223000684774_0015_m_000004_69: Committed. Elapsed time: 962 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.899866","level":"info","event":"25/05/28 13:02:51 INFO Executor: Finished task 4.0 in stage 15.0 (TID 69). 7529 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.915537","level":"info","event":"25/05/28 13:02:51 INFO TaskSetManager: Starting task 12.0 in stage 15.0 (TID 77) (localhost, executor driver, partition 12, NODE_LOCAL, 7897 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.915800","level":"info","event":"25/05/28 13:02:51 INFO FileOutputCommitter: Saved output of task 'attempt_202505281300242330201223000684774_0015_m_000010_75' to s3a://etl-dag/silver/data/customers/_temporary/0/task_202505281300242330201223000684774_0015_m_000010","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.915961","level":"info","event":"25/05/28 13:02:51 INFO SparkHadoopMapRedUtil: attempt_202505281300242330201223000684774_0015_m_000010_75: Committed. Elapsed time: 863 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.918554","level":"info","event":"25/05/28 13:02:51 INFO Executor: Finished task 10.0 in stage 15.0 (TID 75). 7486 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.924029","level":"info","event":"25/05/28 13:02:51 INFO Executor: Running task 12.0 in stage 15.0 (TID 77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.957423","level":"info","event":"25/05/28 13:02:51 INFO TaskSetManager: Finished task 10.0 in stage 15.0 (TID 75) in 146588 ms on localhost (executor driver) (1/13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.957674","level":"info","event":"25/05/28 13:02:51 INFO TaskSetManager: Finished task 4.0 in stage 15.0 (TID 69) in 146595 ms on localhost (executor driver) (2/13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.963863","level":"info","event":"25/05/28 13:02:51 INFO FileOutputCommitter: Saved output of task 'attempt_202505281300242330201223000684774_0015_m_000006_71' to s3a://etl-dag/silver/data/customers/_temporary/0/task_202505281300242330201223000684774_0015_m_000006","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.964113","level":"info","event":"25/05/28 13:02:51 INFO SparkHadoopMapRedUtil: attempt_202505281300242330201223000684774_0015_m_000006_71: Committed. Elapsed time: 729 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.966951","level":"info","event":"25/05/28 13:02:51 INFO Executor: Finished task 6.0 in stage 15.0 (TID 71). 7486 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.971050","level":"info","event":"25/05/28 13:02:51 INFO TaskSetManager: Finished task 6.0 in stage 15.0 (TID 71) in 146614 ms on localhost (executor driver) (3/13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.972131","level":"info","event":"25/05/28 13:02:51 INFO FileOutputCommitter: Saved output of task 'attempt_202505281300242330201223000684774_0015_m_000011_76' to s3a://etl-dag/silver/data/customers/_temporary/0/task_202505281300242330201223000684774_0015_m_000011","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.972285","level":"info","event":"25/05/28 13:02:51 INFO SparkHadoopMapRedUtil: attempt_202505281300242330201223000684774_0015_m_000011_76: Committed. Elapsed time: 756 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.998697","level":"info","event":"25/05/28 13:02:51 INFO ShuffleBlockFetcherIterator: Getting 12 (1502.5 KiB) non-empty blocks including 12 (1502.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:51.999334","level":"info","event":"25/05/28 13:02:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.001226","level":"info","event":"25/05/28 13:02:52 INFO Executor: Told to re-register on heartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.001434","level":"info","event":"25/05/28 13:02:52 INFO BlockManager: BlockManager BlockManagerId(driver, localhost, 42069, None) re-registering with master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.001564","level":"info","event":"25/05/28 13:02:52 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.001686","level":"info","event":"25/05/28 13:02:52 INFO Executor: Finished task 11.0 in stage 15.0 (TID 76). 7486 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.005697","level":"info","event":"25/05/28 13:02:52 INFO TaskSetManager: Finished task 11.0 in stage 15.0 (TID 76) in 146645 ms on localhost (executor driver) (4/13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.007234","level":"info","event":"25/05/28 13:02:52 ERROR Inbox: Ignoring error","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.007428","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.007551","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.007685","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.007799","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.007904","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.008026","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.008134","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.008243","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.008350","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.008452","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.008584","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.008697","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.008806","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.008918","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.009011","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.009901","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.010075","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.010188","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.010285","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.010412","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.010513","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.010610","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.010710","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.010814","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.010924","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.011011","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.011098","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.011196","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.032048","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.032256","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.032476","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.032592","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.032702","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.032796","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.032885","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.032976","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.033069","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.033171","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.033334","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.033443","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.033529","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.033621","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.033697","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.033771","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.033843","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.033917","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.033989","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.034062","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.034140","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.034308","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.034397","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.040106","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.040655","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.040894","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.041051","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.041166","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.041274","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.041384","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.043421","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.043610","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.043740","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.043845","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.043943","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.044048","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.047111","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.050414","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.050669","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.051135","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.051258","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.051350","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.051433","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.051514","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.051793","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.051896","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.051981","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.052061","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.052138","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.052214","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.052290","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.059058","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.059485","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.059810","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.060818","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.063737","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.063933","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.064080","level":"info","event":"25/05/28 13:02:52 WARN Executor: Issue communicating with driver in heartbeater","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.064215","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.064321","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.064457","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.064570","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.064668","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.064763","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.064855","level":"info","event":"at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.064954","level":"info","event":"at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.065044","level":"info","event":"at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.065133","level":"info","event":"at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.065222","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.065312","level":"info","event":"at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.065428","level":"info","event":"at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.065492","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.065552","level":"info","event":"at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.065611","level":"info","event":"at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.065671","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.065729","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.065786","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.065843","level":"info","event":"Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.065901","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.065958","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.066014","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.066070","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.066126","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.066183","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.066300","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.066389","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.066454","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.066514","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.066590","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.066652","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.066713","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.066772","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.066832","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.066892","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.066951","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.067009","level":"info","event":"... 3 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.067068","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.067128","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.067241","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.067346","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.067442","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.067535","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.067624","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.067721","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.067818","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.067920","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.068025","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.068155","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.068268","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.068372","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.068472","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.068572","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.068669","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.068762","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.068855","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.068950","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.069174","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.069318","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.069440","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.069568","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.069801","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.069959","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.070137","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.070248","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.070345","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.070437","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.070525","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.070609","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.070695","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.070782","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.070962","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.071115","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.071237","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.071388","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.071500","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.071611","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.071720","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.071859","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.072007","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.072124","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.072235","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.072345","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.072453","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.072572","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.072707","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.072824","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.072932","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.073054","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.073162","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.073280","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.075303","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.076027","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.076175","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.076287","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.076442","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.277771","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.277982","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.278140","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.278254","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.278374","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.278476","level":"info","event":"25/05/28 13:02:52 INFO FileOutputCommitter: Saved output of task 'attempt_202505281300242330201223000684774_0015_m_000007_72' to s3a://etl-dag/silver/data/customers/_temporary/0/task_202505281300242330201223000684774_0015_m_000007","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.278577","level":"info","event":"25/05/28 13:02:52 INFO SparkHadoopMapRedUtil: attempt_202505281300242330201223000684774_0015_m_000007_72: Committed. Elapsed time: 793 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.278678","level":"info","event":"25/05/28 13:02:52 INFO Executor: Finished task 7.0 in stage 15.0 (TID 72). 7486 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.278775","level":"info","event":"25/05/28 13:02:52 INFO TaskSetManager: Finished task 7.0 in stage 15.0 (TID 72) in 146713 ms on localhost (executor driver) (5/13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.278906","level":"info","event":"25/05/28 13:02:52 INFO FileOutputCommitter: Saved output of task 'attempt_202505281300242330201223000684774_0015_m_000005_70' to s3a://etl-dag/silver/data/customers/_temporary/0/task_202505281300242330201223000684774_0015_m_000005","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.279020","level":"info","event":"25/05/28 13:02:52 INFO SparkHadoopMapRedUtil: attempt_202505281300242330201223000684774_0015_m_000005_70: Committed. Elapsed time: 804 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.279119","level":"info","event":"25/05/28 13:02:52 INFO Executor: Finished task 5.0 in stage 15.0 (TID 70). 7486 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.279218","level":"info","event":"25/05/28 13:02:52 INFO TaskSetManager: Finished task 5.0 in stage 15.0 (TID 70) in 146754 ms on localhost (executor driver) (6/13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.379297","level":"info","event":"25/05/28 13:02:52 INFO FileOutputCommitter: Saved output of task 'attempt_202505281300242330201223000684774_0015_m_000003_68' to s3a://etl-dag/silver/data/customers/_temporary/0/task_202505281300242330201223000684774_0015_m_000003","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.379569","level":"info","event":"25/05/28 13:02:52 INFO SparkHadoopMapRedUtil: attempt_202505281300242330201223000684774_0015_m_000003_68: Committed. Elapsed time: 1069 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.381143","level":"info","event":"25/05/28 13:02:52 INFO Executor: Finished task 3.0 in stage 15.0 (TID 68). 7486 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.385099","level":"info","event":"25/05/28 13:02:52 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 68) in 147029 ms on localhost (executor driver) (7/13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.406018","level":"info","event":"25/05/28 13:02:52 INFO FileOutputCommitter: Saved output of task 'attempt_202505281300242330201223000684774_0015_m_000008_73' to s3a://etl-dag/silver/data/customers/_temporary/0/task_202505281300242330201223000684774_0015_m_000008","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.406255","level":"info","event":"25/05/28 13:02:52 INFO SparkHadoopMapRedUtil: attempt_202505281300242330201223000684774_0015_m_000008_73: Committed. Elapsed time: 1253 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.408291","level":"info","event":"25/05/28 13:02:52 INFO Executor: Finished task 8.0 in stage 15.0 (TID 73). 7486 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.410015","level":"info","event":"25/05/28 13:02:52 INFO TaskSetManager: Finished task 8.0 in stage 15.0 (TID 73) in 147052 ms on localhost (executor driver) (8/13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.442265","level":"info","event":"25/05/28 13:02:52 INFO FileOutputCommitter: Saved output of task 'attempt_202505281300242330201223000684774_0015_m_000001_66' to s3a://etl-dag/silver/data/customers/_temporary/0/task_202505281300242330201223000684774_0015_m_000001","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.442679","level":"info","event":"25/05/28 13:02:52 INFO SparkHadoopMapRedUtil: attempt_202505281300242330201223000684774_0015_m_000001_66: Committed. Elapsed time: 674 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.445022","level":"info","event":"25/05/28 13:02:52 INFO Executor: Finished task 1.0 in stage 15.0 (TID 66). 7486 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.446702","level":"info","event":"25/05/28 13:02:52 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 66) in 147092 ms on localhost (executor driver) (9/13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.516453","level":"info","event":"25/05/28 13:02:52 INFO FileOutputCommitter: Saved output of task 'attempt_202505281300242330201223000684774_0015_m_000000_65' to s3a://etl-dag/silver/data/customers/_temporary/0/task_202505281300242330201223000684774_0015_m_000000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.517255","level":"info","event":"25/05/28 13:02:52 INFO SparkHadoopMapRedUtil: attempt_202505281300242330201223000684774_0015_m_000000_65: Committed. Elapsed time: 396 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.519700","level":"info","event":"25/05/28 13:02:52 INFO Executor: Finished task 0.0 in stage 15.0 (TID 65). 7486 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.522665","level":"info","event":"25/05/28 13:02:52 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 65) in 147172 ms on localhost (executor driver) (10/13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.555422","level":"info","event":"25/05/28 13:02:52 INFO FileOutputCommitter: Saved output of task 'attempt_202505281300242330201223000684774_0015_m_000002_67' to s3a://etl-dag/silver/data/customers/_temporary/0/task_202505281300242330201223000684774_0015_m_000002","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.555976","level":"info","event":"25/05/28 13:02:52 INFO SparkHadoopMapRedUtil: attempt_202505281300242330201223000684774_0015_m_000002_67: Committed. Elapsed time: 1173 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.586807","level":"info","event":"25/05/28 13:02:52 INFO Executor: Finished task 2.0 in stage 15.0 (TID 67). 7529 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.587024","level":"info","event":"25/05/28 13:02:52 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 67) in 147231 ms on localhost (executor driver) (11/13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.894080","level":"info","event":"25/05/28 13:02:52 INFO FileOutputCommitter: Saved output of task 'attempt_202505281300242330201223000684774_0015_m_000009_74' to s3a://etl-dag/silver/data/customers/_temporary/0/task_202505281300242330201223000684774_0015_m_000009","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.895170","level":"info","event":"25/05/28 13:02:52 INFO SparkHadoopMapRedUtil: attempt_202505281300242330201223000684774_0015_m_000009_74: Committed. Elapsed time: 973 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.897728","level":"info","event":"25/05/28 13:02:52 INFO Executor: Finished task 9.0 in stage 15.0 (TID 74). 7486 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.901769","level":"info","event":"25/05/28 13:02:52 INFO TaskSetManager: Finished task 9.0 in stage 15.0 (TID 74) in 147541 ms on localhost (executor driver) (12/13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.942910","level":"info","event":"25/05/28 13:02:52 INFO ShuffleBlockFetcherIterator: Getting 12 (219.5 KiB) non-empty blocks including 12 (219.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:52.943963","level":"info","event":"25/05/28 13:02:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.053645","level":"info","event":"25/05/28 13:02:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.054381","level":"info","event":"25/05/28 13:02:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.061001","level":"info","event":"25/05/28 13:02:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.063604","level":"info","event":"25/05/28 13:02:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.064169","level":"info","event":"25/05/28 13:02:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.068631","level":"info","event":"25/05/28 13:02:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.212371","level":"info","event":"25/05/28 13:02:53 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.213262","level":"info","event":"25/05/28 13:02:53 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.215046","level":"info","event":"25/05/28 13:02:53 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.217810","level":"info","event":"25/05/28 13:02:53 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.218021","level":"info","event":"{","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.218135","level":"info","event":"\"type\" : \"struct\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.218239","level":"info","event":"\"fields\" : [ {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.218364","level":"info","event":"\"name\" : \"Customer_ID\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.218477","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.218575","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.218677","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.218781","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.219013","level":"info","event":"\"name\" : \"Name\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.219161","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.219312","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.219432","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.219585","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.219824","level":"info","event":"\"name\" : \"Email\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.219975","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.220090","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.220385","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.220526","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.220644","level":"info","event":"\"name\" : \"Phone\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.220757","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.220921","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.221026","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.221206","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.221453","level":"info","event":"\"name\" : \"Address\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.221651","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.221922","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.222079","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.222191","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.222294","level":"info","event":"\"name\" : \"City\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.222685","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.222870","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.223006","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.223117","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.223214","level":"info","event":"\"name\" : \"State\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.223385","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.223500","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.223676","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.223783","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.224069","level":"info","event":"\"name\" : \"Zipcode\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.224205","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.224305","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.224399","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.224486","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.224569","level":"info","event":"\"name\" : \"Country\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.224655","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.224738","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.224863","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.224961","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.225046","level":"info","event":"\"name\" : \"Age\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.225131","level":"info","event":"\"type\" : \"integer\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.225214","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.225295","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.225387","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.225484","level":"info","event":"\"name\" : \"Gender\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.225583","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.225687","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.226028","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.226225","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.226358","level":"info","event":"\"name\" : \"Income\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.226982","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.227114","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.227212","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.227306","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.227407","level":"info","event":"\"name\" : \"Customer_Segment\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.227498","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.227616","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.227865","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.227963","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.228053","level":"info","event":"\"name\" : \"total_orders\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.228141","level":"info","event":"\"type\" : \"long\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.228232","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.228317","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.228403","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.229251","level":"info","event":"\"name\" : \"total_spent\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.229392","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.229504","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.229596","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.229686","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.229772","level":"info","event":"\"name\" : \"avg_rating\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.229854","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.229935","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.230018","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.231849","level":"info","event":"} ]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.232018","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.232116","level":"info","event":"and corresponding Parquet message type:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.232489","level":"info","event":"message spark_schema {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.232594","level":"info","event":"optional binary Customer_ID (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.232687","level":"info","event":"optional binary Name (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.232776","level":"info","event":"optional binary Email (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.232876","level":"info","event":"optional binary Phone (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.232967","level":"info","event":"optional binary Address (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.233083","level":"info","event":"optional binary City (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.233181","level":"info","event":"optional binary State (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.233275","level":"info","event":"optional binary Zipcode (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.233384","level":"info","event":"optional binary Country (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.233470","level":"info","event":"optional int32 Age;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.233554","level":"info","event":"optional binary Gender (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.233634","level":"info","event":"optional binary Income (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.233716","level":"info","event":"optional binary Customer_Segment (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.233797","level":"info","event":"optional int64 total_orders;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.233931","level":"info","event":"optional double total_spent;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.234061","level":"info","event":"optional double avg_rating;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.234153","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.234242","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:53.234326","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:57.310651","level":"info","event":"25/05/28 13:02:57 INFO FileOutputCommitter: Saved output of task 'attempt_202505281300242330201223000684774_0015_m_000012_77' to s3a://etl-dag/silver/data/customers/_temporary/0/task_202505281300242330201223000684774_0015_m_000012","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:57.311035","level":"info","event":"25/05/28 13:02:57 INFO SparkHadoopMapRedUtil: attempt_202505281300242330201223000684774_0015_m_000012_77: Committed. Elapsed time: 3322 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:57.312713","level":"info","event":"25/05/28 13:02:57 INFO Executor: Finished task 12.0 in stage 15.0 (TID 77). 7443 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:57.314269","level":"info","event":"25/05/28 13:02:57 INFO TaskSetManager: Finished task 12.0 in stage 15.0 (TID 77) in 5399 ms on localhost (executor driver) (13/13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:57.314401","level":"info","event":"25/05/28 13:02:57 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:57.315450","level":"info","event":"25/05/28 13:02:57 INFO DAGScheduler: ResultStage 15 (parquet at NativeMethodAccessorImpl.java:0) finished in 152.391 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:57.315743","level":"info","event":"25/05/28 13:02:57 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:57.315862","level":"info","event":"25/05/28 13:02:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:57.316208","level":"info","event":"25/05/28 13:02:57 INFO DAGScheduler: Job 9 finished: parquet at NativeMethodAccessorImpl.java:0, took 152.672723 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:02:57.319233","level":"info","event":"25/05/28 13:02:57 INFO FileFormatWriter: Start to commit write Job 2e195832-d024-4f50-976d-ae4151b90f77.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.996644","level":"info","event":"25/05/28 13:03:01 INFO Executor: Told to re-register on heartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.996865","level":"info","event":"25/05/28 13:03:01 INFO BlockManager: BlockManager BlockManagerId(driver, localhost, 42069, None) re-registering with master","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.996943","level":"info","event":"25/05/28 13:03:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42069, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.997765","level":"info","event":"25/05/28 13:03:01 ERROR Inbox: Ignoring error","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.997959","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.998054","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.998134","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.998211","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.998285","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.998376","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.998474","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.998555","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.998647","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.998742","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.998815","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.998886","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.999002","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.999076","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.999146","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.999216","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.999294","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.999380","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.999498","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.999579","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.999650","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.999721","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.999794","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.999864","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:01.999933","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.000048","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.000130","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.000201","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.000274","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.000344","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.000414","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.000512","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.000596","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.000667","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.000747","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.000850","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.000920","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.000987","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.001108","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.001181","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.001249","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.001317","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.001387","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.001459","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.001565","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.001649","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.001721","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.001790","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.001857","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.001925","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.001993","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.002084","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.002176","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.002253","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.002323","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.002394","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.002463","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.002531","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.002628","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.002706","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.002794","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.002877","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.002952","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.003023","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.003091","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.003190","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.003264","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.003381","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.003460","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.003526","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.003578","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.003650","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.003710","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.003759","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.003806","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.003861","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.003913","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.003971","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004029","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004076","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004121","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004209","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004265","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004336","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004389","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004455","level":"info","event":"25/05/28 13:03:01 WARN Executor: Issue communicating with driver in heartbeater","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004502","level":"info","event":"org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004549","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004595","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004641","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004716","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004788","level":"info","event":"at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004837","level":"info","event":"at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004885","level":"info","event":"at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004933","level":"info","event":"at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.004981","level":"info","event":"at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005027","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005074","level":"info","event":"at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005121","level":"info","event":"at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005168","level":"info","event":"at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005253","level":"info","event":"at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005310","level":"info","event":"at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005358","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005406","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005453","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005500","level":"info","event":"Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005547","level":"info","event":"at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005594","level":"info","event":"at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005641","level":"info","event":"at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005687","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005781","level":"info","event":"at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005845","level":"info","event":"at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005901","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.005950","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.006000","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.006049","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.006097","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.006153","level":"info","event":"at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.006221","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.006307","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.006372","level":"info","event":"at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.006449","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.006521","level":"info","event":"at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.006590","level":"info","event":"... 3 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.006660","level":"info","event":"Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:33791","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.006724","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.006846","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.006932","level":"info","event":"at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.007007","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.007079","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.007152","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.007217","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.007280","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.007375","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.007436","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.007488","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.007538","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.007588","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.007649","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.007720","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.007793","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.007841","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.007930","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.007983","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.008032","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.008081","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.008130","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.008177","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.008225","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.008284","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.008353","level":"info","event":"at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.008458","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.008527","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.008606","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.008689","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.008788","level":"info","event":"at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.008874","level":"info","event":"at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.009016","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.009116","level":"info","event":"at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.009204","level":"info","event":"at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.009293","level":"info","event":"at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.009381","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.009469","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.009601","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.009676","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.009737","level":"info","event":"at scala.concurrent.Promise.trySuccess(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.009822","level":"info","event":"at scala.concurrent.Promise.trySuccess$(Promise.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.009916","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.009995","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.010087","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.010166","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.010245","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.010325","level":"info","event":"at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.010400","level":"info","event":"at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.010489","level":"info","event":"at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.010584","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.010647","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.010699","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.010765","level":"info","event":"at scala.concurrent.Promise.complete(Promise.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.010816","level":"info","event":"at scala.concurrent.Promise.complete$(Promise.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.010867","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.010917","level":"info","event":"at scala.concurrent.Promise.success(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.010969","level":"info","event":"at scala.concurrent.Promise.success$(Promise.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.011019","level":"info","event":"at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.011069","level":"info","event":"at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.011179","level":"info","event":"at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.011236","level":"info","event":"at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:02.011289","level":"info","event":"... 8 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:09.497225","level":"info","event":"25/05/28 13:03:09 INFO FileFormatWriter: Write Job 2e195832-d024-4f50-976d-ae4151b90f77 committed. Elapsed time: 12176 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:09.502403","level":"info","event":"25/05/28 13:03:09 INFO FileFormatWriter: Finished processing stats for write job 2e195832-d024-4f50-976d-ae4151b90f77.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:09.532495","level":"info","event":"25/05/28 13:03:09 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:09.532959","level":"info","event":"Customer processing completed successfully!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:09.581635","level":"info","event":"25/05/28 13:03:09 INFO SparkUI: Stopped Spark web UI at http://localhost:4042","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:09.636413","level":"info","event":"25/05/28 13:03:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:09.947691","level":"info","event":"25/05/28 13:03:09 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:09.947959","level":"info","event":"25/05/28 13:03:09 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:09.959140","level":"info","event":"25/05/28 13:03:09 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:09.973217","level":"info","event":"25/05/28 13:03:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:09.994018","level":"info","event":"25/05/28 13:03:09 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:10.573256","level":"info","event":"25/05/28 13:03:10 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:10.574075","level":"info","event":"25/05/28 13:03:10 INFO ShutdownHookManager: Deleting directory /tmp/spark-350f3936-c0e8-435b-8c49-c891ae1504eb","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:10.582117","level":"info","event":"25/05/28 13:03:10 INFO ShutdownHookManager: Deleting directory /tmp/spark-a2062ff5-c3c6-49b7-9e26-d24446e64e1d","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:10.588108","level":"info","event":"25/05/28 13:03:10 INFO ShutdownHookManager: Deleting directory /tmp/spark-350f3936-c0e8-435b-8c49-c891ae1504eb/pyspark-642587a8-c49c-475a-8550-aad8752bdac3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:10.622162","level":"info","event":"25/05/28 13:03:10 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:10.622667","level":"info","event":"25/05/28 13:03:10 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:03:10.623003","level":"info","event":"25/05/28 13:03:10 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
