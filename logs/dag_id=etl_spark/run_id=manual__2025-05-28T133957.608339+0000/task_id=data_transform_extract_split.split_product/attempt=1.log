{"timestamp":"2025-05-28T13:42:16.275777","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-05-28T13:42:16.276917","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/ETL_dags.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-05-28T13:42:17.252217","level":"info","event":"Secrets backends loaded for worker","count":1,"backend_classes":["EnvironmentVariablesBackend"],"logger":"supervisor"}
{"timestamp":"2025-05-28T13:42:17.820648","level":"info","event":"Connection Retrieved 'spark_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-05-28T13:42:17.822389","level":"info","event":"Spark-Submit cmd: spark-submit --master local[*] --conf spark.master=local[*] --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 --conf spark.hadoop.fs.s3a.access.key=minioLocalAccessKey --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.hadoop.fs.s3a.attempts.maximum=3 --conf spark.hadoop.fs.s3a.connection.establish.timeout=5000 --conf spark.hadoop.fs.s3a.connection.timeout=200000 --conf spark.hadoop.fs.s3a.buffer.dir=/tmp --conf spark.hadoop.fs.s3a.fast.upload=true --conf spark.hadoop.fs.s3a.fast.upload.buffer=disk --conf spark.hadoop.fs.s3a.multipart.size=104857600 --conf spark.hadoop.fs.s3a.multipart.threshold=2147483647 --driver-memory 2g --name split-product-local --verbose --deploy-mode client /opt/airflow/dags/spark_jobs/split_product.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.396783","level":"info","event":"Using properties file: /opt/spark/conf/spark-defaults.conf","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.496210","level":"info","event":"Adding default property: spark.executor.extraClassPath=/opt/spark-jars/*","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.496525","level":"info","event":"Adding default property: spark.sql.adaptive.coalescePartitions.enabled=true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.496686","level":"info","event":"Adding default property: spark.sql.adaptive.enabled=true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.496824","level":"info","event":"Adding default property: spark.driver.extraClassPath=/opt/spark-jars/*","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.515499","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.515689","level":"info","event":"master                  local[*]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.515775","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.515840","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.515943","level":"info","event":"executorMemory          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.516007","level":"info","event":"executorCores           null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.516130","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.516205","level":"info","event":"propertiesFile          /opt/spark/conf/spark-defaults.conf","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.516268","level":"info","event":"driverMemory            2g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.516326","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.516442","level":"info","event":"driverExtraClassPath    /opt/spark-jars/*","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.516580","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.516698","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.516840","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.516978","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.517121","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.517249","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.517393","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.517519","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.517682","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.517858","level":"info","event":"primaryResource         file:/opt/airflow/dags/spark_jobs/split_product.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.517965","level":"info","event":"name                    split-product-local","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.518136","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.518267","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.518417","level":"info","event":"packages                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.518584","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.518735","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.518905","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.519078","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.519247","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.519395","level":"info","event":"--conf and those from the properties file /opt/spark/conf/spark-defaults.conf:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.519562","level":"info","event":"(spark.driver.extraClassPath,/opt/spark-jars/*)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.519741","level":"info","event":"(spark.driver.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.519929","level":"info","event":"(spark.executor.extraClassPath,/opt/spark-jars/*)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.520058","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.520229","level":"info","event":"(spark.hadoop.fs.s3a.attempts.maximum,3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.520404","level":"info","event":"(spark.hadoop.fs.s3a.aws.credentials.provider,org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.520550","level":"info","event":"(spark.hadoop.fs.s3a.buffer.dir,/tmp)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.520726","level":"info","event":"(spark.hadoop.fs.s3a.connection.establish.timeout,5000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.520947","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.521081","level":"info","event":"(spark.hadoop.fs.s3a.connection.timeout,200000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.521246","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://minio:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.521386","level":"info","event":"(spark.hadoop.fs.s3a.fast.upload,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.521545","level":"info","event":"(spark.hadoop.fs.s3a.fast.upload.buffer,disk)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.521717","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.521880","level":"info","event":"(spark.hadoop.fs.s3a.multipart.size,104857600)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.522043","level":"info","event":"(spark.hadoop.fs.s3a.multipart.threshold,2147483647)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.522205","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.522331","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.522491","level":"info","event":"(spark.master,local[*])","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.522664","level":"info","event":"(spark.sql.adaptive.coalescePartitions.enabled,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.522820","level":"info","event":"(spark.sql.adaptive.enabled,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.523023","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.523186","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.772802","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.772979","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.773077","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.773150","level":"info","event":"file:/opt/airflow/dags/spark_jobs/split_product.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.773217","level":"info","event":"null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.777630","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.777849","level":"info","event":"(spark.app.name,split-product-local)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.777979","level":"info","event":"(spark.app.submitTime,1748439739756)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.778096","level":"info","event":"(spark.driver.extraClassPath,/opt/spark-jars/*)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.778196","level":"info","event":"(spark.driver.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.778357","level":"info","event":"(spark.executor.extraClassPath,/opt/spark-jars/*)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.778482","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.778599","level":"info","event":"(spark.hadoop.fs.s3a.attempts.maximum,3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.778704","level":"info","event":"(spark.hadoop.fs.s3a.aws.credentials.provider,org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.778827","level":"info","event":"(spark.hadoop.fs.s3a.buffer.dir,/tmp)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.778933","level":"info","event":"(spark.hadoop.fs.s3a.connection.establish.timeout,5000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.779099","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.779201","level":"info","event":"(spark.hadoop.fs.s3a.connection.timeout,200000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.779317","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://minio:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.779485","level":"info","event":"(spark.hadoop.fs.s3a.fast.upload,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.779602","level":"info","event":"(spark.hadoop.fs.s3a.fast.upload.buffer,disk)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.779807","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.779984","level":"info","event":"(spark.hadoop.fs.s3a.multipart.size,104857600)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.780137","level":"info","event":"(spark.hadoop.fs.s3a.multipart.threshold,2147483647)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.780254","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.780362","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.780529","level":"info","event":"(spark.master,local[*])","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.780638","level":"info","event":"(spark.sql.adaptive.coalescePartitions.enabled,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.780740","level":"info","event":"(spark.sql.adaptive.enabled,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.780955","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.781071","level":"info","event":"(spark.submit.pyFiles,)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.781252","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.781378","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.781480","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:19.781648","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.154642","level":"info","event":"25/05/28 13:42:21 INFO SparkContext: Running Spark version 3.5.1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.157693","level":"info","event":"25/05/28 13:42:21 INFO SparkContext: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.157995","level":"info","event":"25/05/28 13:42:21 INFO SparkContext: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.222670","level":"info","event":"25/05/28 13:42:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.314297","level":"info","event":"25/05/28 13:42:21 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.314746","level":"info","event":"25/05/28 13:42:21 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.315103","level":"info","event":"25/05/28 13:42:21 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.315540","level":"info","event":"25/05/28 13:42:21 INFO SparkContext: Submitted application: split_product","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.335531","level":"info","event":"25/05/28 13:42:21 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.344474","level":"info","event":"25/05/28 13:42:21 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.345697","level":"info","event":"25/05/28 13:42:21 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.405238","level":"info","event":"25/05/28 13:42:21 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.405751","level":"info","event":"25/05/28 13:42:21 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.406652","level":"info","event":"25/05/28 13:42:21 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.407485","level":"info","event":"25/05/28 13:42:21 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.408169","level":"info","event":"25/05/28 13:42:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.676130","level":"info","event":"25/05/28 13:42:21 INFO Utils: Successfully started service 'sparkDriver' on port 45439.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.705751","level":"info","event":"25/05/28 13:42:21 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.745941","level":"info","event":"25/05/28 13:42:21 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.769323","level":"info","event":"25/05/28 13:42:21 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.770081","level":"info","event":"25/05/28 13:42:21 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.774369","level":"info","event":"25/05/28 13:42:21 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.801512","level":"info","event":"25/05/28 13:42:21 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-af36deb1-5016-4dd1-a110-7d3af5daa1f5","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.824179","level":"info","event":"25/05/28 13:42:21 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.847591","level":"info","event":"25/05/28 13:42:21 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:21.995658","level":"info","event":"25/05/28 13:42:21 INFO JettyUtils: Start Jetty 127.0.0.1:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:22.054130","level":"info","event":"25/05/28 13:42:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:22.151290","level":"info","event":"25/05/28 13:42:22 INFO Executor: Starting executor ID driver on host localhost","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:22.151586","level":"info","event":"25/05/28 13:42:22 INFO Executor: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:22.151929","level":"info","event":"25/05/28 13:42:22 INFO Executor: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:22.158813","level":"info","event":"25/05/28 13:42:22 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark-jars/*,file:/opt/airflow/*'","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:22.159341","level":"info","event":"25/05/28 13:42:22 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5018a560 for default.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:22.177533","level":"info","event":"25/05/28 13:42:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33969.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:22.177702","level":"info","event":"25/05/28 13:42:22 INFO NettyBlockTransferService: Server created on localhost:33969","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:22.179887","level":"info","event":"25/05/28 13:42:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:22.186126","level":"info","event":"25/05/28 13:42:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 33969, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:22.189196","level":"info","event":"25/05/28 13:42:22 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33969 with 1048.8 MiB RAM, BlockManagerId(driver, localhost, 33969, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:22.191113","level":"info","event":"25/05/28 13:42:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 33969, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:22.192224","level":"info","event":"25/05/28 13:42:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 33969, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:22.593422","level":"info","event":"25/05/28 13:42:22 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:22.620249","level":"info","event":"25/05/28 13:42:22 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:23.783804","level":"info","event":"25/05/28 13:42:23 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:23.800755","level":"info","event":"25/05/28 13:42:23 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:23.801029","level":"info","event":"25/05/28 13:42:23 INFO MetricsSystemImpl: s3a-file-system metrics system started","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:24.656162","level":"info","event":"25/05/28 13:42:24 INFO InMemoryFileIndex: It took 59 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:24.746314","level":"info","event":"25/05/28 13:42:24 INFO InMemoryFileIndex: It took 14 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.015569","level":"info","event":"25/05/28 13:42:27 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.017994","level":"info","event":"25/05/28 13:42:27 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.401387","level":"info","event":"25/05/28 13:42:27 INFO CodeGenerator: Code generated in 143.997937 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.441103","level":"info","event":"25/05/28 13:42:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 211.5 KiB, free 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.644854","level":"info","event":"25/05/28 13:42:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.648092","level":"info","event":"25/05/28 13:42:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33969 (size: 35.3 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.651993","level":"info","event":"25/05/28 13:42:27 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.661894","level":"info","event":"25/05/28 13:42:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7426254 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.776369","level":"info","event":"25/05/28 13:42:27 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.791261","level":"info","event":"25/05/28 13:42:27 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.791517","level":"info","event":"25/05/28 13:42:27 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.791783","level":"info","event":"25/05/28 13:42:27 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.792691","level":"info","event":"25/05/28 13:42:27 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.795875","level":"info","event":"25/05/28 13:42:27 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.856290","level":"info","event":"25/05/28 13:42:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.865140","level":"info","event":"25/05/28 13:42:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.865945","level":"info","event":"25/05/28 13:42:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33969 (size: 6.4 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.867154","level":"info","event":"25/05/28 13:42:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.887284","level":"info","event":"25/05/28 13:42:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.888499","level":"info","event":"25/05/28 13:42:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.920458","level":"info","event":"25/05/28 13:42:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (localhost, executor driver, partition 0, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:27.931365","level":"info","event":"25/05/28 13:42:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.021460","level":"info","event":"25/05/28 13:42:28 INFO CodeGenerator: Code generated in 12.504928 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.024996","level":"info","event":"25/05/28 13:42:28 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 0-7426254, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.040772","level":"info","event":"25/05/28 13:42:28 INFO CodeGenerator: Code generated in 9.843352 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.143673","level":"info","event":"25/05/28 13:42:28 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1756 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.172702","level":"info","event":"25/05/28 13:42:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 260 ms on localhost (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.176812","level":"info","event":"25/05/28 13:42:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.183082","level":"info","event":"25/05/28 13:42:28 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 0.376 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.188355","level":"info","event":"25/05/28 13:42:28 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.188861","level":"info","event":"25/05/28 13:42:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.192551","level":"info","event":"25/05/28 13:42:28 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 0.415461 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.221724","level":"info","event":"25/05/28 13:42:28 INFO CodeGenerator: Code generated in 14.437356 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.279002","level":"info","event":"25/05/28 13:42:28 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:33969 in memory (size: 6.4 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.291644","level":"info","event":"25/05/28 13:42:28 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.291842","level":"info","event":"25/05/28 13:42:28 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.302321","level":"info","event":"25/05/28 13:42:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 211.5 KiB, free 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.322989","level":"info","event":"25/05/28 13:42:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.324611","level":"info","event":"25/05/28 13:42:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33969 (size: 35.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.326484","level":"info","event":"25/05/28 13:42:28 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.328405","level":"info","event":"25/05/28 13:42:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7426254 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.422388","level":"info","event":"25/05/28 13:42:28 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.423852","level":"info","event":"25/05/28 13:42:28 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 12 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.424042","level":"info","event":"25/05/28 13:42:28 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.424120","level":"info","event":"25/05/28 13:42:28 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.424438","level":"info","event":"25/05/28 13:42:28 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.425429","level":"info","event":"25/05/28 13:42:28 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.458193","level":"info","event":"25/05/28 13:42:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 29.0 KiB, free 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.460752","level":"info","event":"25/05/28 13:42:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.461398","level":"info","event":"25/05/28 13:42:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:33969 (size: 13.4 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.462258","level":"info","event":"25/05/28 13:42:28 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.463986","level":"info","event":"25/05/28 13:42:28 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.464220","level":"info","event":"25/05/28 13:42:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 12 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.466212","level":"info","event":"25/05/28 13:42:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (localhost, executor driver, partition 0, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.466697","level":"info","event":"25/05/28 13:42:28 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (localhost, executor driver, partition 1, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.467260","level":"info","event":"25/05/28 13:42:28 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (localhost, executor driver, partition 2, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.467860","level":"info","event":"25/05/28 13:42:28 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (localhost, executor driver, partition 3, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.468351","level":"info","event":"25/05/28 13:42:28 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (localhost, executor driver, partition 4, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.468964","level":"info","event":"25/05/28 13:42:28 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (localhost, executor driver, partition 5, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.469398","level":"info","event":"25/05/28 13:42:28 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (localhost, executor driver, partition 6, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.469905","level":"info","event":"25/05/28 13:42:28 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (localhost, executor driver, partition 7, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.470509","level":"info","event":"25/05/28 13:42:28 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 9) (localhost, executor driver, partition 8, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.471137","level":"info","event":"25/05/28 13:42:28 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 10) (localhost, executor driver, partition 9, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.471682","level":"info","event":"25/05/28 13:42:28 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 11) (localhost, executor driver, partition 10, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.472203","level":"info","event":"25/05/28 13:42:28 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 12) (localhost, executor driver, partition 11, PROCESS_LOCAL, 8219 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.473216","level":"info","event":"25/05/28 13:42:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.474073","level":"info","event":"25/05/28 13:42:28 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.474274","level":"info","event":"25/05/28 13:42:28 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.474732","level":"info","event":"25/05/28 13:42:28 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.475165","level":"info","event":"25/05/28 13:42:28 INFO Executor: Running task 4.0 in stage 1.0 (TID 5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.475722","level":"info","event":"25/05/28 13:42:28 INFO Executor: Running task 5.0 in stage 1.0 (TID 6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.476692","level":"info","event":"25/05/28 13:42:28 INFO Executor: Running task 7.0 in stage 1.0 (TID 8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.485185","level":"info","event":"25/05/28 13:42:28 INFO Executor: Running task 6.0 in stage 1.0 (TID 7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.486249","level":"info","event":"25/05/28 13:42:28 INFO Executor: Running task 8.0 in stage 1.0 (TID 9)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.488295","level":"info","event":"25/05/28 13:42:28 INFO Executor: Running task 10.0 in stage 1.0 (TID 11)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.490184","level":"info","event":"25/05/28 13:42:28 INFO Executor: Running task 9.0 in stage 1.0 (TID 10)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.491577","level":"info","event":"25/05/28 13:42:28 INFO Executor: Running task 11.0 in stage 1.0 (TID 12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.542990","level":"info","event":"25/05/28 13:42:28 INFO CodeGenerator: Code generated in 10.431991 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.552697","level":"info","event":"25/05/28 13:42:28 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 74262540-81688794, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.552981","level":"info","event":"25/05/28 13:42:28 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 44557524-51983778, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.553139","level":"info","event":"25/05/28 13:42:28 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 51983778-59410032, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.553402","level":"info","event":"25/05/28 13:42:28 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 7426254-14852508, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.553737","level":"info","event":"25/05/28 13:42:28 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 0-7426254, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.553903","level":"info","event":"25/05/28 13:42:28 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 14852508-22278762, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.554123","level":"info","event":"25/05/28 13:42:28 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 81688794-84920745, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.555378","level":"info","event":"25/05/28 13:42:28 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 66836286-74262540, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.557138","level":"info","event":"25/05/28 13:42:28 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 22278762-29705016, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.557633","level":"info","event":"25/05/28 13:42:28 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 29705016-37131270, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.558196","level":"info","event":"25/05/28 13:42:28 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 59410032-66836286, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:28.561555","level":"info","event":"25/05/28 13:42:28 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 37131270-44557524, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:29.001148","level":"info","event":"25/05/28 13:42:29 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:33969 in memory (size: 35.3 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:29.676240","level":"info","event":"25/05/28 13:42:29 INFO Executor: Finished task 11.0 in stage 1.0 (TID 12). 1653 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:29.679835","level":"info","event":"25/05/28 13:42:29 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 12) in 1208 ms on localhost (executor driver) (1/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:29.981937","level":"info","event":"25/05/28 13:42:29 INFO Executor: Finished task 8.0 in stage 1.0 (TID 9). 1653 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:29.982510","level":"info","event":"25/05/28 13:42:29 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:29.989687","level":"info","event":"25/05/28 13:42:29 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 9) in 1520 ms on localhost (executor driver) (2/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.001627","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1534 ms on localhost (executor driver) (3/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.005409","level":"info","event":"25/05/28 13:42:30 INFO Executor: Finished task 9.0 in stage 1.0 (TID 10). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.006233","level":"info","event":"25/05/28 13:42:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.008146","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 10) in 1537 ms on localhost (executor driver) (4/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.014354","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1548 ms on localhost (executor driver) (5/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.019599","level":"info","event":"25/05/28 13:42:30 INFO Executor: Finished task 5.0 in stage 1.0 (TID 6). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.020317","level":"info","event":"25/05/28 13:42:30 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.021307","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1552 ms on localhost (executor driver) (6/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.022313","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1555 ms on localhost (executor driver) (7/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.031211","level":"info","event":"25/05/28 13:42:30 INFO Executor: Finished task 6.0 in stage 1.0 (TID 7). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.033766","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1564 ms on localhost (executor driver) (8/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.037705","level":"info","event":"25/05/28 13:42:30 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.039153","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1571 ms on localhost (executor driver) (9/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.039775","level":"info","event":"25/05/28 13:42:30 INFO Executor: Finished task 4.0 in stage 1.0 (TID 5). 1653 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.041479","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1573 ms on localhost (executor driver) (10/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.045682","level":"info","event":"25/05/28 13:42:30 INFO Executor: Finished task 10.0 in stage 1.0 (TID 11). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.047311","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 11) in 1575 ms on localhost (executor driver) (11/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.048999","level":"info","event":"25/05/28 13:42:30 INFO Executor: Finished task 7.0 in stage 1.0 (TID 8). 1610 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.050379","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 1580 ms on localhost (executor driver) (12/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.050699","level":"info","event":"25/05/28 13:42:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.051570","level":"info","event":"25/05/28 13:42:30 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 1.623 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.052121","level":"info","event":"25/05/28 13:42:30 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.052359","level":"info","event":"25/05/28 13:42:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.053036","level":"info","event":"25/05/28 13:42:30 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 1.630167 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.275545","level":"info","event":"25/05/28 13:42:30 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.275770","level":"info","event":"25/05/28 13:42:30 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.461873","level":"info","event":"25/05/28 13:42:30 INFO CodeGenerator: Code generated in 82.419559 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.467488","level":"info","event":"25/05/28 13:42:30 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 211.4 KiB, free 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.484184","level":"info","event":"25/05/28 13:42:30 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.485595","level":"info","event":"25/05/28 13:42:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:33969 (size: 35.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.486954","level":"info","event":"25/05/28 13:42:30 INFO SparkContext: Created broadcast 4 from parquet at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.493714","level":"info","event":"25/05/28 13:42:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7426254 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.512204","level":"info","event":"25/05/28 13:42:30 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:33969 in memory (size: 35.3 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.517922","level":"info","event":"25/05/28 13:42:30 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:33969 in memory (size: 13.4 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.537750","level":"info","event":"25/05/28 13:42:30 INFO DAGScheduler: Registering RDD 13 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.540623","level":"info","event":"25/05/28 13:42:30 INFO DAGScheduler: Got map stage job 2 (parquet at NativeMethodAccessorImpl.java:0) with 12 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.541001","level":"info","event":"25/05/28 13:42:30 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (parquet at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.541467","level":"info","event":"25/05/28 13:42:30 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.542144","level":"info","event":"25/05/28 13:42:30 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.543387","level":"info","event":"25/05/28 13:42:30 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.556190","level":"info","event":"25/05/28 13:42:30 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 42.9 KiB, free 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.558248","level":"info","event":"25/05/28 13:42:30 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.559313","level":"info","event":"25/05/28 13:42:30 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:33969 (size: 19.1 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.560082","level":"info","event":"25/05/28 13:42:30 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.562134","level":"info","event":"25/05/28 13:42:30 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.562302","level":"info","event":"25/05/28 13:42:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 12 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.565908","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 13) (localhost, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.566501","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 14) (localhost, executor driver, partition 1, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.567070","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 15) (localhost, executor driver, partition 2, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.567612","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 16) (localhost, executor driver, partition 3, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.568203","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 17) (localhost, executor driver, partition 4, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.568762","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 18) (localhost, executor driver, partition 5, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.569287","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 19) (localhost, executor driver, partition 6, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.569860","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 20) (localhost, executor driver, partition 7, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.570262","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Starting task 8.0 in stage 2.0 (TID 21) (localhost, executor driver, partition 8, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.570708","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Starting task 9.0 in stage 2.0 (TID 22) (localhost, executor driver, partition 9, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.571364","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Starting task 10.0 in stage 2.0 (TID 23) (localhost, executor driver, partition 10, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.571912","level":"info","event":"25/05/28 13:42:30 INFO TaskSetManager: Starting task 11.0 in stage 2.0 (TID 24) (localhost, executor driver, partition 11, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.572842","level":"info","event":"25/05/28 13:42:30 INFO Executor: Running task 2.0 in stage 2.0 (TID 15)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.573032","level":"info","event":"25/05/28 13:42:30 INFO Executor: Running task 0.0 in stage 2.0 (TID 13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.573183","level":"info","event":"25/05/28 13:42:30 INFO Executor: Running task 1.0 in stage 2.0 (TID 14)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.573307","level":"info","event":"25/05/28 13:42:30 INFO Executor: Running task 3.0 in stage 2.0 (TID 16)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.573446","level":"info","event":"25/05/28 13:42:30 INFO Executor: Running task 6.0 in stage 2.0 (TID 19)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.573576","level":"info","event":"25/05/28 13:42:30 INFO Executor: Running task 5.0 in stage 2.0 (TID 18)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.574179","level":"info","event":"25/05/28 13:42:30 INFO Executor: Running task 4.0 in stage 2.0 (TID 17)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.579375","level":"info","event":"25/05/28 13:42:30 INFO Executor: Running task 7.0 in stage 2.0 (TID 20)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.579598","level":"info","event":"25/05/28 13:42:30 INFO Executor: Running task 10.0 in stage 2.0 (TID 23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.579730","level":"info","event":"25/05/28 13:42:30 INFO Executor: Running task 8.0 in stage 2.0 (TID 21)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.579852","level":"info","event":"25/05/28 13:42:30 INFO Executor: Running task 9.0 in stage 2.0 (TID 22)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.580023","level":"info","event":"25/05/28 13:42:30 INFO Executor: Running task 11.0 in stage 2.0 (TID 24)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.665356","level":"info","event":"25/05/28 13:42:30 INFO CodeGenerator: Code generated in 64.829894 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.689292","level":"info","event":"25/05/28 13:42:30 INFO CodeGenerator: Code generated in 13.013561 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.710284","level":"info","event":"25/05/28 13:42:30 INFO CodeGenerator: Code generated in 6.716345 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.738839","level":"info","event":"25/05/28 13:42:30 INFO CodeGenerator: Code generated in 9.853052 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.748039","level":"info","event":"25/05/28 13:42:30 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 37131270-44557524, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.748327","level":"info","event":"25/05/28 13:42:30 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 81688794-84920745, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.748475","level":"info","event":"25/05/28 13:42:30 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 14852508-22278762, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.748589","level":"info","event":"25/05/28 13:42:30 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 66836286-74262540, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.750700","level":"info","event":"25/05/28 13:42:30 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 44557524-51983778, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.750959","level":"info","event":"25/05/28 13:42:30 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 0-7426254, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.751818","level":"info","event":"25/05/28 13:42:30 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 59410032-66836286, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.752107","level":"info","event":"25/05/28 13:42:30 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 29705016-37131270, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.753047","level":"info","event":"25/05/28 13:42:30 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 22278762-29705016, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.753245","level":"info","event":"25/05/28 13:42:30 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 74262540-81688794, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.753770","level":"info","event":"25/05/28 13:42:30 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 7426254-14852508, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:30.757209","level":"info","event":"25/05/28 13:42:30 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 51983778-59410032, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.021150","level":"info","event":"25/05/28 13:42:32 INFO Executor: Finished task 11.0 in stage 2.0 (TID 24). 2735 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.035096","level":"info","event":"25/05/28 13:42:32 INFO TaskSetManager: Finished task 11.0 in stage 2.0 (TID 24) in 1463 ms on localhost (executor driver) (1/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.081289","level":"info","event":"25/05/28 13:42:32 INFO Executor: Finished task 10.0 in stage 2.0 (TID 23). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.082638","level":"info","event":"25/05/28 13:42:32 INFO TaskSetManager: Finished task 10.0 in stage 2.0 (TID 23) in 1512 ms on localhost (executor driver) (2/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.092700","level":"info","event":"25/05/28 13:42:32 INFO Executor: Finished task 8.0 in stage 2.0 (TID 21). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.095121","level":"info","event":"25/05/28 13:42:32 INFO TaskSetManager: Finished task 8.0 in stage 2.0 (TID 21) in 1525 ms on localhost (executor driver) (3/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.104708","level":"info","event":"25/05/28 13:42:32 INFO Executor: Finished task 4.0 in stage 2.0 (TID 17). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.106146","level":"info","event":"25/05/28 13:42:32 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 17) in 1538 ms on localhost (executor driver) (4/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.139062","level":"info","event":"25/05/28 13:42:32 INFO Executor: Finished task 1.0 in stage 2.0 (TID 14). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.140715","level":"info","event":"25/05/28 13:42:32 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 14) in 1575 ms on localhost (executor driver) (5/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.140963","level":"info","event":"25/05/28 13:42:32 INFO Executor: Finished task 3.0 in stage 2.0 (TID 16). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.141072","level":"info","event":"25/05/28 13:42:32 INFO Executor: Finished task 2.0 in stage 2.0 (TID 15). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.143753","level":"info","event":"25/05/28 13:42:32 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 16) in 1576 ms on localhost (executor driver) (6/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.143997","level":"info","event":"25/05/28 13:42:32 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 15) in 1577 ms on localhost (executor driver) (7/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.145371","level":"info","event":"25/05/28 13:42:32 INFO Executor: Finished task 6.0 in stage 2.0 (TID 19). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.147357","level":"info","event":"25/05/28 13:42:32 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 19) in 1578 ms on localhost (executor driver) (8/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.151587","level":"info","event":"25/05/28 13:42:32 INFO Executor: Finished task 0.0 in stage 2.0 (TID 13). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.153737","level":"info","event":"25/05/28 13:42:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 13) in 1588 ms on localhost (executor driver) (9/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.156285","level":"info","event":"25/05/28 13:42:32 INFO Executor: Finished task 9.0 in stage 2.0 (TID 22). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.156515","level":"info","event":"25/05/28 13:42:32 INFO Executor: Finished task 7.0 in stage 2.0 (TID 20). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.156651","level":"info","event":"25/05/28 13:42:32 INFO Executor: Finished task 5.0 in stage 2.0 (TID 18). 2692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.157743","level":"info","event":"25/05/28 13:42:32 INFO TaskSetManager: Finished task 9.0 in stage 2.0 (TID 22) in 1587 ms on localhost (executor driver) (10/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.158237","level":"info","event":"25/05/28 13:42:32 INFO TaskSetManager: Finished task 7.0 in stage 2.0 (TID 20) in 1588 ms on localhost (executor driver) (11/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.158511","level":"info","event":"25/05/28 13:42:32 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 18) in 1590 ms on localhost (executor driver) (12/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.159065","level":"info","event":"25/05/28 13:42:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.162269","level":"info","event":"25/05/28 13:42:32 INFO DAGScheduler: ShuffleMapStage 2 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.615 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.163049","level":"info","event":"25/05/28 13:42:32 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.163533","level":"info","event":"25/05/28 13:42:32 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.164400","level":"info","event":"25/05/28 13:42:32 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.164961","level":"info","event":"25/05/28 13:42:32 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.188680","level":"info","event":"25/05/28 13:42:32 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.250690","level":"info","event":"25/05/28 13:42:32 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.271879","level":"info","event":"25/05/28 13:42:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.272070","level":"info","event":"25/05/28 13:42:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.273152","level":"info","event":"25/05/28 13:42:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.273487","level":"info","event":"25/05/28 13:42:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.273606","level":"info","event":"25/05/28 13:42:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.274438","level":"info","event":"25/05/28 13:42:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.473024","level":"info","event":"25/05/28 13:42:32 INFO CodeGenerator: Code generated in 45.554117 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.500551","level":"info","event":"25/05/28 13:42:32 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.502347","level":"info","event":"25/05/28 13:42:32 INFO DAGScheduler: Got job 3 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.502527","level":"info","event":"25/05/28 13:42:32 INFO DAGScheduler: Final stage: ResultStage 4 (parquet at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.502611","level":"info","event":"25/05/28 13:42:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.502688","level":"info","event":"25/05/28 13:42:32 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.503285","level":"info","event":"25/05/28 13:42:32 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[16] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.541828","level":"info","event":"25/05/28 13:42:32 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 255.1 KiB, free 1048.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.544231","level":"info","event":"25/05/28 13:42:32 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 93.6 KiB, free 1048.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.545233","level":"info","event":"25/05/28 13:42:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:33969 (size: 93.6 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.546298","level":"info","event":"25/05/28 13:42:32 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.547374","level":"info","event":"25/05/28 13:42:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.547566","level":"info","event":"25/05/28 13:42:32 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.552503","level":"info","event":"25/05/28 13:42:32 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 25) (localhost, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.553385","level":"info","event":"25/05/28 13:42:32 INFO Executor: Running task 0.0 in stage 4.0 (TID 25)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.609200","level":"info","event":"25/05/28 13:42:32 INFO ShuffleBlockFetcherIterator: Getting 12 (531.3 KiB) non-empty blocks including 12 (531.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.611572","level":"info","event":"25/05/28 13:42:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.651322","level":"info","event":"25/05/28 13:42:32 INFO CodeGenerator: Code generated in 32.999673 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.653781","level":"info","event":"25/05/28 13:42:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.654066","level":"info","event":"25/05/28 13:42:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.654296","level":"info","event":"25/05/28 13:42:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.654415","level":"info","event":"25/05/28 13:42:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.654546","level":"info","event":"25/05/28 13:42:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.654822","level":"info","event":"25/05/28 13:42:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.659601","level":"info","event":"25/05/28 13:42:32 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.662679","level":"info","event":"25/05/28 13:42:32 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.677803","level":"info","event":"25/05/28 13:42:32 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.705176","level":"info","event":"25/05/28 13:42:32 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.705349","level":"info","event":"{","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.705429","level":"info","event":"\"type\" : \"struct\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.705495","level":"info","event":"\"fields\" : [ {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.705555","level":"info","event":"\"name\" : \"product_name\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.705615","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.705709","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.705786","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.705845","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.705902","level":"info","event":"\"name\" : \"Product_Category\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.705959","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.706019","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.706093","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.706150","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.706241","level":"info","event":"\"name\" : \"Product_Brand\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.706323","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.706381","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.706444","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.706500","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.706555","level":"info","event":"\"name\" : \"Product_Type\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.706610","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.706664","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.706717","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.706825","level":"info","event":"} ]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.706889","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.706946","level":"info","event":"and corresponding Parquet message type:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.707003","level":"info","event":"message spark_schema {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.707057","level":"info","event":"optional binary product_name (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.707112","level":"info","event":"optional binary Product_Category (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.707166","level":"info","event":"optional binary Product_Brand (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.707219","level":"info","event":"optional binary Product_Type (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.707322","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.707391","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.707448","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:32.771831","level":"info","event":"25/05/28 13:42:32 INFO CodecPool: Got brand-new compressor [.snappy]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.388533","level":"info","event":"25/05/28 13:42:33 INFO FileOutputCommitter: Saved output of task 'attempt_202505281342325461856622608176294_0004_m_000000_25' to s3a://etl-dag/silver/data/products/static/_temporary/0/task_202505281342325461856622608176294_0004_m_000000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.390517","level":"info","event":"25/05/28 13:42:33 INFO SparkHadoopMapRedUtil: attempt_202505281342325461856622608176294_0004_m_000000_25: Committed. Elapsed time: 155 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.396142","level":"info","event":"25/05/28 13:42:33 INFO Executor: Finished task 0.0 in stage 4.0 (TID 25). 5022 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.401619","level":"info","event":"25/05/28 13:42:33 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 25) in 851 ms on localhost (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.401889","level":"info","event":"25/05/28 13:42:33 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.403342","level":"info","event":"25/05/28 13:42:33 INFO DAGScheduler: ResultStage 4 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.882 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.403715","level":"info","event":"25/05/28 13:42:33 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.403864","level":"info","event":"25/05/28 13:42:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.405523","level":"info","event":"25/05/28 13:42:33 INFO DAGScheduler: Job 3 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.904442 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.407517","level":"info","event":"25/05/28 13:42:33 INFO FileFormatWriter: Start to commit write Job 9d5f08d3-2cb2-437c-b238-1e7703453dc6.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.570336","level":"info","event":"25/05/28 13:42:33 INFO FileFormatWriter: Write Job 9d5f08d3-2cb2-437c-b238-1e7703453dc6 committed. Elapsed time: 161 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.573697","level":"info","event":"25/05/28 13:42:33 INFO FileFormatWriter: Finished processing stats for write job 9d5f08d3-2cb2-437c-b238-1e7703453dc6.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.650014","level":"info","event":"25/05/28 13:42:33 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.650254","level":"info","event":"25/05/28 13:42:33 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.788432","level":"info","event":"25/05/28 13:42:33 INFO CodeGenerator: Code generated in 57.7309 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.792397","level":"info","event":"25/05/28 13:42:33 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 211.4 KiB, free 1048.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.805833","level":"info","event":"25/05/28 13:42:33 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1047.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.806495","level":"info","event":"25/05/28 13:42:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:33969 (size: 35.3 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.807465","level":"info","event":"25/05/28 13:42:33 INFO SparkContext: Created broadcast 7 from parquet at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.809488","level":"info","event":"25/05/28 13:42:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7426254 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.836581","level":"info","event":"25/05/28 13:42:33 INFO DAGScheduler: Registering RDD 20 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.836828","level":"info","event":"25/05/28 13:42:33 INFO DAGScheduler: Got map stage job 4 (parquet at NativeMethodAccessorImpl.java:0) with 12 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.836943","level":"info","event":"25/05/28 13:42:33 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (parquet at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.837021","level":"info","event":"25/05/28 13:42:33 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.837111","level":"info","event":"25/05/28 13:42:33 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.837672","level":"info","event":"25/05/28 13:42:33 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[20] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.842361","level":"info","event":"25/05/28 13:42:33 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 56.3 KiB, free 1047.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.844615","level":"info","event":"25/05/28 13:42:33 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 24.2 KiB, free 1047.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.844915","level":"info","event":"25/05/28 13:42:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:33969 (size: 24.2 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.845897","level":"info","event":"25/05/28 13:42:33 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.846795","level":"info","event":"25/05/28 13:42:33 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[20] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.847022","level":"info","event":"25/05/28 13:42:33 INFO TaskSchedulerImpl: Adding task set 5.0 with 12 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.849279","level":"info","event":"25/05/28 13:42:33 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 26) (localhost, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.849757","level":"info","event":"25/05/28 13:42:33 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 27) (localhost, executor driver, partition 1, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.850391","level":"info","event":"25/05/28 13:42:33 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 28) (localhost, executor driver, partition 2, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.850826","level":"info","event":"25/05/28 13:42:33 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 29) (localhost, executor driver, partition 3, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.851371","level":"info","event":"25/05/28 13:42:33 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 30) (localhost, executor driver, partition 4, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.851827","level":"info","event":"25/05/28 13:42:33 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 31) (localhost, executor driver, partition 5, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.852267","level":"info","event":"25/05/28 13:42:33 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 32) (localhost, executor driver, partition 6, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.852865","level":"info","event":"25/05/28 13:42:33 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 33) (localhost, executor driver, partition 7, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.853265","level":"info","event":"25/05/28 13:42:33 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 34) (localhost, executor driver, partition 8, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.853703","level":"info","event":"25/05/28 13:42:33 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 35) (localhost, executor driver, partition 9, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.854104","level":"info","event":"25/05/28 13:42:33 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 36) (localhost, executor driver, partition 10, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.854753","level":"info","event":"25/05/28 13:42:33 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 37) (localhost, executor driver, partition 11, PROCESS_LOCAL, 8208 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.855979","level":"info","event":"25/05/28 13:42:33 INFO Executor: Running task 0.0 in stage 5.0 (TID 26)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.856193","level":"info","event":"25/05/28 13:42:33 INFO Executor: Running task 1.0 in stage 5.0 (TID 27)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.856504","level":"info","event":"25/05/28 13:42:33 INFO Executor: Running task 2.0 in stage 5.0 (TID 28)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.856654","level":"info","event":"25/05/28 13:42:33 INFO Executor: Running task 3.0 in stage 5.0 (TID 29)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.856805","level":"info","event":"25/05/28 13:42:33 INFO Executor: Running task 6.0 in stage 5.0 (TID 32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.856938","level":"info","event":"25/05/28 13:42:33 INFO Executor: Running task 7.0 in stage 5.0 (TID 33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.857067","level":"info","event":"25/05/28 13:42:33 INFO Executor: Running task 5.0 in stage 5.0 (TID 31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.857204","level":"info","event":"25/05/28 13:42:33 INFO Executor: Running task 4.0 in stage 5.0 (TID 30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.860599","level":"info","event":"25/05/28 13:42:33 INFO Executor: Running task 8.0 in stage 5.0 (TID 34)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.860825","level":"info","event":"25/05/28 13:42:33 INFO Executor: Running task 10.0 in stage 5.0 (TID 36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.860957","level":"info","event":"25/05/28 13:42:33 INFO Executor: Running task 11.0 in stage 5.0 (TID 37)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.861069","level":"info","event":"25/05/28 13:42:33 INFO Executor: Running task 9.0 in stage 5.0 (TID 35)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.916905","level":"info","event":"25/05/28 13:42:33 INFO CodeGenerator: Code generated in 47.426322 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.934934","level":"info","event":"25/05/28 13:42:33 INFO CodeGenerator: Code generated in 11.962688 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.945117","level":"info","event":"25/05/28 13:42:33 INFO CodeGenerator: Code generated in 5.853386 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.955551","level":"info","event":"25/05/28 13:42:33 INFO CodeGenerator: Code generated in 6.140504 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.968443","level":"info","event":"25/05/28 13:42:33 INFO CodeGenerator: Code generated in 6.718042 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.972441","level":"info","event":"25/05/28 13:42:33 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 51983778-59410032, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.972715","level":"info","event":"25/05/28 13:42:33 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 7426254-14852508, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.972860","level":"info","event":"25/05/28 13:42:33 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 59410032-66836286, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.972973","level":"info","event":"25/05/28 13:42:33 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 14852508-22278762, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.973074","level":"info","event":"25/05/28 13:42:33 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 81688794-84920745, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.973192","level":"info","event":"25/05/28 13:42:33 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 44557524-51983778, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.973850","level":"info","event":"25/05/28 13:42:33 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 22278762-29705016, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.975322","level":"info","event":"25/05/28 13:42:33 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 74262540-81688794, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.976936","level":"info","event":"25/05/28 13:42:33 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 66836286-74262540, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.980674","level":"info","event":"25/05/28 13:42:33 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 29705016-37131270, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.981017","level":"info","event":"25/05/28 13:42:33 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 0-7426254, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.981955","level":"info","event":"25/05/28 13:42:33 INFO FileScanRDD: Reading File path: s3a://etl-dag/bronze/data/retail_data.csv, range: 37131270-44557524, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:33.989509","level":"info","event":"25/05/28 13:42:33 INFO CodeGenerator: Code generated in 13.637698 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:34.221113","level":"info","event":"25/05/28 13:42:34 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:33969 in memory (size: 93.6 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:34.540584","level":"info","event":"25/05/28 13:42:34 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:33969 in memory (size: 35.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:34.666832","level":"info","event":"25/05/28 13:42:34 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:33969 in memory (size: 19.1 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:34.830292","level":"info","event":"25/05/28 13:42:34 INFO Executor: Finished task 11.0 in stage 5.0 (TID 37). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:34.834251","level":"info","event":"25/05/28 13:42:34 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 37) in 979 ms on localhost (executor driver) (1/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.021633","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 6.0 in stage 5.0 (TID 32). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.024580","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 32) in 1173 ms on localhost (executor driver) (2/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.030797","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 3.0 in stage 5.0 (TID 29). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.033634","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 29) in 1183 ms on localhost (executor driver) (3/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.037219","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 2.0 in stage 5.0 (TID 28). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.040417","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 28) in 1190 ms on localhost (executor driver) (4/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.044871","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 10.0 in stage 5.0 (TID 36). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.047374","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 36) in 1193 ms on localhost (executor driver) (5/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.091229","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 8.0 in stage 5.0 (TID 34). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.097331","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 34) in 1243 ms on localhost (executor driver) (6/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.102693","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 0.0 in stage 5.0 (TID 26). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.104566","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 26) in 1255 ms on localhost (executor driver) (7/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.104913","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 4.0 in stage 5.0 (TID 30). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.105085","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 1.0 in stage 5.0 (TID 27). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.106890","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 27) in 1257 ms on localhost (executor driver) (8/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.107328","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 30) in 1257 ms on localhost (executor driver) (9/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.122118","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 5.0 in stage 5.0 (TID 31). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.123265","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 31) in 1271 ms on localhost (executor driver) (10/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.142047","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 9.0 in stage 5.0 (TID 35). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.143231","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 35) in 1289 ms on localhost (executor driver) (11/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.164202","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 7.0 in stage 5.0 (TID 33). 2748 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.165145","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 33) in 1312 ms on localhost (executor driver) (12/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.165342","level":"info","event":"25/05/28 13:42:35 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.166012","level":"info","event":"25/05/28 13:42:35 INFO DAGScheduler: ShuffleMapStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.327 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.166230","level":"info","event":"25/05/28 13:42:35 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.166349","level":"info","event":"25/05/28 13:42:35 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.166458","level":"info","event":"25/05/28 13:42:35 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.166579","level":"info","event":"25/05/28 13:42:35 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.181573","level":"info","event":"25/05/28 13:42:35 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1139915, minimum partition size: 1048576","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.200070","level":"info","event":"25/05/28 13:42:35 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.264723","level":"info","event":"25/05/28 13:42:35 INFO CodeGenerator: Code generated in 40.507866 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.285296","level":"info","event":"25/05/28 13:42:35 INFO DAGScheduler: Registering RDD 23 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.285541","level":"info","event":"25/05/28 13:42:35 INFO DAGScheduler: Got map stage job 5 (parquet at NativeMethodAccessorImpl.java:0) with 12 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.285712","level":"info","event":"25/05/28 13:42:35 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (parquet at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.285843","level":"info","event":"25/05/28 13:42:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.285967","level":"info","event":"25/05/28 13:42:35 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.286295","level":"info","event":"25/05/28 13:42:35 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[23] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.298466","level":"info","event":"25/05/28 13:42:35 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 78.3 KiB, free 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.300329","level":"info","event":"25/05/28 13:42:35 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 32.0 KiB, free 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.300807","level":"info","event":"25/05/28 13:42:35 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:33969 (size: 32.0 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.301623","level":"info","event":"25/05/28 13:42:35 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.302454","level":"info","event":"25/05/28 13:42:35 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[23] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.302623","level":"info","event":"25/05/28 13:42:35 INFO TaskSchedulerImpl: Adding task set 7.0 with 12 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.304467","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 38) (localhost, executor driver, partition 0, NODE_LOCAL, 7604 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.304739","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 39) (localhost, executor driver, partition 1, NODE_LOCAL, 7604 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.304981","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 40) (localhost, executor driver, partition 2, NODE_LOCAL, 7604 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.305276","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 41) (localhost, executor driver, partition 3, NODE_LOCAL, 7604 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.305609","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 42) (localhost, executor driver, partition 4, NODE_LOCAL, 7604 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.305906","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 43) (localhost, executor driver, partition 5, NODE_LOCAL, 7604 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.306244","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 44) (localhost, executor driver, partition 6, NODE_LOCAL, 7604 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.306655","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 45) (localhost, executor driver, partition 7, NODE_LOCAL, 7604 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.307037","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 46) (localhost, executor driver, partition 8, NODE_LOCAL, 7604 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.307434","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 47) (localhost, executor driver, partition 9, NODE_LOCAL, 7604 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.307798","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 48) (localhost, executor driver, partition 10, NODE_LOCAL, 7604 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.308151","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 49) (localhost, executor driver, partition 11, NODE_LOCAL, 7604 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.311849","level":"info","event":"25/05/28 13:42:35 INFO Executor: Running task 0.0 in stage 7.0 (TID 38)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.312426","level":"info","event":"25/05/28 13:42:35 INFO Executor: Running task 2.0 in stage 7.0 (TID 40)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.312621","level":"info","event":"25/05/28 13:42:35 INFO Executor: Running task 3.0 in stage 7.0 (TID 41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.312745","level":"info","event":"25/05/28 13:42:35 INFO Executor: Running task 1.0 in stage 7.0 (TID 39)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.312851","level":"info","event":"25/05/28 13:42:35 INFO Executor: Running task 4.0 in stage 7.0 (TID 42)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.312949","level":"info","event":"25/05/28 13:42:35 INFO Executor: Running task 11.0 in stage 7.0 (TID 49)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.313045","level":"info","event":"25/05/28 13:42:35 INFO Executor: Running task 10.0 in stage 7.0 (TID 48)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.313151","level":"info","event":"25/05/28 13:42:35 INFO Executor: Running task 7.0 in stage 7.0 (TID 45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.313284","level":"info","event":"25/05/28 13:42:35 INFO Executor: Running task 5.0 in stage 7.0 (TID 43)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.313385","level":"info","event":"25/05/28 13:42:35 INFO Executor: Running task 9.0 in stage 7.0 (TID 47)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.313481","level":"info","event":"25/05/28 13:42:35 INFO Executor: Running task 6.0 in stage 7.0 (TID 44)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.313656","level":"info","event":"25/05/28 13:42:35 INFO Executor: Running task 8.0 in stage 7.0 (TID 46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.320496","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Getting 12 (1070.0 KiB) non-empty blocks including 12 (1070.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.320961","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Getting 12 (1061.1 KiB) non-empty blocks including 12 (1061.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.321352","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.321518","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Getting 12 (1071.5 KiB) non-empty blocks including 12 (1071.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.321684","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.321819","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.321963","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Getting 12 (1075.6 KiB) non-empty blocks including 12 (1075.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.322092","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.324380","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Getting 12 (1073.8 KiB) non-empty blocks including 12 (1073.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.324647","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Getting 12 (1599.4 KiB) non-empty blocks including 12 (1599.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.324793","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.324958","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Getting 12 (1073.1 KiB) non-empty blocks including 12 (1073.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.325078","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.325222","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.328070","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Getting 12 (1068.8 KiB) non-empty blocks including 12 (1068.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.328340","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.329752","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Getting 12 (1071.7 KiB) non-empty blocks including 12 (1071.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.329979","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.334241","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Getting 12 (1063.0 KiB) non-empty blocks including 12 (1063.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.334457","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.335431","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Getting 12 (1069.0 KiB) non-empty blocks including 12 (1069.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.335665","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Getting 12 (1061.4 KiB) non-empty blocks including 12 (1061.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.335810","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.335937","level":"info","event":"25/05/28 13:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.395665","level":"info","event":"25/05/28 13:42:35 INFO CodeGenerator: Code generated in 69.768393 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.417193","level":"info","event":"25/05/28 13:42:35 INFO CodeGenerator: Code generated in 17.955582 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.429985","level":"info","event":"25/05/28 13:42:35 INFO CodeGenerator: Code generated in 8.033728 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.451136","level":"info","event":"25/05/28 13:42:35 INFO CodeGenerator: Code generated in 11.682969 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.821060","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 5.0 in stage 7.0 (TID 43). 5823 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.822588","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 43) in 517 ms on localhost (executor driver) (1/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.882611","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 0.0 in stage 7.0 (TID 38). 5823 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.884419","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 38) in 580 ms on localhost (executor driver) (2/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.897970","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 3.0 in stage 7.0 (TID 41). 5823 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.899495","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 41) in 594 ms on localhost (executor driver) (3/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.919229","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 6.0 in stage 7.0 (TID 44). 5823 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.923009","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 44) in 617 ms on localhost (executor driver) (4/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.934362","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 11.0 in stage 7.0 (TID 49). 5823 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.934815","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 10.0 in stage 7.0 (TID 48). 5823 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.938218","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 8.0 in stage 7.0 (TID 46). 5823 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.938489","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 49) in 628 ms on localhost (executor driver) (5/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.938955","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 7.0 in stage 7.0 (TID 45). 5823 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.939616","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 48) in 630 ms on localhost (executor driver) (6/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.940502","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 45) in 634 ms on localhost (executor driver) (7/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.940719","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 46) in 634 ms on localhost (executor driver) (8/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.943025","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 4.0 in stage 7.0 (TID 42). 5823 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.945439","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 42) in 639 ms on localhost (executor driver) (9/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.947145","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 2.0 in stage 7.0 (TID 40). 5823 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.947529","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 9.0 in stage 7.0 (TID 47). 5823 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.949880","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 40) in 644 ms on localhost (executor driver) (10/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.950972","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 47) in 643 ms on localhost (executor driver) (11/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.955952","level":"info","event":"25/05/28 13:42:35 INFO Executor: Finished task 1.0 in stage 7.0 (TID 39). 5823 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.958311","level":"info","event":"25/05/28 13:42:35 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 39) in 652 ms on localhost (executor driver) (12/12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.958637","level":"info","event":"25/05/28 13:42:35 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.958933","level":"info","event":"25/05/28 13:42:35 INFO DAGScheduler: ShuffleMapStage 7 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.663 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.959269","level":"info","event":"25/05/28 13:42:35 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.959420","level":"info","event":"25/05/28 13:42:35 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.959714","level":"info","event":"25/05/28 13:42:35 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.960790","level":"info","event":"25/05/28 13:42:35 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.965727","level":"info","event":"25/05/28 13:42:35 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:35.998352","level":"info","event":"25/05/28 13:42:35 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.000263","level":"info","event":"25/05/28 13:42:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.000562","level":"info","event":"25/05/28 13:42:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.000866","level":"info","event":"25/05/28 13:42:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.001053","level":"info","event":"25/05/28 13:42:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.001171","level":"info","event":"25/05/28 13:42:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.001385","level":"info","event":"25/05/28 13:42:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.070075","level":"info","event":"25/05/28 13:42:36 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.110908","level":"info","event":"25/05/28 13:42:36 INFO CodeGenerator: Code generated in 26.159522 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.125269","level":"info","event":"25/05/28 13:42:36 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.127901","level":"info","event":"25/05/28 13:42:36 INFO DAGScheduler: Got job 6 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.128330","level":"info","event":"25/05/28 13:42:36 INFO DAGScheduler: Final stage: ResultStage 10 (parquet at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.128672","level":"info","event":"25/05/28 13:42:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.128942","level":"info","event":"25/05/28 13:42:36 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.129193","level":"info","event":"25/05/28 13:42:36 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[26] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.169459","level":"info","event":"25/05/28 13:42:36 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 276.2 KiB, free 1048.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.180481","level":"info","event":"25/05/28 13:42:36 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:33969 in memory (size: 32.0 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.181529","level":"info","event":"25/05/28 13:42:36 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 102.3 KiB, free 1048.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.182171","level":"info","event":"25/05/28 13:42:36 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:33969 (size: 102.3 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.184537","level":"info","event":"25/05/28 13:42:36 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.185475","level":"info","event":"25/05/28 13:42:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[26] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.185714","level":"info","event":"25/05/28 13:42:36 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.188878","level":"info","event":"25/05/28 13:42:36 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 50) (localhost, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.190059","level":"info","event":"25/05/28 13:42:36 INFO Executor: Running task 0.0 in stage 10.0 (TID 50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.237524","level":"info","event":"25/05/28 13:42:36 INFO ShuffleBlockFetcherIterator: Getting 12 (252.2 KiB) non-empty blocks including 12 (252.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.237843","level":"info","event":"25/05/28 13:42:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.263051","level":"info","event":"25/05/28 13:42:36 INFO CodeGenerator: Code generated in 23.041717 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.265937","level":"info","event":"25/05/28 13:42:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.266163","level":"info","event":"25/05/28 13:42:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.266548","level":"info","event":"25/05/28 13:42:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.266685","level":"info","event":"25/05/28 13:42:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.266810","level":"info","event":"25/05/28 13:42:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.266977","level":"info","event":"25/05/28 13:42:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.267124","level":"info","event":"25/05/28 13:42:36 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.267759","level":"info","event":"25/05/28 13:42:36 INFO CodecConfig: Compression: SNAPPY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.270235","level":"info","event":"25/05/28 13:42:36 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.273735","level":"info","event":"25/05/28 13:42:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.274075","level":"info","event":"{","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.274230","level":"info","event":"\"type\" : \"struct\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.274409","level":"info","event":"\"fields\" : [ {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.274547","level":"info","event":"\"name\" : \"product_name\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.274679","level":"info","event":"\"type\" : \"string\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.274802","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.274969","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.275094","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.275209","level":"info","event":"\"name\" : \"total_transactions\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.275321","level":"info","event":"\"type\" : \"long\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.275470","level":"info","event":"\"nullable\" : false,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.275603","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.275725","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.275843","level":"info","event":"\"name\" : \"unique_customers\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.276007","level":"info","event":"\"type\" : \"long\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.276134","level":"info","event":"\"nullable\" : false,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.276250","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.276370","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.276556","level":"info","event":"\"name\" : \"total_revenue\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.276690","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.276801","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.276908","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.277021","level":"info","event":"}, {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.277180","level":"info","event":"\"name\" : \"avg_rating\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.277321","level":"info","event":"\"type\" : \"double\",","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.277443","level":"info","event":"\"nullable\" : true,","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.277558","level":"info","event":"\"metadata\" : { }","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.277720","level":"info","event":"} ]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.277842","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.277959","level":"info","event":"and corresponding Parquet message type:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.278086","level":"info","event":"message spark_schema {","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.278209","level":"info","event":"optional binary product_name (STRING);","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.278321","level":"info","event":"required int64 total_transactions;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.278454","level":"info","event":"required int64 unique_customers;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.278604","level":"info","event":"optional double total_revenue;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.278833","level":"info","event":"optional double avg_rating;","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.279016","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.279143","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.279368","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.493808","level":"info","event":"25/05/28 13:42:36 INFO FileOutputCommitter: Saved output of task 'attempt_202505281342368329063529339935140_0010_m_000000_50' to s3a://etl-dag/silver/data/products/aggregated/_temporary/0/task_202505281342368329063529339935140_0010_m_000000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.494006","level":"info","event":"25/05/28 13:42:36 INFO SparkHadoopMapRedUtil: attempt_202505281342368329063529339935140_0010_m_000000_50: Committed. Elapsed time: 82 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.496155","level":"info","event":"25/05/28 13:42:36 INFO Executor: Finished task 0.0 in stage 10.0 (TID 50). 7038 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.497267","level":"info","event":"25/05/28 13:42:36 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 50) in 309 ms on localhost (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.497464","level":"info","event":"25/05/28 13:42:36 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.498440","level":"info","event":"25/05/28 13:42:36 INFO DAGScheduler: ResultStage 10 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.360 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.498833","level":"info","event":"25/05/28 13:42:36 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.499011","level":"info","event":"25/05/28 13:42:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.499387","level":"info","event":"25/05/28 13:42:36 INFO DAGScheduler: Job 6 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.373865 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.500821","level":"info","event":"25/05/28 13:42:36 INFO FileFormatWriter: Start to commit write Job 4520e1aa-f8ee-4944-bd1e-2e07853c1f6d.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.627095","level":"info","event":"25/05/28 13:42:36 INFO FileFormatWriter: Write Job 4520e1aa-f8ee-4944-bd1e-2e07853c1f6d committed. Elapsed time: 126 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.627493","level":"info","event":"25/05/28 13:42:36 INFO FileFormatWriter: Finished processing stats for write job 4520e1aa-f8ee-4944-bd1e-2e07853c1f6d.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.629357","level":"info","event":"25/05/28 13:42:36 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.643577","level":"info","event":"25/05/28 13:42:36 INFO SparkUI: Stopped Spark web UI at http://localhost:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.658373","level":"info","event":"25/05/28 13:42:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.681214","level":"info","event":"25/05/28 13:42:36 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.681549","level":"info","event":"25/05/28 13:42:36 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.686287","level":"info","event":"25/05/28 13:42:36 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.689279","level":"info","event":"25/05/28 13:42:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.701136","level":"info","event":"25/05/28 13:42:36 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.937828","level":"info","event":"25/05/28 13:42:36 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.938224","level":"info","event":"25/05/28 13:42:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-c2365d63-da81-4347-995c-a166c7355401","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.941714","level":"info","event":"25/05/28 13:42:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-515128cd-61ff-4fb5-8063-504e12fdf22d/pyspark-21358f27-61c0-4766-9dde-630d8690d3e3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.945532","level":"info","event":"25/05/28 13:42:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-515128cd-61ff-4fb5-8063-504e12fdf22d","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.954315","level":"info","event":"25/05/28 13:42:36 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.954515","level":"info","event":"25/05/28 13:42:36 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-05-28T13:42:36.954645","level":"info","event":"25/05/28 13:42:36 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
